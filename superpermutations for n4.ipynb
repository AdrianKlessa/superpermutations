{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Finding short superpermutations for n=4",
   "id": "44577e4bb392f49d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:49:08.342241Z",
     "start_time": "2025-06-18T18:49:06.479166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from GymPermutationsEnv import GymPermutationEnv"
   ],
   "id": "9eec6592a776cba4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:49:11.675139Z",
     "start_time": "2025-06-18T18:49:10.481299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.logger import HumanOutputFormat, KVWriter, Logger\n",
    "\n",
    "class MLflowOutputFormat(KVWriter):\n",
    "    \"\"\"\n",
    "    Dumps key/value pairs into MLflow's numeric format.\n",
    "    \"\"\"\n",
    "\n",
    "    def write(\n",
    "        self,\n",
    "        key_values: Dict[str, Any],\n",
    "        key_excluded: Dict[str, Union[str, Tuple[str, ...]]],\n",
    "        step: int = 0,\n",
    "    ) -> None:\n",
    "\n",
    "        for (key, value), (_, excluded) in zip(\n",
    "            sorted(key_values.items()), sorted(key_excluded.items())\n",
    "        ):\n",
    "\n",
    "            if excluded is not None and \"mlflow\" in excluded:\n",
    "                continue\n",
    "\n",
    "            if isinstance(value, np.ScalarType):\n",
    "                if not isinstance(value, str):\n",
    "                    mlflow.log_metric(key, value, step)\n",
    "\n",
    "\n",
    "loggers = Logger(\n",
    "    folder=None,\n",
    "    output_formats=[HumanOutputFormat(sys.stdout), MLflowOutputFormat()],\n",
    ")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ],
   "id": "346ce92e8dd13be2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:49:12.224597Z",
     "start_time": "2025-06-18T18:49:12.219069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "\n",
    "class PermutationLogCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.best_permutation = []\n",
    "        self.best_permutation_length=-1\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for _info in infos:\n",
    "            if \"superpermutation\" in _info and \"superpermutation_length\" in _info:\n",
    "                if self.best_permutation_length==-1 or (_info[\"superpermutation_length\"] < self.best_permutation_length):\n",
    "                    self.best_permutation_length = _info[\"superpermutation_length\"]\n",
    "                    self.best_permutation = \" \".join([str(i) for i in _info[\"superpermutation\"]])\n",
    "                self.logger.record(\"superpermutation/best_superpermutation_length\", self.best_permutation_length)\n",
    "                self.logger.record(\"superpermutation/best_superpermutation\", self.best_permutation)\n",
    "        return True\n"
   ],
   "id": "65a0bfe30e66d1a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:59:41.116430Z",
     "start_time": "2025-06-18T18:49:41.327406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the agent\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import permutation_utils\n",
    "\n",
    "alphabet_size=4\n",
    "vec_env = make_vec_env(GymPermutationEnv, n_envs=16, env_kwargs=dict(alphabet_size=alphabet_size), vec_env_cls=SubprocVecEnv)\n",
    "eval_env = make_vec_env(GymPermutationEnv, env_kwargs=dict(alphabet_size=alphabet_size), vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "max_reward_unscaled = permutation_utils.get_max_possible_reward(4, 33)\n",
    "max_reward_scaled = max_reward_unscaled/alphabet_size\n",
    "\n",
    "# Set up hyperparameters (mostly defaults)\n",
    "hp_policy_type = \"MlpPolicy\"\n",
    "hp_learning_rate = 3e-4\n",
    "hp_clip_range = 0.2\n",
    "hp_batch_size = 64\n",
    "hp_n_steps=2048\n",
    "hp_seed = 42 # Not really a hyperparameter, unless we're extremely unlucky...\n",
    "hp_training_timesteps = 10_000_000\n",
    "\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=max_reward_scaled, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, callback_on_new_best=callback_on_best, verbose=1, n_eval_episodes=20, deterministic=False)\n",
    "permutation_metrics_callback = PermutationLogCallback()\n",
    "callback_list = CallbackList([eval_callback, permutation_metrics_callback])\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"alphabet_size\", alphabet_size)\n",
    "\n",
    "    mlflow.log_param(\"policy_type\", hp_policy_type)\n",
    "    mlflow.log_param(\"learning_rate\", hp_learning_rate)\n",
    "    mlflow.log_param(\"clip_range\", hp_clip_range)\n",
    "    mlflow.log_param(\"batch_size\", hp_batch_size)\n",
    "    mlflow.log_param(\"n_steps\", hp_n_steps)\n",
    "    mlflow.log_param(\"seed\", hp_seed)\n",
    "    mlflow.log_param(\"training_timesteps\", hp_training_timesteps)\n",
    "\n",
    "    model = PPO(hp_policy_type,\n",
    "                vec_env,\n",
    "                verbose=1,\n",
    "                batch_size=hp_batch_size,\n",
    "                clip_range=hp_clip_range,\n",
    "                seed=hp_seed,\n",
    "                n_steps=hp_n_steps,\n",
    "                learning_rate=hp_learning_rate)\n",
    "    # Set custom logger\n",
    "    model.set_logger(loggers)\n",
    "    model.learn(int(hp_training_timesteps), callback=callback_list)"
   ],
   "id": "ae45cbcc4c940b00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 34                                   |\n",
      "|    ep_rew_mean                  | -11.2                                |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 2 1 3 1 2 3 4 1 2 3 1 2 4 3 1 2... |\n",
      "|    best_superpermutation_length | 40                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 6912                                 |\n",
      "|    iterations                   | 1                                    |\n",
      "|    time_elapsed                 | 4                                    |\n",
      "|    total_timesteps              | 32768                                |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 33.7                                 |\n",
      "|    ep_rew_mean                  | -9.85                                |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 2 1 3 1 2 3 4 1 2 3 1 2 4 3 1 2... |\n",
      "|    best_superpermutation_length | 40                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 2599                                 |\n",
      "|    iterations                   | 2                                    |\n",
      "|    time_elapsed                 | 25                                   |\n",
      "|    total_timesteps              | 65536                                |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.014637911                          |\n",
      "|    clip_fraction                | 0.165                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -3.17                                |\n",
      "|    explained_variance           | 0.0588                               |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 1.83                                 |\n",
      "|    n_updates                    | 10                                   |\n",
      "|    policy_gradient_loss         | -0.0197                              |\n",
      "|    value_loss                   | 4.35                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 32.9                                 |\n",
      "|    ep_rew_mean                  | -8.18                                |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 1 2 4 3 1 3 2 4 1 3 4... |\n",
      "|    best_superpermutation_length | 37                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 2166                                 |\n",
      "|    iterations                   | 3                                    |\n",
      "|    time_elapsed                 | 45                                   |\n",
      "|    total_timesteps              | 98304                                |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.016272891                          |\n",
      "|    clip_fraction                | 0.212                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -3.14                                |\n",
      "|    explained_variance           | 0.352                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 1.97                                 |\n",
      "|    n_updates                    | 20                                   |\n",
      "|    policy_gradient_loss         | -0.028                               |\n",
      "|    value_loss                   | 5.42                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 30.4                                 |\n",
      "|    ep_rew_mean                  | -4.77                                |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 1 2 4 3 1 3 2 4 1 3 4... |\n",
      "|    best_superpermutation_length | 37                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 2008                                 |\n",
      "|    iterations                   | 4                                    |\n",
      "|    time_elapsed                 | 65                                   |\n",
      "|    total_timesteps              | 131072                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.017884346                          |\n",
      "|    clip_fraction                | 0.236                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -3.09                                |\n",
      "|    explained_variance           | 0.292                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 4.99                                 |\n",
      "|    n_updates                    | 30                                   |\n",
      "|    policy_gradient_loss         | -0.0313                              |\n",
      "|    value_loss                   | 9.21                                 |\n",
      "--------------------------------------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-4.59 +/- 4.93\n",
      "Episode length: 30.45 +/- 4.47\n",
      "--------------------------------------------------------------------------\n",
      "| eval/                           |                                      |\n",
      "|    mean_ep_length               | 30.4                                 |\n",
      "|    mean_reward                  | -4.59                                |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 1 2 4 3 1 3 2 4 1 3 4... |\n",
      "|    best_superpermutation_length | 37                                   |\n",
      "| time/                           |                                      |\n",
      "|    total_timesteps              | 160000                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.01732824                           |\n",
      "|    clip_fraction                | 0.231                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -3.02                                |\n",
      "|    explained_variance           | 0.206                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 6.87                                 |\n",
      "|    n_updates                    | 40                                   |\n",
      "|    policy_gradient_loss         | -0.0316                              |\n",
      "|    value_loss                   | 16.6                                 |\n",
      "--------------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 28.9                                 |\n",
      "|    ep_rew_mean                  | -2.75                                |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 1 2 4 3 1 3 2 4 1 3 4... |\n",
      "|    best_superpermutation_length | 37                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1903                                 |\n",
      "|    iterations                   | 5                                    |\n",
      "|    time_elapsed                 | 86                                   |\n",
      "|    total_timesteps              | 163840                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 25.6                                 |\n",
      "|    ep_rew_mean                  | 0.94                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1833                                 |\n",
      "|    iterations                   | 6                                    |\n",
      "|    time_elapsed                 | 107                                  |\n",
      "|    total_timesteps              | 196608                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.019357726                          |\n",
      "|    clip_fraction                | 0.275                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2.93                                |\n",
      "|    explained_variance           | 0.146                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 6.92                                 |\n",
      "|    n_updates                    | 50                                   |\n",
      "|    policy_gradient_loss         | -0.0346                              |\n",
      "|    value_loss                   | 17.9                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 22.4                                 |\n",
      "|    ep_rew_mean                  | 4.19                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1794                                 |\n",
      "|    iterations                   | 7                                    |\n",
      "|    time_elapsed                 | 127                                  |\n",
      "|    total_timesteps              | 229376                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.025191145                          |\n",
      "|    clip_fraction                | 0.355                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2.79                                |\n",
      "|    explained_variance           | 0.143                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 5.97                                 |\n",
      "|    n_updates                    | 60                                   |\n",
      "|    policy_gradient_loss         | -0.043                               |\n",
      "|    value_loss                   | 12.2                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 20                                   |\n",
      "|    ep_rew_mean                  | 6.61                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1780                                 |\n",
      "|    iterations                   | 8                                    |\n",
      "|    time_elapsed                 | 147                                  |\n",
      "|    total_timesteps              | 262144                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.029870633                          |\n",
      "|    clip_fraction                | 0.402                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2.64                                |\n",
      "|    explained_variance           | 0.197                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 2.29                                 |\n",
      "|    n_updates                    | 70                                   |\n",
      "|    policy_gradient_loss         | -0.0449                              |\n",
      "|    value_loss                   | 6.58                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 18.5                                 |\n",
      "|    ep_rew_mean                  | 8.35                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1771                                 |\n",
      "|    iterations                   | 9                                    |\n",
      "|    time_elapsed                 | 166                                  |\n",
      "|    total_timesteps              | 294912                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.02347806                           |\n",
      "|    clip_fraction                | 0.332                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2.52                                |\n",
      "|    explained_variance           | 0.377                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 1.48                                 |\n",
      "|    n_updates                    | 80                                   |\n",
      "|    policy_gradient_loss         | -0.0362                              |\n",
      "|    value_loss                   | 3.61                                 |\n",
      "--------------------------------------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=9.06 +/- 1.74\n",
      "Episode length: 17.80 +/- 2.09\n",
      "--------------------------------------------------------------------------\n",
      "| eval/                           |                                      |\n",
      "|    mean_ep_length               | 17.8                                 |\n",
      "|    mean_reward                  | 9.06                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    total_timesteps              | 320000                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.025721475                          |\n",
      "|    clip_fraction                | 0.317                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2.38                                |\n",
      "|    explained_variance           | 0.642                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.936                                |\n",
      "|    n_updates                    | 90                                   |\n",
      "|    policy_gradient_loss         | -0.0354                              |\n",
      "|    value_loss                   | 2.56                                 |\n",
      "--------------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 17.1                                 |\n",
      "|    ep_rew_mean                  | 9.58                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1757                                 |\n",
      "|    iterations                   | 10                                   |\n",
      "|    time_elapsed                 | 186                                  |\n",
      "|    total_timesteps              | 327680                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 16.6                                 |\n",
      "|    ep_rew_mean                  | 10.3                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1750                                 |\n",
      "|    iterations                   | 11                                   |\n",
      "|    time_elapsed                 | 205                                  |\n",
      "|    total_timesteps              | 360448                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.024896117                          |\n",
      "|    clip_fraction                | 0.307                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2.27                                |\n",
      "|    explained_variance           | 0.791                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.77                                 |\n",
      "|    n_updates                    | 100                                  |\n",
      "|    policy_gradient_loss         | -0.0339                              |\n",
      "|    value_loss                   | 1.82                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 15.5                                 |\n",
      "|    ep_rew_mean                  | 11.5                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 3 2 1 4 3 2 1 3 4 2 1 3 1 2 4 3 1... |\n",
      "|    best_superpermutation_length | 34                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1739                                 |\n",
      "|    iterations                   | 12                                   |\n",
      "|    time_elapsed                 | 226                                  |\n",
      "|    total_timesteps              | 393216                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.02534927                           |\n",
      "|    clip_fraction                | 0.305                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2.14                                |\n",
      "|    explained_variance           | 0.861                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.398                                |\n",
      "|    n_updates                    | 110                                  |\n",
      "|    policy_gradient_loss         | -0.033                               |\n",
      "|    value_loss                   | 1.35                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 14.9                                 |\n",
      "|    ep_rew_mean                  | 12.1                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1728                                 |\n",
      "|    iterations                   | 13                                   |\n",
      "|    time_elapsed                 | 246                                  |\n",
      "|    total_timesteps              | 425984                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.026399553                          |\n",
      "|    clip_fraction                | 0.318                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -2                                   |\n",
      "|    explained_variance           | 0.909                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.491                                |\n",
      "|    n_updates                    | 120                                  |\n",
      "|    policy_gradient_loss         | -0.0334                              |\n",
      "|    value_loss                   | 1.09                                 |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 14.4                                 |\n",
      "|    ep_rew_mean                  | 12.8                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1722                                 |\n",
      "|    iterations                   | 14                                   |\n",
      "|    time_elapsed                 | 266                                  |\n",
      "|    total_timesteps              | 458752                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.02868746                           |\n",
      "|    clip_fraction                | 0.333                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -1.87                                |\n",
      "|    explained_variance           | 0.932                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.435                                |\n",
      "|    n_updates                    | 130                                  |\n",
      "|    policy_gradient_loss         | -0.0344                              |\n",
      "|    value_loss                   | 0.88                                 |\n",
      "--------------------------------------------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=13.70 +/- 1.54\n",
      "Episode length: 13.30 +/- 1.49\n",
      "--------------------------------------------------------------------------\n",
      "| eval/                           |                                      |\n",
      "|    mean_ep_length               | 13.3                                 |\n",
      "|    mean_reward                  | 13.7                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    total_timesteps              | 480000                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.02724561                           |\n",
      "|    clip_fraction                | 0.316                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -1.72                                |\n",
      "|    explained_variance           | 0.947                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.28                                 |\n",
      "|    n_updates                    | 140                                  |\n",
      "|    policy_gradient_loss         | -0.0304                              |\n",
      "|    value_loss                   | 0.737                                |\n",
      "--------------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 13.6                                 |\n",
      "|    ep_rew_mean                  | 13.6                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1715                                 |\n",
      "|    iterations                   | 15                                   |\n",
      "|    time_elapsed                 | 286                                  |\n",
      "|    total_timesteps              | 491520                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 13.2                                 |\n",
      "|    ep_rew_mean                  | 14                                   |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1712                                 |\n",
      "|    iterations                   | 16                                   |\n",
      "|    time_elapsed                 | 306                                  |\n",
      "|    total_timesteps              | 524288                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.02913398                           |\n",
      "|    clip_fraction                | 0.327                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -1.58                                |\n",
      "|    explained_variance           | 0.963                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.268                                |\n",
      "|    n_updates                    | 150                                  |\n",
      "|    policy_gradient_loss         | -0.0312                              |\n",
      "|    value_loss                   | 0.575                                |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 12.7                                 |\n",
      "|    ep_rew_mean                  | 14.4                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1707                                 |\n",
      "|    iterations                   | 17                                   |\n",
      "|    time_elapsed                 | 326                                  |\n",
      "|    total_timesteps              | 557056                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.03094914                           |\n",
      "|    clip_fraction                | 0.314                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -1.43                                |\n",
      "|    explained_variance           | 0.971                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.142                                |\n",
      "|    n_updates                    | 160                                  |\n",
      "|    policy_gradient_loss         | -0.0284                              |\n",
      "|    value_loss                   | 0.461                                |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 12                                   |\n",
      "|    ep_rew_mean                  | 14.8                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1704                                 |\n",
      "|    iterations                   | 18                                   |\n",
      "|    time_elapsed                 | 345                                  |\n",
      "|    total_timesteps              | 589824                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.03236243                           |\n",
      "|    clip_fraction                | 0.304                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -1.29                                |\n",
      "|    explained_variance           | 0.98                                 |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.167                                |\n",
      "|    n_updates                    | 170                                  |\n",
      "|    policy_gradient_loss         | -0.0252                              |\n",
      "|    value_loss                   | 0.334                                |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 12.2                                 |\n",
      "|    ep_rew_mean                  | 14.9                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1701                                 |\n",
      "|    iterations                   | 19                                   |\n",
      "|    time_elapsed                 | 365                                  |\n",
      "|    total_timesteps              | 622592                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.030455774                          |\n",
      "|    clip_fraction                | 0.291                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -1.18                                |\n",
      "|    explained_variance           | 0.987                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.186                                |\n",
      "|    n_updates                    | 180                                  |\n",
      "|    policy_gradient_loss         | -0.0216                              |\n",
      "|    value_loss                   | 0.224                                |\n",
      "--------------------------------------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=15.04 +/- 0.53\n",
      "Episode length: 12.15 +/- 1.35\n",
      "--------------------------------------------------------------------------\n",
      "| eval/                           |                                      |\n",
      "|    mean_ep_length               | 12.2                                 |\n",
      "|    mean_reward                  | 15                                   |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    total_timesteps              | 640000                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.031558745                          |\n",
      "|    clip_fraction                | 0.275                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -1.07                                |\n",
      "|    explained_variance           | 0.989                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.0612                               |\n",
      "|    n_updates                    | 190                                  |\n",
      "|    policy_gradient_loss         | -0.02                                |\n",
      "|    value_loss                   | 0.193                                |\n",
      "--------------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 11.8                                 |\n",
      "|    ep_rew_mean                  | 15.1                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1696                                 |\n",
      "|    iterations                   | 20                                   |\n",
      "|    time_elapsed                 | 386                                  |\n",
      "|    total_timesteps              | 655360                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 11.5                                 |\n",
      "|    ep_rew_mean                  | 15.3                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1694                                 |\n",
      "|    iterations                   | 21                                   |\n",
      "|    time_elapsed                 | 406                                  |\n",
      "|    total_timesteps              | 688128                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.031824347                          |\n",
      "|    clip_fraction                | 0.279                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.964                               |\n",
      "|    explained_variance           | 0.992                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | -0.0174                              |\n",
      "|    n_updates                    | 200                                  |\n",
      "|    policy_gradient_loss         | -0.0196                              |\n",
      "|    value_loss                   | 0.134                                |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 11.1                                 |\n",
      "|    ep_rew_mean                  | 15.4                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1688                                 |\n",
      "|    iterations                   | 22                                   |\n",
      "|    time_elapsed                 | 426                                  |\n",
      "|    total_timesteps              | 720896                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.035083674                          |\n",
      "|    clip_fraction                | 0.283                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.851                               |\n",
      "|    explained_variance           | 0.995                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.00353                              |\n",
      "|    n_updates                    | 210                                  |\n",
      "|    policy_gradient_loss         | -0.0212                              |\n",
      "|    value_loss                   | 0.0975                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.9                                 |\n",
      "|    ep_rew_mean                  | 15.6                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1685                                 |\n",
      "|    iterations                   | 23                                   |\n",
      "|    time_elapsed                 | 447                                  |\n",
      "|    total_timesteps              | 753664                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.041663796                          |\n",
      "|    clip_fraction                | 0.259                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.73                                |\n",
      "|    explained_variance           | 0.996                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.0558                               |\n",
      "|    n_updates                    | 220                                  |\n",
      "|    policy_gradient_loss         | -0.022                               |\n",
      "|    value_loss                   | 0.0805                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.7                                 |\n",
      "|    ep_rew_mean                  | 15.7                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1684                                 |\n",
      "|    iterations                   | 24                                   |\n",
      "|    time_elapsed                 | 466                                  |\n",
      "|    total_timesteps              | 786432                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.042827338                          |\n",
      "|    clip_fraction                | 0.23                                 |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.631                               |\n",
      "|    explained_variance           | 0.997                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | -0.015                               |\n",
      "|    n_updates                    | 230                                  |\n",
      "|    policy_gradient_loss         | -0.0151                              |\n",
      "|    value_loss                   | 0.0541                               |\n",
      "--------------------------------------------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=15.60 +/- 0.36\n",
      "Episode length: 10.75 +/- 0.89\n",
      "--------------------------------------------------------------------------\n",
      "| eval/                           |                                      |\n",
      "|    mean_ep_length               | 10.8                                 |\n",
      "|    mean_reward                  | 15.6                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    total_timesteps              | 800000                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.03851141                           |\n",
      "|    clip_fraction                | 0.235                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.565                               |\n",
      "|    explained_variance           | 0.998                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | -0.00897                             |\n",
      "|    n_updates                    | 240                                  |\n",
      "|    policy_gradient_loss         | -0.0146                              |\n",
      "|    value_loss                   | 0.0321                               |\n",
      "--------------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.7                                 |\n",
      "|    ep_rew_mean                  | 15.7                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1680                                 |\n",
      "|    iterations                   | 25                                   |\n",
      "|    time_elapsed                 | 487                                  |\n",
      "|    total_timesteps              | 819200                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.4                                 |\n",
      "|    ep_rew_mean                  | 15.7                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1678                                 |\n",
      "|    iterations                   | 26                                   |\n",
      "|    time_elapsed                 | 507                                  |\n",
      "|    total_timesteps              | 851968                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.043461356                          |\n",
      "|    clip_fraction                | 0.222                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.498                               |\n",
      "|    explained_variance           | 0.996                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.0848                               |\n",
      "|    n_updates                    | 250                                  |\n",
      "|    policy_gradient_loss         | -0.0131                              |\n",
      "|    value_loss                   | 0.0734                               |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.4                                 |\n",
      "|    ep_rew_mean                  | 15.7                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1677                                 |\n",
      "|    iterations                   | 27                                   |\n",
      "|    time_elapsed                 | 527                                  |\n",
      "|    total_timesteps              | 884736                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.038233865                          |\n",
      "|    clip_fraction                | 0.212                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.472                               |\n",
      "|    explained_variance           | 0.995                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | -0.00899                             |\n",
      "|    n_updates                    | 260                                  |\n",
      "|    policy_gradient_loss         | -0.0186                              |\n",
      "|    value_loss                   | 0.085                                |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.6                                 |\n",
      "|    ep_rew_mean                  | 15.6                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1673                                 |\n",
      "|    iterations                   | 28                                   |\n",
      "|    time_elapsed                 | 548                                  |\n",
      "|    total_timesteps              | 917504                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.06459826                           |\n",
      "|    clip_fraction                | 0.195                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.398                               |\n",
      "|    explained_variance           | 0.997                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.00681                              |\n",
      "|    n_updates                    | 270                                  |\n",
      "|    policy_gradient_loss         | -0.0143                              |\n",
      "|    value_loss                   | 0.049                                |\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.4                                 |\n",
      "|    ep_rew_mean                  | 15.7                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1669                                 |\n",
      "|    iterations                   | 29                                   |\n",
      "|    time_elapsed                 | 569                                  |\n",
      "|    total_timesteps              | 950272                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.06933914                           |\n",
      "|    clip_fraction                | 0.272                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.411                               |\n",
      "|    explained_variance           | 0.997                                |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | -0.0191                              |\n",
      "|    n_updates                    | 280                                  |\n",
      "|    policy_gradient_loss         | -0.015                               |\n",
      "|    value_loss                   | 0.0598                               |\n",
      "--------------------------------------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=15.71 +/- 0.16\n",
      "Episode length: 10.20 +/- 0.51\n",
      "--------------------------------------------------------------------------\n",
      "| eval/                           |                                      |\n",
      "|    mean_ep_length               | 10.2                                 |\n",
      "|    mean_reward                  | 15.7                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    total_timesteps              | 960000                               |\n",
      "| train/                          |                                      |\n",
      "|    approx_kl                    | 0.06430506                           |\n",
      "|    clip_fraction                | 0.228                                |\n",
      "|    clip_range                   | 0.2                                  |\n",
      "|    entropy_loss                 | -0.404                               |\n",
      "|    explained_variance           | 0.99                                 |\n",
      "|    learning_rate                | 0.0003                               |\n",
      "|    loss                         | 0.0256                               |\n",
      "|    n_updates                    | 290                                  |\n",
      "|    policy_gradient_loss         | -0.018                               |\n",
      "|    value_loss                   | 0.152                                |\n",
      "--------------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------------------------------------------------\n",
      "| rollout/                        |                                      |\n",
      "|    ep_len_mean                  | 10.3                                 |\n",
      "|    ep_rew_mean                  | 15.6                                 |\n",
      "| superpermutation/               |                                      |\n",
      "|    best_superpermutation        | 4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3... |\n",
      "|    best_superpermutation_length | 33                                   |\n",
      "| time/                           |                                      |\n",
      "|    fps                          | 1667                                 |\n",
      "|    iterations                   | 30                                   |\n",
      "|    time_elapsed                 | 589                                  |\n",
      "|    total_timesteps              | 983040                               |\n",
      "--------------------------------------------------------------------------\n",
      "🏃 View run marvelous-snail-72 at: http://127.0.0.1:8080/#/experiments/0/runs/6f1cb75ea4064e62936a37f15e118fd4\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 48\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Set custom logger\u001B[39;00m\n\u001B[0;32m     47\u001B[0m model\u001B[38;5;241m.\u001B[39mset_logger(loggers)\n\u001B[1;32m---> 48\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhp_training_timesteps\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001B[0m, in \u001B[0;36mPPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    303\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfPPO,\n\u001B[0;32m    304\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    309\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    310\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfPPO:\n\u001B[1;32m--> 311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:336\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    333\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mep_info_buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    334\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dump_logs(iteration)\n\u001B[1;32m--> 336\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    338\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_end()\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:278\u001B[0m, in \u001B[0;36mPPO.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;66;03m# Clip grad norm\u001B[39;00m\n\u001B[0;32m    277\u001B[0m     th\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_grad_norm)\n\u001B[1;32m--> 278\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_updates \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m continue_training:\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    482\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    483\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    484\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    485\u001B[0m             )\n\u001B[1;32m--> 487\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    490\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    211\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    213\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    214\u001B[0m         group,\n\u001B[0;32m    215\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    220\u001B[0m         state_steps,\n\u001B[0;32m    221\u001B[0m     )\n\u001B[1;32m--> 223\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:784\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    782\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 784\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    786\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    803\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:430\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    428\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    429\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 430\u001B[0m         denom \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbias_correction2_sqrt\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    432\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[0;32m    434\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model actually finds the optimal solution fairly quickly but it takes a while for early stopping to kick in since it doesn't find it reliably (we store it anyway so the training can be cancelled manually once we see that the solution is good enough)",
   "id": "70593b2283ed650e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:59:52.496947Z",
     "start_time": "2025-06-18T18:59:52.491778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(permutation_metrics_callback.best_permutation_length)\n",
    "print(permutation_metrics_callback.best_permutation)"
   ],
   "id": "a4da3faf20f92106",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3 4 2 1 3 4 2 3 1 4 2 3 4 1 2 3 4\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The RL agent found the following superpermutation:\n",
    "4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3 4 2 1 3 4 2 3 1 4 2 3 4 1 2 3 4\n",
    "\n",
    "We can check if it's the same (up to relabelling) as the shortest superpermutation shown on Wikipedia:"
   ],
   "id": "3b6d93f90c007b2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T19:01:08.789147Z",
     "start_time": "2025-06-18T19:01:08.782754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import permutation_utils\n",
    "found = [int(i) for i in \"4 3 2 1 4 3 2 4 1 3 2 4 3 1 2 4 3 4 2 1 3 4 2 3 1 4 2 3 4 1 2 3 4\".split(\" \")]\n",
    "shortest_superpermutation = [int(i) for i in \"123412314231243121342132413214321\"]\n",
    "relabellings_list = permutation_utils.get_possible_relabellings(shortest_superpermutation, [1,2,3,4])\n",
    "print(found in relabellings_list)"
   ],
   "id": "bc062972a7e6e1ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Calculating the maximum possible reward for an episode\n",
    "\n",
    "Assume that n is the size of the alphabet. Let us call the superpermutation formed by appending every possible permutation a \"naive superpermutation\".\n",
    "\n",
    "Since there are n! possible permutations, each having length n and every one has to be included, the naive superpermutation has length n!*n.\n",
    "\n",
    "The rewards in the environment are formed in such a way that the model gets 1 point for each character \"saved\" compared to this naive superpermutation. That is, if merging two permutations that have 2 overlapping characters, we get 2 points. If by merging we also added another permutation (other than the two we merged), we additionally reward the model with n points.\n",
    "\n",
    "Thus the cumulative reward for an episode is (aside from penalties for picking already added permutations) equal to (n!*n)-(length of the superpermutation created by the model).\n",
    "\n",
    "So the length of the superpermutation created by the model is at most (n!*n)-(sum of cumulative rewards for the episode)\n",
    "\n",
    "For n=4, this is (4!*4)-(sum of cumulative rewards for the episode).\n",
    "\n",
    "33 = 96-reward-->reward=63"
   ],
   "id": "1421099d78f83d81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de1e39f56433cfa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
