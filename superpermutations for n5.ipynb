{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Finding short superpermutations for n=5",
   "id": "6ee96f072b92992a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T10:59:39.196358Z",
     "start_time": "2025-06-18T10:59:23.188492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from GymPermutationsEnv import GymPermutationEnv"
   ],
   "id": "101919a42f0bfc35",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T10:59:45.338491Z",
     "start_time": "2025-06-18T10:59:45.334968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import permutation_utils\n",
    "\n",
    "alphabet_size = 5\n",
    "\n",
    "max_reward_unscaled = permutation_utils.get_max_possible_reward(5, 153)\n",
    "max_reward_scaled = max_reward_unscaled/alphabet_size"
   ],
   "id": "7c1aec3f4c829386",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T10:59:45.370615Z",
     "start_time": "2025-06-18T10:59:45.365752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "math.factorial(alphabet_size)*alphabet_size"
   ],
   "id": "1873d76c90b9d298",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T10:59:50.868026Z",
     "start_time": "2025-06-18T10:59:45.387666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.logger import HumanOutputFormat, KVWriter, Logger\n",
    "\n",
    "class MLflowOutputFormat(KVWriter):\n",
    "    \"\"\"\n",
    "    Dumps key/value pairs into MLflow's numeric format.\n",
    "    \"\"\"\n",
    "\n",
    "    def write(\n",
    "        self,\n",
    "        key_values: Dict[str, Any],\n",
    "        key_excluded: Dict[str, Union[str, Tuple[str, ...]]],\n",
    "        step: int = 0,\n",
    "    ) -> None:\n",
    "\n",
    "        for (key, value), (_, excluded) in zip(\n",
    "            sorted(key_values.items()), sorted(key_excluded.items())\n",
    "        ):\n",
    "\n",
    "            if excluded is not None and \"mlflow\" in excluded:\n",
    "                continue\n",
    "\n",
    "            if isinstance(value, np.ScalarType):\n",
    "                if not isinstance(value, str):\n",
    "                    mlflow.log_metric(key, value, step)\n",
    "\n",
    "\n",
    "loggers = Logger(\n",
    "    folder=None,\n",
    "    output_formats=[HumanOutputFormat(sys.stdout), MLflowOutputFormat()],\n",
    ")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ],
   "id": "d1e08f67d1849458",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T11:32:14.994621Z",
     "start_time": "2025-06-18T11:32:14.987994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "\n",
    "class PermutationLogCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.best_permutation = []\n",
    "        self.best_permutation_length=-1\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for _info in infos:\n",
    "            if \"superpermutation\" in _info and \"superpermutation_length\" in _info:\n",
    "                if self.best_permutation_length==-1 or (_info[\"superpermutation_length\"] < self.best_permutation_length):\n",
    "                    self.best_permutation_length = _info[\"superpermutation_length\"]\n",
    "                    self.best_permutation = \" \".join([str(i) for i in _info[\"superpermutation\"]])\n",
    "                self.logger.record(\"superpermutation/best_superpermutation_length\", self.best_permutation_length)\n",
    "                self.logger.record(\"superpermutation/best_superpermutation\", self.best_permutation)\n",
    "        return True\n"
   ],
   "id": "b3ed3e46d7267b1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*The logs from the run below are from before I fixed a typo, permutation-->superpermutation*",
   "id": "c1ee5e90827a2f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:18:45.747173Z",
     "start_time": "2025-06-18T11:32:17.061032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate the env\n",
    "vec_env = make_vec_env(GymPermutationEnv, n_envs=16, env_kwargs=dict(alphabet_size=alphabet_size), vec_env_cls=SubprocVecEnv)\n",
    "eval_env = make_vec_env(GymPermutationEnv, env_kwargs=dict(alphabet_size=alphabet_size), vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "# Set up hyperparameters\n",
    "# More conservative settings to counter policy collapse\n",
    "hp_policy_type = \"MlpPolicy\"\n",
    "hp_learning_rate = 5e-5\n",
    "hp_clip_range = 0.1\n",
    "hp_batch_size = 128\n",
    "hp_n_steps=4096\n",
    "hp_seed = 42 # Not really a hyperparameter, unless we're extremely unlucky...\n",
    "hp_training_timesteps = 2e8\n",
    "\n",
    "# Train the agent\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=max_reward_scaled, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, callback_on_new_best=callback_on_best, verbose=1, n_eval_episodes=20, deterministic=False)\n",
    "permutation_metrics_callback = PermutationLogCallback()\n",
    "callback_list = CallbackList([eval_callback, permutation_metrics_callback])\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"alphabet_size\", alphabet_size)\n",
    "\n",
    "    mlflow.log_param(\"policy_type\", hp_policy_type)\n",
    "    mlflow.log_param(\"learning_rate\", hp_learning_rate)\n",
    "    mlflow.log_param(\"clip_range\", hp_clip_range)\n",
    "    mlflow.log_param(\"batch_size\", hp_batch_size)\n",
    "    mlflow.log_param(\"n_steps\", hp_n_steps)\n",
    "    mlflow.log_param(\"seed\", hp_seed)\n",
    "    mlflow.log_param(\"training_timesteps\", hp_training_timesteps)\n",
    "\n",
    "    model = PPO(hp_policy_type,\n",
    "                vec_env,\n",
    "                verbose=1,\n",
    "                batch_size=hp_batch_size,\n",
    "                clip_range=hp_clip_range,\n",
    "                seed=hp_seed,\n",
    "                n_steps=hp_n_steps,\n",
    "                learning_rate=hp_learning_rate)\n",
    "    # Set custom logger\n",
    "    model.set_logger(loggers)\n",
    "    model.learn(int(hp_training_timesteps), callback=callback_list)\n"
   ],
   "id": "d1cc6314d1adcaf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -48.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 2092     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 65536    |\n",
      "| train/             |          |\n",
      "|    learning_rate   | 5e-05    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -48.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1273         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024733394 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.79        |\n",
      "|    explained_variance   | -0.0165      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 2.47         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 7.47         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-49.80 +/- 4.92\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -49.8        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019656604 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 2.23         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    value_loss           | 6.81         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -47.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 1057     |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -47.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1021         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019468269 |\n",
      "|    clip_fraction        | 0.0435       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.97         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    value_loss           | 5.12         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-47.67 +/- 3.90\n",
      "Episode length: 154.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 154         |\n",
      "|    mean_reward          | -47.7       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001965187 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 4.4         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -46.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 963      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 327680   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -46.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 954          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 411          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020719806 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 2.19         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 4.23         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -45.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 946          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 484          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020987373 |\n",
      "|    clip_fraction        | 0.0552       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.77        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 3.9          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-45.57 +/- 3.79\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -45.6        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022045441 |\n",
      "|    clip_fraction        | 0.0628       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.77        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -45.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 921      |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 569      |\n",
      "|    total_timesteps | 524288   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -44.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 919          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 641          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023638408 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.76        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-43.33 +/- 2.95\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -43.3        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023484754 |\n",
      "|    clip_fraction        | 0.0711       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.76        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    value_loss           | 3.53         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -44.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 726      |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -43.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 905          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 796          |\n",
      "|    total_timesteps      | 720896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024585242 |\n",
      "|    clip_fraction        | 0.0831       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.75        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 3.27         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -42.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 906          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 867          |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025274816 |\n",
      "|    clip_fraction        | 0.0877       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.74        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    value_loss           | 3.19         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-41.16 +/- 3.03\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -41.2        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025216585 |\n",
      "|    clip_fraction        | 0.087        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.74        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -42.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 892      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 954      |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 154         |\n",
      "|    ep_rew_mean          | -42.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 893         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1027        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002629093 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.972       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=-42.09 +/- 3.67\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -42.1        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027321314 |\n",
      "|    clip_fraction        | 0.0998       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.72        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -41.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 885      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 1110     |\n",
      "|    total_timesteps | 983040   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -41.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1181         |\n",
      "|    total_timesteps      | 1048576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027795248 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    value_loss           | 2.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -40.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 1251         |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028056693 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    value_loss           | 2.4          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=-39.76 +/- 3.94\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -39.8        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028780717 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.69        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    value_loss           | 2.3          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -40.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 882      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 1336     |\n",
      "|    total_timesteps | 1179648  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -39.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 882          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 1411         |\n",
      "|    total_timesteps      | 1245184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029132995 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.68        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.888        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 2.17         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=-38.82 +/- 2.32\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -38.8        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030251774 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.763        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 2.05         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -39.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 876      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 1496     |\n",
      "|    total_timesteps | 1310720  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -39.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 878          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1566         |\n",
      "|    total_timesteps      | 1376256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030515655 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.732        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=-37.81 +/- 3.52\n",
      "Episode length: 154.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | -37.8        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031351536 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.65        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.693        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 1.87         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -38.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 871      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 1653     |\n",
      "|    total_timesteps | 1441792  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -38.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 871          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 1730         |\n",
      "|    total_timesteps      | 1507328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031306813 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.787        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -37.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 871          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1804         |\n",
      "|    total_timesteps      | 1572864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032000039 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.63        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.734        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=-37.32 +/- 4.24\n",
      "Episode length: 154.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 154         |\n",
      "|    mean_reward          | -37.3       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003308164 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.708       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -37.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 866      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1891     |\n",
      "|    total_timesteps | 1638400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 154         |\n",
      "|    ep_rew_mean          | -37         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 867         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1964        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003365953 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.642       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=-36.26 +/- 3.06\n",
      "Episode length: 154.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 154         |\n",
      "|    mean_reward          | -36.3       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003378674 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.649       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -36.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 862      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 2052     |\n",
      "|    total_timesteps | 1769472  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | -35.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 863          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 2126         |\n",
      "|    total_timesteps      | 1835008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034703896 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.59        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.689        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 5 3 2 4 5 3 4 2 1 4 5 1 3 2 3 4... |\n",
      "|    best_permutation_length | 368                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -36.7                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 864                                  |\n",
      "|    iterations              | 29                                   |\n",
      "|    time_elapsed            | 2199                                 |\n",
      "|    total_timesteps         | 1900544                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0035383906                         |\n",
      "|    clip_fraction           | 0.154                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.57                                |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.659                                |\n",
      "|    n_updates               | 280                                  |\n",
      "|    policy_gradient_loss    | -0.0139                              |\n",
      "|    value_loss              | 1.48                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=-35.38 +/- 4.24\n",
      "Episode length: 153.95 +/- 0.22\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 154                                  |\n",
      "|    mean_reward             | -35.4                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 5 3 1 4 2 3 5 1 2 4 2 3 4 5... |\n",
      "|    best_permutation_length | 349                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 1920000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0035043191                         |\n",
      "|    clip_fraction           | 0.156                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.56                                |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.548                                |\n",
      "|    n_updates               | 290                                  |\n",
      "|    policy_gradient_loss    | -0.0136                              |\n",
      "|    value_loss              | 2.07                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 5 3 1 4 2 3 5 1 2 4 2 3 4 5... |\n",
      "|    best_permutation_length | 349                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -35.4                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 30                                   |\n",
      "|    time_elapsed            | 2283                                 |\n",
      "|    total_timesteps         | 1966080                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 5 3 1 4 2 3 5 1 2 4 2 3 4 5... |\n",
      "|    best_permutation_length | 349                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -34.9                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 31                                   |\n",
      "|    time_elapsed            | 2356                                 |\n",
      "|    total_timesteps         | 2031616                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0033709211                         |\n",
      "|    clip_fraction           | 0.154                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.55                                |\n",
      "|    explained_variance      | 0.98                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 12.7                                 |\n",
      "|    n_updates               | 300                                  |\n",
      "|    policy_gradient_loss    | -0.0115                              |\n",
      "|    value_loss              | 4.6                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=-34.33 +/- 3.38\n",
      "Episode length: 154.00 +/- 0.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 154                                  |\n",
      "|    mean_reward             | -34.3                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 3 4 2 5 3 1 4 2 4 3 1 5 2 5 4 3... |\n",
      "|    best_permutation_length | 342                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 2080000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0036635213                         |\n",
      "|    clip_fraction           | 0.164                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.54                                |\n",
      "|    explained_variance      | 0.986                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.724                                |\n",
      "|    n_updates               | 310                                  |\n",
      "|    policy_gradient_loss    | -0.013                               |\n",
      "|    value_loss              | 3.33                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -34.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 858      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 2443     |\n",
      "|    total_timesteps | 2097152  |\n",
      "---------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 3 4 2 5 3 1 4 2 4 3 1 5 2 5 4 3... |\n",
      "|    best_permutation_length | 342                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -34.4                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 33                                   |\n",
      "|    time_elapsed            | 2514                                 |\n",
      "|    total_timesteps         | 2162688                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.003643826                          |\n",
      "|    clip_fraction           | 0.166                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.53                                |\n",
      "|    explained_variance      | 0.991                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.66                                 |\n",
      "|    n_updates               | 320                                  |\n",
      "|    policy_gradient_loss    | -0.0139                              |\n",
      "|    value_loss              | 2.12                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 3 4 2 5 3 1 4 2 4 3 1 5 2 5 4 3... |\n",
      "|    best_permutation_length | 342                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -34.1                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 34                                   |\n",
      "|    time_elapsed            | 2584                                 |\n",
      "|    total_timesteps         | 2228224                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0037067365                         |\n",
      "|    clip_fraction           | 0.167                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.51                                |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.607                                |\n",
      "|    n_updates               | 330                                  |\n",
      "|    policy_gradient_loss    | -0.0135                              |\n",
      "|    value_loss              | 2.1                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=-33.27 +/- 4.08\n",
      "Episode length: 153.75 +/- 1.09\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 154                                  |\n",
      "|    mean_reward             | -33.3                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 3 4 2 5 3 1 4 2 4 3 1 5 2 5 4 3... |\n",
      "|    best_permutation_length | 342                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 2240000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0036482317                         |\n",
      "|    clip_fraction           | 0.168                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.5                                 |\n",
      "|    explained_variance      | 0.984                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.02                                 |\n",
      "|    n_updates               | 340                                  |\n",
      "|    policy_gradient_loss    | -0.0119                              |\n",
      "|    value_loss              | 3.96                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 3 4 2 5 3 1 4 2 4 3 1 5 2 5 4 3... |\n",
      "|    best_permutation_length | 342                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -34                                  |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 859                                  |\n",
      "|    iterations              | 35                                   |\n",
      "|    time_elapsed            | 2667                                 |\n",
      "|    total_timesteps         | 2293760                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 2 1 4 2 3 5 4 1 2 4 5 3 1 2 5... |\n",
      "|    best_permutation_length | 330                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -33.9                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 36                                   |\n",
      "|    time_elapsed            | 2738                                 |\n",
      "|    total_timesteps         | 2359296                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0035308667                         |\n",
      "|    clip_fraction           | 0.162                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.49                                |\n",
      "|    explained_variance      | 0.968                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.23                                 |\n",
      "|    n_updates               | 350                                  |\n",
      "|    policy_gradient_loss    | -0.00915                             |\n",
      "|    value_loss              | 7.61                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=-34.49 +/- 3.29\n",
      "Episode length: 154.00 +/- 0.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 154                                  |\n",
      "|    mean_reward             | -34.5                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 2 1 4 2 3 5 4 1 2 4 5 3 1 2 5... |\n",
      "|    best_permutation_length | 330                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 2400000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0037700194                         |\n",
      "|    clip_fraction           | 0.176                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.48                                |\n",
      "|    explained_variance      | 0.969                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.62                                 |\n",
      "|    n_updates               | 360                                  |\n",
      "|    policy_gradient_loss    | -0.00894                             |\n",
      "|    value_loss              | 7.13                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 2 1 4 2 3 5 4 1 2 4 5 3 1 2 5... |\n",
      "|    best_permutation_length | 330                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -33.6                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 859                                  |\n",
      "|    iterations              | 37                                   |\n",
      "|    time_elapsed            | 2820                                 |\n",
      "|    total_timesteps         | 2424832                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 3 4 1 2 3 5 4 1 5 2 4 3 1 2 5 4... |\n",
      "|    best_permutation_length | 329                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -33.2                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 38                                   |\n",
      "|    time_elapsed            | 2892                                 |\n",
      "|    total_timesteps         | 2490368                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0036892942                         |\n",
      "|    clip_fraction           | 0.182                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.47                                |\n",
      "|    explained_variance      | 0.968                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 7.27                                 |\n",
      "|    n_updates               | 370                                  |\n",
      "|    policy_gradient_loss    | -0.00917                             |\n",
      "|    value_loss              | 6.94                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 3 4 1 2 3 5 4 1 5 2 4 3 1 2 5 4... |\n",
      "|    best_permutation_length | 329                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -32.5                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 39                                   |\n",
      "|    time_elapsed            | 2962                                 |\n",
      "|    total_timesteps         | 2555904                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0035937915                         |\n",
      "|    clip_fraction           | 0.173                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.46                                |\n",
      "|    explained_variance      | 0.954                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.05                                 |\n",
      "|    n_updates               | 380                                  |\n",
      "|    policy_gradient_loss    | -0.00641                             |\n",
      "|    value_loss              | 9.05                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=-34.39 +/- 5.12\n",
      "Episode length: 153.65 +/- 1.53\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 154                                  |\n",
      "|    mean_reward             | -34.4                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 3 4 1 2 3 5 4 1 5 2 4 3 1 2 5 4... |\n",
      "|    best_permutation_length | 329                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 2560000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0036952                            |\n",
      "|    clip_fraction           | 0.183                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.45                                |\n",
      "|    explained_variance      | 0.952                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5                                    |\n",
      "|    n_updates               | 390                                  |\n",
      "|    policy_gradient_loss    | -0.00777                             |\n",
      "|    value_loss              | 9.19                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 153                                  |\n",
      "|    ep_rew_mean             | -32.2                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 40                                   |\n",
      "|    time_elapsed            | 3046                                 |\n",
      "|    total_timesteps         | 2621440                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -32.4                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 41                                   |\n",
      "|    time_elapsed            | 3116                                 |\n",
      "|    total_timesteps         | 2686976                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0035073925                         |\n",
      "|    clip_fraction           | 0.178                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.44                                |\n",
      "|    explained_variance      | 0.94                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.88                                 |\n",
      "|    n_updates               | 400                                  |\n",
      "|    policy_gradient_loss    | -0.00778                             |\n",
      "|    value_loss              | 11                                   |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=-31.18 +/- 6.11\n",
      "Episode length: 153.10 +/- 3.92\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 153                                  |\n",
      "|    mean_reward             | -31.2                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 2720000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0038235555                         |\n",
      "|    clip_fraction           | 0.192                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.43                                |\n",
      "|    explained_variance      | 0.941                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.98                                 |\n",
      "|    n_updates               | 410                                  |\n",
      "|    policy_gradient_loss    | -0.00859                             |\n",
      "|    value_loss              | 9.76                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 153                                  |\n",
      "|    ep_rew_mean             | -31.6                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 859                                  |\n",
      "|    iterations              | 42                                   |\n",
      "|    time_elapsed            | 3202                                 |\n",
      "|    total_timesteps         | 2752512                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 154                                  |\n",
      "|    ep_rew_mean             | -32.6                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 43                                   |\n",
      "|    time_elapsed            | 3274                                 |\n",
      "|    total_timesteps         | 2818048                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00370397                           |\n",
      "|    clip_fraction           | 0.177                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.42                                |\n",
      "|    explained_variance      | 0.919                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.48                                 |\n",
      "|    n_updates               | 420                                  |\n",
      "|    policy_gradient_loss    | -0.00856                             |\n",
      "|    value_loss              | 11.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=-31.94 +/- 6.64\n",
      "Episode length: 153.05 +/- 4.14\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 153                                  |\n",
      "|    mean_reward             | -31.9                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 2880000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0038025635                         |\n",
      "|    clip_fraction           | 0.183                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.41                                |\n",
      "|    explained_variance      | 0.919                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.55                                 |\n",
      "|    n_updates               | 430                                  |\n",
      "|    policy_gradient_loss    | -0.00977                             |\n",
      "|    value_loss              | 11.8                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 153                                  |\n",
      "|    ep_rew_mean             | -30.5                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 858                                  |\n",
      "|    iterations              | 44                                   |\n",
      "|    time_elapsed            | 3358                                 |\n",
      "|    total_timesteps         | 2883584                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 153                                  |\n",
      "|    ep_rew_mean             | -31                                  |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 859                                  |\n",
      "|    iterations              | 45                                   |\n",
      "|    time_elapsed            | 3430                                 |\n",
      "|    total_timesteps         | 2949120                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0037950561                         |\n",
      "|    clip_fraction           | 0.184                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.4                                 |\n",
      "|    explained_variance      | 0.906                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.29                                 |\n",
      "|    n_updates               | 440                                  |\n",
      "|    policy_gradient_loss    | -0.00985                             |\n",
      "|    value_loss              | 11.8                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 152                                  |\n",
      "|    ep_rew_mean             | -29.9                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 46                                   |\n",
      "|    time_elapsed            | 3501                                 |\n",
      "|    total_timesteps         | 3014656                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.003997958                          |\n",
      "|    clip_fraction           | 0.19                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.39                                |\n",
      "|    explained_variance      | 0.9                                  |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 6.36                                 |\n",
      "|    n_updates               | 450                                  |\n",
      "|    policy_gradient_loss    | -0.0105                              |\n",
      "|    value_loss              | 12.2                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=3040000, episode_reward=-31.25 +/- 4.28\n",
      "Episode length: 153.75 +/- 0.77\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 154                                  |\n",
      "|    mean_reward             | -31.2                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 3040000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0040254435                         |\n",
      "|    clip_fraction           | 0.192                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.37                                |\n",
      "|    explained_variance      | 0.9                                  |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.99                                 |\n",
      "|    n_updates               | 460                                  |\n",
      "|    policy_gradient_loss    | -0.0113                              |\n",
      "|    value_loss              | 11.6                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 152                                  |\n",
      "|    ep_rew_mean             | -29                                  |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 858                                  |\n",
      "|    iterations              | 47                                   |\n",
      "|    time_elapsed            | 3586                                 |\n",
      "|    total_timesteps         | 3080192                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 152                                  |\n",
      "|    ep_rew_mean             | -29.7                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 48                                   |\n",
      "|    time_elapsed            | 3657                                 |\n",
      "|    total_timesteps         | 3145728                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0039873775                         |\n",
      "|    clip_fraction           | 0.192                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.36                                |\n",
      "|    explained_variance      | 0.898                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.43                                 |\n",
      "|    n_updates               | 470                                  |\n",
      "|    policy_gradient_loss    | -0.0115                              |\n",
      "|    value_loss              | 10.8                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=-29.73 +/- 7.24\n",
      "Episode length: 152.15 +/- 4.51\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 152                                  |\n",
      "|    mean_reward             | -29.7                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 3200000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0041811997                         |\n",
      "|    clip_fraction           | 0.203                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.35                                |\n",
      "|    explained_variance      | 0.903                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.72                                 |\n",
      "|    n_updates               | 480                                  |\n",
      "|    policy_gradient_loss    | -0.0122                              |\n",
      "|    value_loss              | 9.57                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 151                                  |\n",
      "|    ep_rew_mean             | -26.9                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 858                                  |\n",
      "|    iterations              | 49                                   |\n",
      "|    time_elapsed            | 3740                                 |\n",
      "|    total_timesteps         | 3211264                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 152                                  |\n",
      "|    ep_rew_mean             | -28                                  |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 859                                  |\n",
      "|    iterations              | 50                                   |\n",
      "|    time_elapsed            | 3811                                 |\n",
      "|    total_timesteps         | 3276800                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004151849                          |\n",
      "|    clip_fraction           | 0.199                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.33                                |\n",
      "|    explained_variance      | 0.898                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.31                                 |\n",
      "|    n_updates               | 490                                  |\n",
      "|    policy_gradient_loss    | -0.0119                              |\n",
      "|    value_loss              | 9.78                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 150                                  |\n",
      "|    ep_rew_mean             | -26.3                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 51                                   |\n",
      "|    time_elapsed            | 3883                                 |\n",
      "|    total_timesteps         | 3342336                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004204723                          |\n",
      "|    clip_fraction           | 0.207                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.31                                |\n",
      "|    explained_variance      | 0.898                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.54                                 |\n",
      "|    n_updates               | 500                                  |\n",
      "|    policy_gradient_loss    | -0.0128                              |\n",
      "|    value_loss              | 8.72                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=-23.75 +/- 12.10\n",
      "Episode length: 148.00 +/- 10.28\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 148                                  |\n",
      "|    mean_reward             | -23.8                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 3 5 4 1 2 4 1 5 3 2 4 3 5 1 3 5 2... |\n",
      "|    best_permutation_length | 327                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 3360000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004234163                          |\n",
      "|    clip_fraction           | 0.206                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.3                                 |\n",
      "|    explained_variance      | 0.892                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.34                                 |\n",
      "|    n_updates               | 510                                  |\n",
      "|    policy_gradient_loss    | -0.0125                              |\n",
      "|    value_loss              | 9.04                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 4 5 3 1 2 4 2 3 5 1 2 3 5 4 1 2 3... |\n",
      "|    best_permutation_length | 323                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 149                                  |\n",
      "|    ep_rew_mean             | -24.8                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 859                                  |\n",
      "|    iterations              | 52                                   |\n",
      "|    time_elapsed            | 3966                                 |\n",
      "|    total_timesteps         | 3407872                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 4 5 3 1 2 4 2 3 5 1 2 3 5 4 1 2 3... |\n",
      "|    best_permutation_length | 323                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 149                                  |\n",
      "|    ep_rew_mean             | -23.9                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 53                                   |\n",
      "|    time_elapsed            | 4036                                 |\n",
      "|    total_timesteps         | 3473408                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004404973                          |\n",
      "|    clip_fraction           | 0.214                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.28                                |\n",
      "|    explained_variance      | 0.892                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.33                                 |\n",
      "|    n_updates               | 520                                  |\n",
      "|    policy_gradient_loss    | -0.0135                              |\n",
      "|    value_loss              | 8.35                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=-22.77 +/- 11.21\n",
      "Episode length: 146.70 +/- 9.30\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 147                                  |\n",
      "|    mean_reward             | -22.8                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 4 5 3 1 2 4 2 3 5 1 2 3 5 4 1 2 3... |\n",
      "|    best_permutation_length | 323                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 3520000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0043643406                         |\n",
      "|    clip_fraction           | 0.213                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.26                                |\n",
      "|    explained_variance      | 0.893                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.59                                 |\n",
      "|    n_updates               | 530                                  |\n",
      "|    policy_gradient_loss    | -0.0132                              |\n",
      "|    value_loss              | 8.66                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 149                                  |\n",
      "|    ep_rew_mean             | -24.1                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 859                                  |\n",
      "|    iterations              | 54                                   |\n",
      "|    time_elapsed            | 4119                                 |\n",
      "|    total_timesteps         | 3538944                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 148                                  |\n",
      "|    ep_rew_mean             | -23.2                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 55                                   |\n",
      "|    time_elapsed            | 4188                                 |\n",
      "|    total_timesteps         | 3604480                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004515392                          |\n",
      "|    clip_fraction           | 0.218                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.24                                |\n",
      "|    explained_variance      | 0.89                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.58                                 |\n",
      "|    n_updates               | 540                                  |\n",
      "|    policy_gradient_loss    | -0.0134                              |\n",
      "|    value_loss              | 8.22                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 146                                  |\n",
      "|    ep_rew_mean             | -20.6                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 56                                   |\n",
      "|    time_elapsed            | 4259                                 |\n",
      "|    total_timesteps         | 3670016                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0045796507                         |\n",
      "|    clip_fraction           | 0.219                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.22                                |\n",
      "|    explained_variance      | 0.889                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.84                                 |\n",
      "|    n_updates               | 550                                  |\n",
      "|    policy_gradient_loss    | -0.0134                              |\n",
      "|    value_loss              | 8.08                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=3680000, episode_reward=-19.13 +/- 11.70\n",
      "Episode length: 144.30 +/- 9.41\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 144                                  |\n",
      "|    mean_reward             | -19.1                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 3680000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0047053336                         |\n",
      "|    clip_fraction           | 0.221                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.2                                 |\n",
      "|    explained_variance      | 0.889                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.99                                 |\n",
      "|    n_updates               | 560                                  |\n",
      "|    policy_gradient_loss    | -0.0136                              |\n",
      "|    value_loss              | 8.18                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 144                                  |\n",
      "|    ep_rew_mean             | -18.4                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 57                                   |\n",
      "|    time_elapsed            | 4341                                 |\n",
      "|    total_timesteps         | 3735552                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 144                                  |\n",
      "|    ep_rew_mean             | -18.5                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 58                                   |\n",
      "|    time_elapsed            | 4412                                 |\n",
      "|    total_timesteps         | 3801088                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0046917377                         |\n",
      "|    clip_fraction           | 0.228                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.18                                |\n",
      "|    explained_variance      | 0.895                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.7                                  |\n",
      "|    n_updates               | 570                                  |\n",
      "|    policy_gradient_loss    | -0.0139                              |\n",
      "|    value_loss              | 7.71                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=-16.83 +/- 12.88\n",
      "Episode length: 142.85 +/- 12.02\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 143                                  |\n",
      "|    mean_reward             | -16.8                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 3840000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004623036                          |\n",
      "|    clip_fraction           | 0.224                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.16                                |\n",
      "|    explained_variance      | 0.893                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.78                                 |\n",
      "|    n_updates               | 580                                  |\n",
      "|    policy_gradient_loss    | -0.0135                              |\n",
      "|    value_loss              | 7.56                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 144                                  |\n",
      "|    ep_rew_mean             | -18.4                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 860                                  |\n",
      "|    iterations              | 59                                   |\n",
      "|    time_elapsed            | 4494                                 |\n",
      "|    total_timesteps         | 3866624                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 140                                  |\n",
      "|    ep_rew_mean             | -13.9                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 60                                   |\n",
      "|    time_elapsed            | 4564                                 |\n",
      "|    total_timesteps         | 3932160                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0047722748                         |\n",
      "|    clip_fraction           | 0.229                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.15                                |\n",
      "|    explained_variance      | 0.895                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.15                                 |\n",
      "|    n_updates               | 590                                  |\n",
      "|    policy_gradient_loss    | -0.0137                              |\n",
      "|    value_loss              | 7.25                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 141                                  |\n",
      "|    ep_rew_mean             | -15.7                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 61                                   |\n",
      "|    time_elapsed            | 4635                                 |\n",
      "|    total_timesteps         | 3997696                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0047558118                         |\n",
      "|    clip_fraction           | 0.225                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.13                                |\n",
      "|    explained_variance      | 0.893                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.63                                 |\n",
      "|    n_updates               | 600                                  |\n",
      "|    policy_gradient_loss    | -0.0134                              |\n",
      "|    value_loss              | 7.66                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=-12.73 +/- 13.89\n",
      "Episode length: 139.00 +/- 13.90\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 139                                  |\n",
      "|    mean_reward             | -12.7                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 1 4 3 2 4 1 5 2 3 1 4 5 2 3 4 1... |\n",
      "|    best_permutation_length | 318                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 4000000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0048319283                         |\n",
      "|    clip_fraction           | 0.233                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.11                                |\n",
      "|    explained_variance      | 0.895                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.18                                 |\n",
      "|    n_updates               | 610                                  |\n",
      "|    policy_gradient_loss    | -0.0139                              |\n",
      "|    value_loss              | 7.49                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 140                                  |\n",
      "|    ep_rew_mean             | -13.7                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 62                                   |\n",
      "|    time_elapsed            | 4716                                 |\n",
      "|    total_timesteps         | 4063232                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 138                                  |\n",
      "|    ep_rew_mean             | -11.5                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 63                                   |\n",
      "|    time_elapsed            | 4786                                 |\n",
      "|    total_timesteps         | 4128768                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0048845406                         |\n",
      "|    clip_fraction           | 0.239                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.09                                |\n",
      "|    explained_variance      | 0.894                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.15                                 |\n",
      "|    n_updates               | 620                                  |\n",
      "|    policy_gradient_loss    | -0.0136                              |\n",
      "|    value_loss              | 7.13                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=-6.94 +/- 12.00\n",
      "Episode length: 133.40 +/- 11.80\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 133                                  |\n",
      "|    mean_reward             | -6.94                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 4160000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0049591144                         |\n",
      "|    clip_fraction           | 0.238                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.07                                |\n",
      "|    explained_variance      | 0.89                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.83                                 |\n",
      "|    n_updates               | 630                                  |\n",
      "|    policy_gradient_loss    | -0.0141                              |\n",
      "|    value_loss              | 7.11                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 138                                  |\n",
      "|    ep_rew_mean             | -12.1                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 64                                   |\n",
      "|    time_elapsed            | 4867                                 |\n",
      "|    total_timesteps         | 4194304                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 136                                  |\n",
      "|    ep_rew_mean             | -9.69                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 65                                   |\n",
      "|    time_elapsed            | 4937                                 |\n",
      "|    total_timesteps         | 4259840                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0050712028                         |\n",
      "|    clip_fraction           | 0.24                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.05                                |\n",
      "|    explained_variance      | 0.888                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.55                                 |\n",
      "|    n_updates               | 640                                  |\n",
      "|    policy_gradient_loss    | -0.0143                              |\n",
      "|    value_loss              | 7.2                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=-4.66 +/- 17.02\n",
      "Episode length: 131.20 +/- 16.87\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 131                                  |\n",
      "|    mean_reward             | -4.66                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 4320000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005025416                          |\n",
      "|    clip_fraction           | 0.244                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.03                                |\n",
      "|    explained_variance      | 0.891                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.5                                  |\n",
      "|    n_updates               | 650                                  |\n",
      "|    policy_gradient_loss    | -0.0145                              |\n",
      "|    value_loss              | 7.13                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 134                                  |\n",
      "|    ep_rew_mean             | -8                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 861                                  |\n",
      "|    iterations              | 66                                   |\n",
      "|    time_elapsed            | 5018                                 |\n",
      "|    total_timesteps         | 4325376                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 134                                  |\n",
      "|    ep_rew_mean             | -7.74                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 67                                   |\n",
      "|    time_elapsed            | 5088                                 |\n",
      "|    total_timesteps         | 4390912                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0051055443                         |\n",
      "|    clip_fraction           | 0.243                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -4.01                                |\n",
      "|    explained_variance      | 0.891                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.21                                 |\n",
      "|    n_updates               | 660                                  |\n",
      "|    policy_gradient_loss    | -0.0143                              |\n",
      "|    value_loss              | 6.85                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 132                                  |\n",
      "|    ep_rew_mean             | -4.95                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 863                                  |\n",
      "|    iterations              | 68                                   |\n",
      "|    time_elapsed            | 5157                                 |\n",
      "|    total_timesteps         | 4456448                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0051247333                         |\n",
      "|    clip_fraction           | 0.249                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.99                                |\n",
      "|    explained_variance      | 0.89                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.18                                 |\n",
      "|    n_updates               | 670                                  |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 6.58                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=-8.52 +/- 15.10\n",
      "Episode length: 134.65 +/- 14.75\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 135                                  |\n",
      "|    mean_reward             | -8.52                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 4480000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0051825074                         |\n",
      "|    clip_fraction           | 0.249                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.97                                |\n",
      "|    explained_variance      | 0.888                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.41                                 |\n",
      "|    n_updates               | 680                                  |\n",
      "|    policy_gradient_loss    | -0.0145                              |\n",
      "|    value_loss              | 6.72                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 131                                  |\n",
      "|    ep_rew_mean             | -4.46                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 863                                  |\n",
      "|    iterations              | 69                                   |\n",
      "|    time_elapsed            | 5239                                 |\n",
      "|    total_timesteps         | 4521984                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 131                                  |\n",
      "|    ep_rew_mean             | -4.16                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 864                                  |\n",
      "|    iterations              | 70                                   |\n",
      "|    time_elapsed            | 5309                                 |\n",
      "|    total_timesteps         | 4587520                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005139895                          |\n",
      "|    clip_fraction           | 0.246                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.96                                |\n",
      "|    explained_variance      | 0.892                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.56                                 |\n",
      "|    n_updates               | 690                                  |\n",
      "|    policy_gradient_loss    | -0.0142                              |\n",
      "|    value_loss              | 6.53                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=-3.78 +/- 14.01\n",
      "Episode length: 129.90 +/- 13.37\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 130                                  |\n",
      "|    mean_reward             | -3.78                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 4640000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0050770985                         |\n",
      "|    clip_fraction           | 0.247                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.93                                |\n",
      "|    explained_variance      | 0.893                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.91                                 |\n",
      "|    n_updates               | 700                                  |\n",
      "|    policy_gradient_loss    | -0.0143                              |\n",
      "|    value_loss              | 6.54                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 131                                  |\n",
      "|    ep_rew_mean             | -3.86                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 862                                  |\n",
      "|    iterations              | 71                                   |\n",
      "|    time_elapsed            | 5391                                 |\n",
      "|    total_timesteps         | 4653056                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 130                                  |\n",
      "|    ep_rew_mean             | -3.55                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 863                                  |\n",
      "|    iterations              | 72                                   |\n",
      "|    time_elapsed            | 5462                                 |\n",
      "|    total_timesteps         | 4718592                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0053552045                         |\n",
      "|    clip_fraction           | 0.255                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.91                                |\n",
      "|    explained_variance      | 0.891                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.49                                 |\n",
      "|    n_updates               | 710                                  |\n",
      "|    policy_gradient_loss    | -0.0148                              |\n",
      "|    value_loss              | 6.29                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 129                                  |\n",
      "|    ep_rew_mean             | -2.28                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 864                                  |\n",
      "|    iterations              | 73                                   |\n",
      "|    time_elapsed            | 5533                                 |\n",
      "|    total_timesteps         | 4784128                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005415555                          |\n",
      "|    clip_fraction           | 0.253                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.9                                 |\n",
      "|    explained_variance      | 0.885                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.13                                 |\n",
      "|    n_updates               | 720                                  |\n",
      "|    policy_gradient_loss    | -0.0145                              |\n",
      "|    value_loss              | 6.28                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=-8.28 +/- 13.08\n",
      "Episode length: 134.50 +/- 11.71\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 134                                  |\n",
      "|    mean_reward             | -8.28                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 4800000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00534132                           |\n",
      "|    clip_fraction           | 0.253                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.88                                |\n",
      "|    explained_variance      | 0.887                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.35                                 |\n",
      "|    n_updates               | 730                                  |\n",
      "|    policy_gradient_loss    | -0.0142                              |\n",
      "|    value_loss              | 6.29                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 126                                  |\n",
      "|    ep_rew_mean             | 0.938                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 863                                  |\n",
      "|    iterations              | 74                                   |\n",
      "|    time_elapsed            | 5617                                 |\n",
      "|    total_timesteps         | 4849664                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 126                                  |\n",
      "|    ep_rew_mean             | 0.656                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 863                                  |\n",
      "|    iterations              | 75                                   |\n",
      "|    time_elapsed            | 5690                                 |\n",
      "|    total_timesteps         | 4915200                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0053664474                         |\n",
      "|    clip_fraction           | 0.261                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.86                                |\n",
      "|    explained_variance      | 0.891                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.89                                 |\n",
      "|    n_updates               | 740                                  |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 6.11                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=6.09 +/- 14.43\n",
      "Episode length: 120.90 +/- 14.94\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 121                                  |\n",
      "|    mean_reward             | 6.09                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 4960000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005255662                          |\n",
      "|    clip_fraction           | 0.257                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.85                                |\n",
      "|    explained_variance      | 0.892                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.62                                 |\n",
      "|    n_updates               | 750                                  |\n",
      "|    policy_gradient_loss    | -0.0143                              |\n",
      "|    value_loss              | 6.23                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 1 4 2 3 5 4 1 2 4 5 1 3 1 5 2 4 5... |\n",
      "|    best_permutation_length | 317                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 124                                  |\n",
      "|    ep_rew_mean             | 3.15                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 863                                  |\n",
      "|    iterations              | 76                                   |\n",
      "|    time_elapsed            | 5768                                 |\n",
      "|    total_timesteps         | 4980736                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 5 3 4 1 2 4 5 3 1 2 4 5 1 3 4 2... |\n",
      "|    best_permutation_length | 314                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 124                                  |\n",
      "|    ep_rew_mean             | 2.31                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 864                                  |\n",
      "|    iterations              | 77                                   |\n",
      "|    time_elapsed            | 5838                                 |\n",
      "|    total_timesteps         | 5046272                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0054387357                         |\n",
      "|    clip_fraction           | 0.259                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.83                                |\n",
      "|    explained_variance      | 0.894                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.03                                 |\n",
      "|    n_updates               | 760                                  |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 6.03                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 5 3 4 1 2 4 5 3 1 2 4 5 1 3 4 2... |\n",
      "|    best_permutation_length | 314                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 124                                  |\n",
      "|    ep_rew_mean             | 2.38                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 865                                  |\n",
      "|    iterations              | 78                                   |\n",
      "|    time_elapsed            | 5907                                 |\n",
      "|    total_timesteps         | 5111808                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0056001316                         |\n",
      "|    clip_fraction           | 0.265                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.81                                |\n",
      "|    explained_variance      | 0.89                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.8                                  |\n",
      "|    n_updates               | 770                                  |\n",
      "|    policy_gradient_loss    | -0.0149                              |\n",
      "|    value_loss              | 5.99                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=5120000, episode_reward=1.54 +/- 12.09\n",
      "Episode length: 125.20 +/- 12.43\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 125                                  |\n",
      "|    mean_reward             | 1.54                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 5 3 4 1 2 4 5 3 1 2 4 5 1 3 4 2... |\n",
      "|    best_permutation_length | 314                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 5120000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005632967                          |\n",
      "|    clip_fraction           | 0.265                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.8                                 |\n",
      "|    explained_variance      | 0.884                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.49                                 |\n",
      "|    n_updates               | 780                                  |\n",
      "|    policy_gradient_loss    | -0.0144                              |\n",
      "|    value_loss              | 6.1                                  |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 5 3 4 1 2 4 5 3 1 2 4 5 1 3 4 2... |\n",
      "|    best_permutation_length | 314                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 124                                  |\n",
      "|    ep_rew_mean             | 2.81                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 864                                  |\n",
      "|    iterations              | 79                                   |\n",
      "|    time_elapsed            | 5986                                 |\n",
      "|    total_timesteps         | 5177344                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 124                                  |\n",
      "|    ep_rew_mean             | 3.17                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 865                                  |\n",
      "|    iterations              | 80                                   |\n",
      "|    time_elapsed            | 6055                                 |\n",
      "|    total_timesteps         | 5242880                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005671816                          |\n",
      "|    clip_fraction           | 0.269                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.78                                |\n",
      "|    explained_variance      | 0.892                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.01                                 |\n",
      "|    n_updates               | 790                                  |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 5.9                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=5280000, episode_reward=1.59 +/- 12.95\n",
      "Episode length: 125.05 +/- 13.19\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 125                                  |\n",
      "|    mean_reward             | 1.59                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 5280000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005521452                          |\n",
      "|    clip_fraction           | 0.266                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.76                                |\n",
      "|    explained_variance      | 0.89                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.37                                 |\n",
      "|    n_updates               | 800                                  |\n",
      "|    policy_gradient_loss    | -0.0144                              |\n",
      "|    value_loss              | 6.01                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 121                                  |\n",
      "|    ep_rew_mean             | 5.35                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 865                                  |\n",
      "|    iterations              | 81                                   |\n",
      "|    time_elapsed            | 6134                                 |\n",
      "|    total_timesteps         | 5308416                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 121                                  |\n",
      "|    ep_rew_mean             | 6.12                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 866                                  |\n",
      "|    iterations              | 82                                   |\n",
      "|    time_elapsed            | 6203                                 |\n",
      "|    total_timesteps         | 5373952                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0055912794                         |\n",
      "|    clip_fraction           | 0.27                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.75                                |\n",
      "|    explained_variance      | 0.891                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.06                                 |\n",
      "|    n_updates               | 810                                  |\n",
      "|    policy_gradient_loss    | -0.0145                              |\n",
      "|    value_loss              | 5.7                                  |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 120                                  |\n",
      "|    ep_rew_mean             | 6.48                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 867                                  |\n",
      "|    iterations              | 83                                   |\n",
      "|    time_elapsed            | 6272                                 |\n",
      "|    total_timesteps         | 5439488                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005667351                          |\n",
      "|    clip_fraction           | 0.268                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.73                                |\n",
      "|    explained_variance      | 0.895                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.88                                 |\n",
      "|    n_updates               | 820                                  |\n",
      "|    policy_gradient_loss    | -0.0144                              |\n",
      "|    value_loss              | 5.86                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=5440000, episode_reward=7.29 +/- 8.32\n",
      "Episode length: 119.55 +/- 8.51\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 120                                  |\n",
      "|    mean_reward             | 7.29                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 5440000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0057101212                         |\n",
      "|    clip_fraction           | 0.277                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.71                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.31                                 |\n",
      "|    n_updates               | 830                                  |\n",
      "|    policy_gradient_loss    | -0.0147                              |\n",
      "|    value_loss              | 5.64                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 119                                  |\n",
      "|    ep_rew_mean             | 7.67                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 866                                  |\n",
      "|    iterations              | 84                                   |\n",
      "|    time_elapsed            | 6350                                 |\n",
      "|    total_timesteps         | 5505024                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 120                                  |\n",
      "|    ep_rew_mean             | 7.17                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 867                                  |\n",
      "|    iterations              | 85                                   |\n",
      "|    time_elapsed            | 6419                                 |\n",
      "|    total_timesteps         | 5570560                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005728442                          |\n",
      "|    clip_fraction           | 0.271                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.7                                 |\n",
      "|    explained_variance      | 0.894                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.84                                 |\n",
      "|    n_updates               | 840                                  |\n",
      "|    policy_gradient_loss    | -0.0149                              |\n",
      "|    value_loss              | 5.74                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=5600000, episode_reward=9.14 +/- 9.83\n",
      "Episode length: 117.80 +/- 9.63\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 118                                  |\n",
      "|    mean_reward             | 9.14                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 5600000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0058216876                         |\n",
      "|    clip_fraction           | 0.275                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.68                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.02                                 |\n",
      "|    n_updates               | 850                                  |\n",
      "|    policy_gradient_loss    | -0.0149                              |\n",
      "|    value_loss              | 5.69                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 5 4 3 2 1 3 1 2 4 5 2 5 3 4 1 2 3... |\n",
      "|    best_permutation_length | 311                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 118                                  |\n",
      "|    ep_rew_mean             | 8.84                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 867                                  |\n",
      "|    iterations              | 86                                   |\n",
      "|    time_elapsed            | 6497                                 |\n",
      "|    total_timesteps         | 5636096                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 118                                  |\n",
      "|    ep_rew_mean             | 8.3                                  |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 868                                  |\n",
      "|    iterations              | 87                                   |\n",
      "|    time_elapsed            | 6565                                 |\n",
      "|    total_timesteps         | 5701632                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005858165                          |\n",
      "|    clip_fraction           | 0.275                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.66                                |\n",
      "|    explained_variance      | 0.89                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.19                                 |\n",
      "|    n_updates               | 860                                  |\n",
      "|    policy_gradient_loss    | -0.0144                              |\n",
      "|    value_loss              | 5.85                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=5760000, episode_reward=10.40 +/- 10.07\n",
      "Episode length: 116.15 +/- 9.84\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 116                                  |\n",
      "|    mean_reward             | 10.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 5760000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0058185123                         |\n",
      "|    clip_fraction           | 0.278                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.64                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2                                    |\n",
      "|    n_updates               | 870                                  |\n",
      "|    policy_gradient_loss    | -0.0151                              |\n",
      "|    value_loss              | 5.94                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 117                                  |\n",
      "|    ep_rew_mean             | 9.37                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 868                                  |\n",
      "|    iterations              | 88                                   |\n",
      "|    time_elapsed            | 6643                                 |\n",
      "|    total_timesteps         | 5767168                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 115                                  |\n",
      "|    ep_rew_mean             | 11.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 869                                  |\n",
      "|    iterations              | 89                                   |\n",
      "|    time_elapsed            | 6711                                 |\n",
      "|    total_timesteps         | 5832704                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00595699                           |\n",
      "|    clip_fraction           | 0.28                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.62                                |\n",
      "|    explained_variance      | 0.898                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.49                                 |\n",
      "|    n_updates               | 880                                  |\n",
      "|    policy_gradient_loss    | -0.0147                              |\n",
      "|    value_loss              | 5.74                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 115                                  |\n",
      "|    ep_rew_mean             | 11.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 869                                  |\n",
      "|    iterations              | 90                                   |\n",
      "|    time_elapsed            | 6780                                 |\n",
      "|    total_timesteps         | 5898240                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0059588384                         |\n",
      "|    clip_fraction           | 0.281                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.61                                |\n",
      "|    explained_variance      | 0.898                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.66                                 |\n",
      "|    n_updates               | 890                                  |\n",
      "|    policy_gradient_loss    | -0.0151                              |\n",
      "|    value_loss              | 5.6                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=5920000, episode_reward=6.39 +/- 12.67\n",
      "Episode length: 120.70 +/- 13.20\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 121                                  |\n",
      "|    mean_reward             | 6.39                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 5920000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0059679225                         |\n",
      "|    clip_fraction           | 0.284                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.58                                |\n",
      "|    explained_variance      | 0.894                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.33                                 |\n",
      "|    n_updates               | 900                                  |\n",
      "|    policy_gradient_loss    | -0.0148                              |\n",
      "|    value_loss              | 5.85                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 117                                  |\n",
      "|    ep_rew_mean             | 9.38                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 869                                  |\n",
      "|    iterations              | 91                                   |\n",
      "|    time_elapsed            | 6858                                 |\n",
      "|    total_timesteps         | 5963776                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 116                                  |\n",
      "|    ep_rew_mean             | 11.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 870                                  |\n",
      "|    iterations              | 92                                   |\n",
      "|    time_elapsed            | 6929                                 |\n",
      "|    total_timesteps         | 6029312                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005897657                          |\n",
      "|    clip_fraction           | 0.281                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.56                                |\n",
      "|    explained_variance      | 0.892                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.35                                 |\n",
      "|    n_updates               | 910                                  |\n",
      "|    policy_gradient_loss    | -0.0148                              |\n",
      "|    value_loss              | 5.93                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=6080000, episode_reward=13.03 +/- 14.78\n",
      "Episode length: 113.10 +/- 14.71\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 113                                  |\n",
      "|    mean_reward             | 13                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 6080000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0061007487                         |\n",
      "|    clip_fraction           | 0.288                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.55                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.59                                 |\n",
      "|    n_updates               | 920                                  |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 5.67                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 115                                  |\n",
      "|    ep_rew_mean             | 11.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 869                                  |\n",
      "|    iterations              | 93                                   |\n",
      "|    time_elapsed            | 7008                                 |\n",
      "|    total_timesteps         | 6094848                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 114                                  |\n",
      "|    ep_rew_mean             | 12.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 870                                  |\n",
      "|    iterations              | 94                                   |\n",
      "|    time_elapsed            | 7079                                 |\n",
      "|    total_timesteps         | 6160384                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0059699533                         |\n",
      "|    clip_fraction           | 0.282                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.53                                |\n",
      "|    explained_variance      | 0.897                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.44                                 |\n",
      "|    n_updates               | 930                                  |\n",
      "|    policy_gradient_loss    | -0.0144                              |\n",
      "|    value_loss              | 5.71                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 113                                  |\n",
      "|    ep_rew_mean             | 13.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 870                                  |\n",
      "|    iterations              | 95                                   |\n",
      "|    time_elapsed            | 7149                                 |\n",
      "|    total_timesteps         | 6225920                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0060822777                         |\n",
      "|    clip_fraction           | 0.288                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.51                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.66                                 |\n",
      "|    n_updates               | 940                                  |\n",
      "|    policy_gradient_loss    | -0.0149                              |\n",
      "|    value_loss              | 5.64                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=6240000, episode_reward=15.67 +/- 13.47\n",
      "Episode length: 110.70 +/- 13.74\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 111                                  |\n",
      "|    mean_reward             | 15.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 6240000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005986125                          |\n",
      "|    clip_fraction           | 0.283                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.49                                |\n",
      "|    explained_variance      | 0.89                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.04                                 |\n",
      "|    n_updates               | 950                                  |\n",
      "|    policy_gradient_loss    | -0.0147                              |\n",
      "|    value_loss              | 5.88                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 112                                  |\n",
      "|    ep_rew_mean             | 15.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 869                                  |\n",
      "|    iterations              | 96                                   |\n",
      "|    time_elapsed            | 7233                                 |\n",
      "|    total_timesteps         | 6291456                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 110                                  |\n",
      "|    ep_rew_mean             | 17.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 870                                  |\n",
      "|    iterations              | 97                                   |\n",
      "|    time_elapsed            | 7304                                 |\n",
      "|    total_timesteps         | 6356992                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0062012062                         |\n",
      "|    clip_fraction           | 0.289                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.47                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.98                                 |\n",
      "|    n_updates               | 960                                  |\n",
      "|    policy_gradient_loss    | -0.0147                              |\n",
      "|    value_loss              | 5.66                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=6400000, episode_reward=21.56 +/- 11.10\n",
      "Episode length: 104.95 +/- 10.66\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 105                                  |\n",
      "|    mean_reward             | 21.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 4 5 3 1 2 5 4 3 1 4 3... |\n",
      "|    best_permutation_length | 298                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 6400000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0061150664                         |\n",
      "|    clip_fraction           | 0.287                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.45                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.99                                 |\n",
      "|    n_updates               | 970                                  |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 5.73                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 5 2... |\n",
      "|    best_permutation_length | 297                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 111                                  |\n",
      "|    ep_rew_mean             | 16                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 870                                  |\n",
      "|    iterations              | 98                                   |\n",
      "|    time_elapsed            | 7380                                 |\n",
      "|    total_timesteps         | 6422528                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 5 2... |\n",
      "|    best_permutation_length | 297                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 109                                  |\n",
      "|    ep_rew_mean             | 17.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 871                                  |\n",
      "|    iterations              | 99                                   |\n",
      "|    time_elapsed            | 7448                                 |\n",
      "|    total_timesteps         | 6488064                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0060692746                         |\n",
      "|    clip_fraction           | 0.288                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.42                                |\n",
      "|    explained_variance      | 0.9                                  |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.05                                 |\n",
      "|    n_updates               | 980                                  |\n",
      "|    policy_gradient_loss    | -0.0145                              |\n",
      "|    value_loss              | 5.56                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 5 2... |\n",
      "|    best_permutation_length | 297                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 110                                  |\n",
      "|    ep_rew_mean             | 16.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 871                                  |\n",
      "|    iterations              | 100                                  |\n",
      "|    time_elapsed            | 7516                                 |\n",
      "|    total_timesteps         | 6553600                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0061980262                         |\n",
      "|    clip_fraction           | 0.291                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.41                                |\n",
      "|    explained_variance      | 0.902                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.44                                 |\n",
      "|    n_updates               | 990                                  |\n",
      "|    policy_gradient_loss    | -0.015                               |\n",
      "|    value_loss              | 5.5                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=6560000, episode_reward=19.81 +/- 13.28\n",
      "Episode length: 107.05 +/- 13.38\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 107                                  |\n",
      "|    mean_reward             | 19.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 5 2... |\n",
      "|    best_permutation_length | 297                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 6560000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063839965                         |\n",
      "|    clip_fraction           | 0.291                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.39                                |\n",
      "|    explained_variance      | 0.899                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.36                                 |\n",
      "|    n_updates               | 1000                                 |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 5.73                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 5 2... |\n",
      "|    best_permutation_length | 297                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 109                                  |\n",
      "|    ep_rew_mean             | 18                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 871                                  |\n",
      "|    iterations              | 101                                  |\n",
      "|    time_elapsed            | 7592                                 |\n",
      "|    total_timesteps         | 6619136                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 5... |\n",
      "|    best_permutation_length | 296                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 106                                  |\n",
      "|    ep_rew_mean             | 20.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 872                                  |\n",
      "|    iterations              | 102                                  |\n",
      "|    time_elapsed            | 7660                                 |\n",
      "|    total_timesteps         | 6684672                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0062775295                         |\n",
      "|    clip_fraction           | 0.288                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.37                                |\n",
      "|    explained_variance      | 0.903                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.84                                 |\n",
      "|    n_updates               | 1010                                 |\n",
      "|    policy_gradient_loss    | -0.0148                              |\n",
      "|    value_loss              | 5.66                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=6720000, episode_reward=19.22 +/- 9.50\n",
      "Episode length: 107.40 +/- 9.32\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 107                                  |\n",
      "|    mean_reward             | 19.2                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 5... |\n",
      "|    best_permutation_length | 296                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 6720000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006199058                          |\n",
      "|    clip_fraction           | 0.294                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.35                                |\n",
      "|    explained_variance      | 0.905                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.2                                  |\n",
      "|    n_updates               | 1020                                 |\n",
      "|    policy_gradient_loss    | -0.0147                              |\n",
      "|    value_loss              | 5.47                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 5... |\n",
      "|    best_permutation_length | 296                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 104                                  |\n",
      "|    ep_rew_mean             | 22.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 872                                  |\n",
      "|    iterations              | 103                                  |\n",
      "|    time_elapsed            | 7735                                 |\n",
      "|    total_timesteps         | 6750208                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 104                                  |\n",
      "|    ep_rew_mean             | 22                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 873                                  |\n",
      "|    iterations              | 104                                  |\n",
      "|    time_elapsed            | 7802                                 |\n",
      "|    total_timesteps         | 6815744                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0062512797                         |\n",
      "|    clip_fraction           | 0.289                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.33                                |\n",
      "|    explained_variance      | 0.905                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.35                                 |\n",
      "|    n_updates               | 1030                                 |\n",
      "|    policy_gradient_loss    | -0.0145                              |\n",
      "|    value_loss              | 5.51                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=6880000, episode_reward=22.38 +/- 9.17\n",
      "Episode length: 104.10 +/- 9.63\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 104                                  |\n",
      "|    mean_reward             | 22.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 6880000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0061762305                         |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.31                                |\n",
      "|    explained_variance      | 0.904                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.7                                  |\n",
      "|    n_updates               | 1040                                 |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 5.45                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 104                                  |\n",
      "|    ep_rew_mean             | 22.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 873                                  |\n",
      "|    iterations              | 105                                  |\n",
      "|    time_elapsed            | 7878                                 |\n",
      "|    total_timesteps         | 6881280                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 107                                  |\n",
      "|    ep_rew_mean             | 20                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 874                                  |\n",
      "|    iterations              | 106                                  |\n",
      "|    time_elapsed            | 7945                                 |\n",
      "|    total_timesteps         | 6946816                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006335629                          |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.3                                 |\n",
      "|    explained_variance      | 0.91                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.3                                  |\n",
      "|    n_updates               | 1050                                 |\n",
      "|    policy_gradient_loss    | -0.0147                              |\n",
      "|    value_loss              | 5.18                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 102                                  |\n",
      "|    ep_rew_mean             | 23.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 875                                  |\n",
      "|    iterations              | 107                                  |\n",
      "|    time_elapsed            | 8012                                 |\n",
      "|    total_timesteps         | 7012352                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063162507                         |\n",
      "|    clip_fraction           | 0.289                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.27                                |\n",
      "|    explained_variance      | 0.903                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.36                                 |\n",
      "|    n_updates               | 1060                                 |\n",
      "|    policy_gradient_loss    | -0.0141                              |\n",
      "|    value_loss              | 5.59                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=7040000, episode_reward=21.16 +/- 8.47\n",
      "Episode length: 105.75 +/- 8.69\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 106                                  |\n",
      "|    mean_reward             | 21.2                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 7040000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0062809824                         |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.26                                |\n",
      "|    explained_variance      | 0.913                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.37                                 |\n",
      "|    n_updates               | 1070                                 |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 5.43                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 103                                  |\n",
      "|    ep_rew_mean             | 23.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 875                                  |\n",
      "|    iterations              | 108                                  |\n",
      "|    time_elapsed            | 8087                                 |\n",
      "|    total_timesteps         | 7077888                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 101                                  |\n",
      "|    ep_rew_mean             | 25.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 875                                  |\n",
      "|    iterations              | 109                                  |\n",
      "|    time_elapsed            | 8156                                 |\n",
      "|    total_timesteps         | 7143424                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006258562                          |\n",
      "|    clip_fraction           | 0.291                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.24                                |\n",
      "|    explained_variance      | 0.906                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.06                                 |\n",
      "|    n_updates               | 1080                                 |\n",
      "|    policy_gradient_loss    | -0.0144                              |\n",
      "|    value_loss              | 5.6                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=7200000, episode_reward=22.77 +/- 11.00\n",
      "Episode length: 103.85 +/- 10.74\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 104                                  |\n",
      "|    mean_reward             | 22.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 7200000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063105933                         |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.21                                |\n",
      "|    explained_variance      | 0.913                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.08                                 |\n",
      "|    n_updates               | 1090                                 |\n",
      "|    policy_gradient_loss    | -0.0141                              |\n",
      "|    value_loss              | 5.47                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 101                                  |\n",
      "|    ep_rew_mean             | 25.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 875                                  |\n",
      "|    iterations              | 110                                  |\n",
      "|    time_elapsed            | 8231                                 |\n",
      "|    total_timesteps         | 7208960                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 100                                  |\n",
      "|    ep_rew_mean             | 26.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 876                                  |\n",
      "|    iterations              | 111                                  |\n",
      "|    time_elapsed            | 8298                                 |\n",
      "|    total_timesteps         | 7274496                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064838277                         |\n",
      "|    clip_fraction           | 0.297                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.2                                 |\n",
      "|    explained_variance      | 0.912                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.18                                 |\n",
      "|    n_updates               | 1100                                 |\n",
      "|    policy_gradient_loss    | -0.0143                              |\n",
      "|    value_loss              | 5.36                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 99.1                                 |\n",
      "|    ep_rew_mean             | 27.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 877                                  |\n",
      "|    iterations              | 112                                  |\n",
      "|    time_elapsed            | 8365                                 |\n",
      "|    total_timesteps         | 7340032                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065377224                         |\n",
      "|    clip_fraction           | 0.297                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.18                                |\n",
      "|    explained_variance      | 0.914                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.94                                 |\n",
      "|    n_updates               | 1110                                 |\n",
      "|    policy_gradient_loss    | -0.0143                              |\n",
      "|    value_loss              | 5.22                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=7360000, episode_reward=28.52 +/- 10.22\n",
      "Episode length: 97.55 +/- 10.06\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 97.5                                 |\n",
      "|    mean_reward             | 28.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 7360000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006394296                          |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.16                                |\n",
      "|    explained_variance      | 0.915                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.42                                 |\n",
      "|    n_updates               | 1120                                 |\n",
      "|    policy_gradient_loss    | -0.0138                              |\n",
      "|    value_loss              | 5.26                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 101                                  |\n",
      "|    ep_rew_mean             | 25.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 877                                  |\n",
      "|    iterations              | 113                                  |\n",
      "|    time_elapsed            | 8440                                 |\n",
      "|    total_timesteps         | 7405568                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 98.8                                 |\n",
      "|    ep_rew_mean             | 27.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 878                                  |\n",
      "|    iterations              | 114                                  |\n",
      "|    time_elapsed            | 8506                                 |\n",
      "|    total_timesteps         | 7471104                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064304825                         |\n",
      "|    clip_fraction           | 0.296                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.13                                |\n",
      "|    explained_variance      | 0.918                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.66                                 |\n",
      "|    n_updates               | 1130                                 |\n",
      "|    policy_gradient_loss    | -0.0142                              |\n",
      "|    value_loss              | 5.4                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=7520000, episode_reward=30.53 +/- 9.63\n",
      "Episode length: 96.00 +/- 9.24\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 96                                   |\n",
      "|    mean_reward             | 30.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 7520000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006347865                          |\n",
      "|    clip_fraction           | 0.289                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.11                                |\n",
      "|    explained_variance      | 0.92                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.83                                 |\n",
      "|    n_updates               | 1140                                 |\n",
      "|    policy_gradient_loss    | -0.0139                              |\n",
      "|    value_loss              | 5.36                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 98.2                                 |\n",
      "|    ep_rew_mean             | 28.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 878                                  |\n",
      "|    iterations              | 115                                  |\n",
      "|    time_elapsed            | 8581                                 |\n",
      "|    total_timesteps         | 7536640                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 93.8                                 |\n",
      "|    ep_rew_mean             | 32.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 879                                  |\n",
      "|    iterations              | 116                                  |\n",
      "|    time_elapsed            | 8648                                 |\n",
      "|    total_timesteps         | 7602176                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006279384                          |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.1                                 |\n",
      "|    explained_variance      | 0.922                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.41                                 |\n",
      "|    n_updates               | 1150                                 |\n",
      "|    policy_gradient_loss    | -0.0135                              |\n",
      "|    value_loss              | 5.28                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 95.6                                 |\n",
      "|    ep_rew_mean             | 31.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 879                                  |\n",
      "|    iterations              | 117                                  |\n",
      "|    time_elapsed            | 8715                                 |\n",
      "|    total_timesteps         | 7667712                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006346315                          |\n",
      "|    clip_fraction           | 0.294                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.07                                |\n",
      "|    explained_variance      | 0.924                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.68                                 |\n",
      "|    n_updates               | 1160                                 |\n",
      "|    policy_gradient_loss    | -0.0141                              |\n",
      "|    value_loss              | 5.26                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=7680000, episode_reward=28.62 +/- 9.60\n",
      "Episode length: 97.95 +/- 9.94\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 98                                   |\n",
      "|    mean_reward             | 28.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 4 2... |\n",
      "|    best_permutation_length | 277                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 7680000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006201202                          |\n",
      "|    clip_fraction           | 0.291                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.05                                |\n",
      "|    explained_variance      | 0.928                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.25                                 |\n",
      "|    n_updates               | 1170                                 |\n",
      "|    policy_gradient_loss    | -0.0137                              |\n",
      "|    value_loss              | 5.35                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 276                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 95.8                                 |\n",
      "|    ep_rew_mean             | 30.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 879                                  |\n",
      "|    iterations              | 118                                  |\n",
      "|    time_elapsed            | 8789                                 |\n",
      "|    total_timesteps         | 7733248                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 276                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 95.4                                 |\n",
      "|    ep_rew_mean             | 31.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 880                                  |\n",
      "|    iterations              | 119                                  |\n",
      "|    time_elapsed            | 8857                                 |\n",
      "|    total_timesteps         | 7798784                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064868545                         |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.03                                |\n",
      "|    explained_variance      | 0.929                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.95                                 |\n",
      "|    n_updates               | 1180                                 |\n",
      "|    policy_gradient_loss    | -0.0133                              |\n",
      "|    value_loss              | 5.06                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=7840000, episode_reward=32.59 +/- 8.47\n",
      "Episode length: 93.90 +/- 8.90\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 93.9                                 |\n",
      "|    mean_reward             | 32.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 276                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 7840000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006340266                          |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -3.01                                |\n",
      "|    explained_variance      | 0.93                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.06                                 |\n",
      "|    n_updates               | 1190                                 |\n",
      "|    policy_gradient_loss    | -0.0137                              |\n",
      "|    value_loss              | 5.18                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 276                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 94.6                                 |\n",
      "|    ep_rew_mean             | 32.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 880                                  |\n",
      "|    iterations              | 120                                  |\n",
      "|    time_elapsed            | 8931                                 |\n",
      "|    total_timesteps         | 7864320                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 273                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 94.2                                 |\n",
      "|    ep_rew_mean             | 32.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 881                                  |\n",
      "|    iterations              | 121                                  |\n",
      "|    time_elapsed            | 8997                                 |\n",
      "|    total_timesteps         | 7929856                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064645614                         |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.99                                |\n",
      "|    explained_variance      | 0.93                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.75                                 |\n",
      "|    n_updates               | 1200                                 |\n",
      "|    policy_gradient_loss    | -0.0137                              |\n",
      "|    value_loss              | 5.24                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 93.5                                 |\n",
      "|    ep_rew_mean             | 33                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 882                                  |\n",
      "|    iterations              | 122                                  |\n",
      "|    time_elapsed            | 9064                                 |\n",
      "|    total_timesteps         | 7995392                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064854305                         |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.97                                |\n",
      "|    explained_variance      | 0.931                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.51                                 |\n",
      "|    n_updates               | 1210                                 |\n",
      "|    policy_gradient_loss    | -0.0135                              |\n",
      "|    value_loss              | 5.32                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=8000000, episode_reward=36.14 +/- 6.76\n",
      "Episode length: 90.25 +/- 6.32\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 90.2                                 |\n",
      "|    mean_reward             | 36.1                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 8000000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006501239                          |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.95                                |\n",
      "|    explained_variance      | 0.934                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.01                                 |\n",
      "|    n_updates               | 1220                                 |\n",
      "|    policy_gradient_loss    | -0.0133                              |\n",
      "|    value_loss              | 5.17                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 91.4                                 |\n",
      "|    ep_rew_mean             | 35.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 882                                  |\n",
      "|    iterations              | 123                                  |\n",
      "|    time_elapsed            | 9138                                 |\n",
      "|    total_timesteps         | 8060928                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 90                                   |\n",
      "|    ep_rew_mean             | 36.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 882                                  |\n",
      "|    iterations              | 124                                  |\n",
      "|    time_elapsed            | 9205                                 |\n",
      "|    total_timesteps         | 8126464                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006406314                          |\n",
      "|    clip_fraction           | 0.29                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.92                                |\n",
      "|    explained_variance      | 0.937                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.33                                 |\n",
      "|    n_updates               | 1230                                 |\n",
      "|    policy_gradient_loss    | -0.0133                              |\n",
      "|    value_loss              | 4.89                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=8160000, episode_reward=35.30 +/- 9.89\n",
      "Episode length: 91.00 +/- 9.71\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 91                                   |\n",
      "|    mean_reward             | 35.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 8160000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006474924                          |\n",
      "|    clip_fraction           | 0.294                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.9                                 |\n",
      "|    explained_variance      | 0.936                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.23                                 |\n",
      "|    n_updates               | 1240                                 |\n",
      "|    policy_gradient_loss    | -0.0133                              |\n",
      "|    value_loss              | 5.14                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 91.8                                 |\n",
      "|    ep_rew_mean             | 34.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 882                                  |\n",
      "|    iterations              | 125                                  |\n",
      "|    time_elapsed            | 9279                                 |\n",
      "|    total_timesteps         | 8192000                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 90                                   |\n",
      "|    ep_rew_mean             | 36.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 883                                  |\n",
      "|    iterations              | 126                                  |\n",
      "|    time_elapsed            | 9345                                 |\n",
      "|    total_timesteps         | 8257536                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0062687984                         |\n",
      "|    clip_fraction           | 0.289                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.88                                |\n",
      "|    explained_variance      | 0.936                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.35                                 |\n",
      "|    n_updates               | 1250                                 |\n",
      "|    policy_gradient_loss    | -0.0132                              |\n",
      "|    value_loss              | 5.14                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=8320000, episode_reward=36.78 +/- 6.70\n",
      "Episode length: 89.35 +/- 6.56\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 89.3                                 |\n",
      "|    mean_reward             | 36.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 8320000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063823545                         |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.86                                |\n",
      "|    explained_variance      | 0.94                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.02                                 |\n",
      "|    n_updates               | 1260                                 |\n",
      "|    policy_gradient_loss    | -0.0127                              |\n",
      "|    value_loss              | 4.99                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 272                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 89.7                                 |\n",
      "|    ep_rew_mean             | 36.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 883                                  |\n",
      "|    iterations              | 127                                  |\n",
      "|    time_elapsed            | 9419                                 |\n",
      "|    total_timesteps         | 8323072                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 88.4                                 |\n",
      "|    ep_rew_mean             | 38.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 884                                  |\n",
      "|    iterations              | 128                                  |\n",
      "|    time_elapsed            | 9487                                 |\n",
      "|    total_timesteps         | 8388608                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063736755                         |\n",
      "|    clip_fraction           | 0.291                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.83                                |\n",
      "|    explained_variance      | 0.941                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.91                                 |\n",
      "|    n_updates               | 1270                                 |\n",
      "|    policy_gradient_loss    | -0.0134                              |\n",
      "|    value_loss              | 5.06                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 87.2                                 |\n",
      "|    ep_rew_mean             | 39.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 884                                  |\n",
      "|    iterations              | 129                                  |\n",
      "|    time_elapsed            | 9555                                 |\n",
      "|    total_timesteps         | 8454144                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065938365                         |\n",
      "|    clip_fraction           | 0.296                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.81                                |\n",
      "|    explained_variance      | 0.944                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.98                                 |\n",
      "|    n_updates               | 1280                                 |\n",
      "|    policy_gradient_loss    | -0.0127                              |\n",
      "|    value_loss              | 4.95                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=8480000, episode_reward=38.49 +/- 7.92\n",
      "Episode length: 89.45 +/- 7.79\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 89.5                                 |\n",
      "|    mean_reward             | 38.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 8480000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00636147                           |\n",
      "|    clip_fraction           | 0.297                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.79                                |\n",
      "|    explained_variance      | 0.945                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.44                                 |\n",
      "|    n_updates               | 1290                                 |\n",
      "|    policy_gradient_loss    | -0.013                               |\n",
      "|    value_loss              | 4.83                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 87.3                                 |\n",
      "|    ep_rew_mean             | 39.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 884                                  |\n",
      "|    iterations              | 130                                  |\n",
      "|    time_elapsed            | 9628                                 |\n",
      "|    total_timesteps         | 8519680                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 87.7                                 |\n",
      "|    ep_rew_mean             | 38.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 885                                  |\n",
      "|    iterations              | 131                                  |\n",
      "|    time_elapsed            | 9694                                 |\n",
      "|    total_timesteps         | 8585216                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006558623                          |\n",
      "|    clip_fraction           | 0.294                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.77                                |\n",
      "|    explained_variance      | 0.947                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.91                                 |\n",
      "|    n_updates               | 1300                                 |\n",
      "|    policy_gradient_loss    | -0.0128                              |\n",
      "|    value_loss              | 4.82                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=8640000, episode_reward=36.09 +/- 6.96\n",
      "Episode length: 90.65 +/- 6.75\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 90.7                                 |\n",
      "|    mean_reward             | 36.1                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 8640000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00648012                           |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.74                                |\n",
      "|    explained_variance      | 0.948                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.64                                 |\n",
      "|    n_updates               | 1310                                 |\n",
      "|    policy_gradient_loss    | -0.0129                              |\n",
      "|    value_loss              | 4.8                                  |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 85.1                                 |\n",
      "|    ep_rew_mean             | 41.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 885                                  |\n",
      "|    iterations              | 132                                  |\n",
      "|    time_elapsed            | 9768                                 |\n",
      "|    total_timesteps         | 8650752                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 84.8                                 |\n",
      "|    ep_rew_mean             | 41.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 886                                  |\n",
      "|    iterations              | 133                                  |\n",
      "|    time_elapsed            | 9834                                 |\n",
      "|    total_timesteps         | 8716288                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006522008                          |\n",
      "|    clip_fraction           | 0.296                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.72                                |\n",
      "|    explained_variance      | 0.946                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.13                                 |\n",
      "|    n_updates               | 1320                                 |\n",
      "|    policy_gradient_loss    | -0.0132                              |\n",
      "|    value_loss              | 5.05                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 85.3                                 |\n",
      "|    ep_rew_mean             | 41.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 886                                  |\n",
      "|    iterations              | 134                                  |\n",
      "|    time_elapsed            | 9902                                 |\n",
      "|    total_timesteps         | 8781824                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006407964                          |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.7                                 |\n",
      "|    explained_variance      | 0.948                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.81                                 |\n",
      "|    n_updates               | 1330                                 |\n",
      "|    policy_gradient_loss    | -0.0131                              |\n",
      "|    value_loss              | 5.08                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=8800000, episode_reward=41.56 +/- 8.52\n",
      "Episode length: 85.25 +/- 8.07\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 85.2                                 |\n",
      "|    mean_reward             | 41.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 8800000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0066866195                         |\n",
      "|    clip_fraction           | 0.298                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.67                                |\n",
      "|    explained_variance      | 0.952                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.66                                 |\n",
      "|    n_updates               | 1340                                 |\n",
      "|    policy_gradient_loss    | -0.0127                              |\n",
      "|    value_loss              | 4.89                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 84.2                                 |\n",
      "|    ep_rew_mean             | 42.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 886                                  |\n",
      "|    iterations              | 135                                  |\n",
      "|    time_elapsed            | 9975                                 |\n",
      "|    total_timesteps         | 8847360                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 82.4                                 |\n",
      "|    ep_rew_mean             | 44.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 887                                  |\n",
      "|    iterations              | 136                                  |\n",
      "|    time_elapsed            | 10041                                |\n",
      "|    total_timesteps         | 8912896                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065530604                         |\n",
      "|    clip_fraction           | 0.296                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.64                                |\n",
      "|    explained_variance      | 0.954                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.58                                 |\n",
      "|    n_updates               | 1350                                 |\n",
      "|    policy_gradient_loss    | -0.0125                              |\n",
      "|    value_loss              | 4.81                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=8960000, episode_reward=42.40 +/- 7.16\n",
      "Episode length: 84.25 +/- 7.31\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 84.2                                 |\n",
      "|    mean_reward             | 42.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 8960000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065200976                         |\n",
      "|    clip_fraction           | 0.295                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.61                                |\n",
      "|    explained_variance      | 0.955                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.97                                 |\n",
      "|    n_updates               | 1360                                 |\n",
      "|    policy_gradient_loss    | -0.0126                              |\n",
      "|    value_loss              | 4.89                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 83.1                                 |\n",
      "|    ep_rew_mean             | 43.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 887                                  |\n",
      "|    iterations              | 137                                  |\n",
      "|    time_elapsed            | 10114                                |\n",
      "|    total_timesteps         | 8978432                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 259                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 82.7                                 |\n",
      "|    ep_rew_mean             | 43.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 888                                  |\n",
      "|    iterations              | 138                                  |\n",
      "|    time_elapsed            | 10180                                |\n",
      "|    total_timesteps         | 9043968                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006520243                          |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.58                                |\n",
      "|    explained_variance      | 0.957                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.19                                 |\n",
      "|    n_updates               | 1370                                 |\n",
      "|    policy_gradient_loss    | -0.0122                              |\n",
      "|    value_loss              | 4.67                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 249                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 81.3                                 |\n",
      "|    ep_rew_mean             | 45.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 889                                  |\n",
      "|    iterations              | 139                                  |\n",
      "|    time_elapsed            | 10245                                |\n",
      "|    total_timesteps         | 9109504                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0068525122                         |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.56                                |\n",
      "|    explained_variance      | 0.955                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.6                                  |\n",
      "|    n_updates               | 1380                                 |\n",
      "|    policy_gradient_loss    | -0.0122                              |\n",
      "|    value_loss              | 4.92                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=9120000, episode_reward=44.80 +/- 7.38\n",
      "Episode length: 81.40 +/- 7.53\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 81.4                                 |\n",
      "|    mean_reward             | 44.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 249                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 9120000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006542302                          |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.52                                |\n",
      "|    explained_variance      | 0.959                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.98                                 |\n",
      "|    n_updates               | 1390                                 |\n",
      "|    policy_gradient_loss    | -0.0124                              |\n",
      "|    value_loss              | 4.71                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 249                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 79.7                                 |\n",
      "|    ep_rew_mean             | 47.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 889                                  |\n",
      "|    iterations              | 140                                  |\n",
      "|    time_elapsed            | 10317                                |\n",
      "|    total_timesteps         | 9175040                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 248                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 79.8                                 |\n",
      "|    ep_rew_mean             | 46.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 889                                  |\n",
      "|    iterations              | 141                                  |\n",
      "|    time_elapsed            | 10383                                |\n",
      "|    total_timesteps         | 9240576                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064100474                         |\n",
      "|    clip_fraction           | 0.298                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.5                                 |\n",
      "|    explained_variance      | 0.96                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.26                                 |\n",
      "|    n_updates               | 1400                                 |\n",
      "|    policy_gradient_loss    | -0.0127                              |\n",
      "|    value_loss              | 4.7                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=9280000, episode_reward=50.38 +/- 5.91\n",
      "Episode length: 75.90 +/- 5.95\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 75.9                                 |\n",
      "|    mean_reward             | 50.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 248                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 9280000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0066642496                         |\n",
      "|    clip_fraction           | 0.295                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.47                                |\n",
      "|    explained_variance      | 0.964                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.06                                 |\n",
      "|    n_updates               | 1410                                 |\n",
      "|    policy_gradient_loss    | -0.0121                              |\n",
      "|    value_loss              | 4.4                                  |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 248                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 78.5                                 |\n",
      "|    ep_rew_mean             | 48.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 890                                  |\n",
      "|    iterations              | 142                                  |\n",
      "|    time_elapsed            | 10455                                |\n",
      "|    total_timesteps         | 9306112                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 241                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 78.7                                 |\n",
      "|    ep_rew_mean             | 48                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 890                                  |\n",
      "|    iterations              | 143                                  |\n",
      "|    time_elapsed            | 10520                                |\n",
      "|    total_timesteps         | 9371648                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006530338                          |\n",
      "|    clip_fraction           | 0.29                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.44                                |\n",
      "|    explained_variance      | 0.963                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.46                                 |\n",
      "|    n_updates               | 1420                                 |\n",
      "|    policy_gradient_loss    | -0.0119                              |\n",
      "|    value_loss              | 4.66                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 241                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 77.5                                 |\n",
      "|    ep_rew_mean             | 49.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 891                                  |\n",
      "|    iterations              | 144                                  |\n",
      "|    time_elapsed            | 10586                                |\n",
      "|    total_timesteps         | 9437184                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006788064                          |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.4                                 |\n",
      "|    explained_variance      | 0.965                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.14                                 |\n",
      "|    n_updates               | 1430                                 |\n",
      "|    policy_gradient_loss    | -0.012                               |\n",
      "|    value_loss              | 4.6                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=9440000, episode_reward=49.30 +/- 6.09\n",
      "Episode length: 77.10 +/- 6.15\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 77.1                                 |\n",
      "|    mean_reward             | 49.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 241                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 9440000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006439124                          |\n",
      "|    clip_fraction           | 0.291                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.37                                |\n",
      "|    explained_variance      | 0.965                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.55                                 |\n",
      "|    n_updates               | 1440                                 |\n",
      "|    policy_gradient_loss    | -0.0118                              |\n",
      "|    value_loss              | 4.73                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 241                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 77.4                                 |\n",
      "|    ep_rew_mean             | 49.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 891                                  |\n",
      "|    iterations              | 145                                  |\n",
      "|    time_elapsed            | 10657                                |\n",
      "|    total_timesteps         | 9502720                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 241                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 75.8                                 |\n",
      "|    ep_rew_mean             | 51                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 892                                  |\n",
      "|    iterations              | 146                                  |\n",
      "|    time_elapsed            | 10723                                |\n",
      "|    total_timesteps         | 9568256                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065902127                         |\n",
      "|    clip_fraction           | 0.293                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.34                                |\n",
      "|    explained_variance      | 0.968                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.36                                 |\n",
      "|    n_updates               | 1450                                 |\n",
      "|    policy_gradient_loss    | -0.0119                              |\n",
      "|    value_loss              | 4.35                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=9600000, episode_reward=50.96 +/- 7.65\n",
      "Episode length: 75.85 +/- 8.42\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 75.8                                 |\n",
      "|    mean_reward             | 51                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 241                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 9600000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0068872985                         |\n",
      "|    clip_fraction           | 0.292                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.3                                 |\n",
      "|    explained_variance      | 0.969                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.51                                 |\n",
      "|    n_updates               | 1460                                 |\n",
      "|    policy_gradient_loss    | -0.0115                              |\n",
      "|    value_loss              | 4.34                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 74.3                                 |\n",
      "|    ep_rew_mean             | 52.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 892                                  |\n",
      "|    iterations              | 147                                  |\n",
      "|    time_elapsed            | 10797                                |\n",
      "|    total_timesteps         | 9633792                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 73.9                                 |\n",
      "|    ep_rew_mean             | 52.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 892                                  |\n",
      "|    iterations              | 148                                  |\n",
      "|    time_elapsed            | 10863                                |\n",
      "|    total_timesteps         | 9699328                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0069081686                         |\n",
      "|    clip_fraction           | 0.287                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.26                                |\n",
      "|    explained_variance      | 0.97                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.68                                 |\n",
      "|    n_updates               | 1470                                 |\n",
      "|    policy_gradient_loss    | -0.011                               |\n",
      "|    value_loss              | 4.4                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=9760000, episode_reward=50.32 +/- 9.97\n",
      "Episode length: 76.05 +/- 9.51\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 76                                   |\n",
      "|    mean_reward             | 50.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 9760000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065803127                         |\n",
      "|    clip_fraction           | 0.282                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.22                                |\n",
      "|    explained_variance      | 0.972                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.31                                 |\n",
      "|    n_updates               | 1480                                 |\n",
      "|    policy_gradient_loss    | -0.0112                              |\n",
      "|    value_loss              | 4.27                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 75                                   |\n",
      "|    ep_rew_mean             | 52.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 893                                  |\n",
      "|    iterations              | 149                                  |\n",
      "|    time_elapsed            | 10934                                |\n",
      "|    total_timesteps         | 9764864                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 72.9                                 |\n",
      "|    ep_rew_mean             | 53.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 893                                  |\n",
      "|    iterations              | 150                                  |\n",
      "|    time_elapsed            | 10999                                |\n",
      "|    total_timesteps         | 9830400                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064222296                         |\n",
      "|    clip_fraction           | 0.288                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.19                                |\n",
      "|    explained_variance      | 0.974                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.47                                 |\n",
      "|    n_updates               | 1490                                 |\n",
      "|    policy_gradient_loss    | -0.011                               |\n",
      "|    value_loss              | 4.15                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 70.9                                 |\n",
      "|    ep_rew_mean             | 55.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 894                                  |\n",
      "|    iterations              | 151                                  |\n",
      "|    time_elapsed            | 11064                                |\n",
      "|    total_timesteps         | 9895936                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006477357                          |\n",
      "|    clip_fraction           | 0.285                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.15                                |\n",
      "|    explained_variance      | 0.975                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.57                                 |\n",
      "|    n_updates               | 1500                                 |\n",
      "|    policy_gradient_loss    | -0.0106                              |\n",
      "|    value_loss              | 4.17                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=9920000, episode_reward=57.25 +/- 4.73\n",
      "Episode length: 69.45 +/- 5.12\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 69.5                                 |\n",
      "|    mean_reward             | 57.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 9920000                              |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006459033                          |\n",
      "|    clip_fraction           | 0.286                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.12                                |\n",
      "|    explained_variance      | 0.975                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.87                                 |\n",
      "|    n_updates               | 1510                                 |\n",
      "|    policy_gradient_loss    | -0.0105                              |\n",
      "|    value_loss              | 4.02                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 231                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 70.6                                 |\n",
      "|    ep_rew_mean             | 55.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 894                                  |\n",
      "|    iterations              | 152                                  |\n",
      "|    time_elapsed            | 11134                                |\n",
      "|    total_timesteps         | 9961472                              |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 229                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 70.7                                 |\n",
      "|    ep_rew_mean             | 56                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 895                                  |\n",
      "|    iterations              | 153                                  |\n",
      "|    time_elapsed            | 11199                                |\n",
      "|    total_timesteps         | 10027008                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0066257613                         |\n",
      "|    clip_fraction           | 0.285                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.06                                |\n",
      "|    explained_variance      | 0.977                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.48                                 |\n",
      "|    n_updates               | 1520                                 |\n",
      "|    policy_gradient_loss    | -0.011                               |\n",
      "|    value_loss              | 4.07                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=10080000, episode_reward=56.92 +/- 3.96\n",
      "Episode length: 69.15 +/- 3.55\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 69.2                                 |\n",
      "|    mean_reward             | 56.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 228                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 10080000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065137786                         |\n",
      "|    clip_fraction           | 0.284                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -2.04                                |\n",
      "|    explained_variance      | 0.978                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.51                                 |\n",
      "|    n_updates               | 1530                                 |\n",
      "|    policy_gradient_loss    | -0.0106                              |\n",
      "|    value_loss              | 3.99                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 228                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 69.3                                 |\n",
      "|    ep_rew_mean             | 57.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 895                                  |\n",
      "|    iterations              | 154                                  |\n",
      "|    time_elapsed            | 11269                                |\n",
      "|    total_timesteps         | 10092544                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 227                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 68.5                                 |\n",
      "|    ep_rew_mean             | 58.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 896                                  |\n",
      "|    iterations              | 155                                  |\n",
      "|    time_elapsed            | 11333                                |\n",
      "|    total_timesteps         | 10158080                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0068599936                         |\n",
      "|    clip_fraction           | 0.287                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.99                                |\n",
      "|    explained_variance      | 0.978                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.15                                 |\n",
      "|    n_updates               | 1540                                 |\n",
      "|    policy_gradient_loss    | -0.0104                              |\n",
      "|    value_loss              | 4.09                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 227                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 67.2                                 |\n",
      "|    ep_rew_mean             | 59.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 896                                  |\n",
      "|    iterations              | 156                                  |\n",
      "|    time_elapsed            | 11398                                |\n",
      "|    total_timesteps         | 10223616                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0067020096                         |\n",
      "|    clip_fraction           | 0.281                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.96                                |\n",
      "|    explained_variance      | 0.982                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.52                                 |\n",
      "|    n_updates               | 1550                                 |\n",
      "|    policy_gradient_loss    | -0.0106                              |\n",
      "|    value_loss              | 3.64                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=10240000, episode_reward=59.51 +/- 5.15\n",
      "Episode length: 66.80 +/- 5.17\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 66.8                                 |\n",
      "|    mean_reward             | 59.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 227                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 10240000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0066499105                         |\n",
      "|    clip_fraction           | 0.278                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.9                                 |\n",
      "|    explained_variance      | 0.983                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.57                                 |\n",
      "|    n_updates               | 1560                                 |\n",
      "|    policy_gradient_loss    | -0.0101                              |\n",
      "|    value_loss              | 3.56                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 223                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 66.4                                 |\n",
      "|    ep_rew_mean             | 60.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 897                                  |\n",
      "|    iterations              | 157                                  |\n",
      "|    time_elapsed            | 11468                                |\n",
      "|    total_timesteps         | 10289152                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 222                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 66.1                                 |\n",
      "|    ep_rew_mean             | 60.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 897                                  |\n",
      "|    iterations              | 158                                  |\n",
      "|    time_elapsed            | 11532                                |\n",
      "|    total_timesteps         | 10354688                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0067275288                         |\n",
      "|    clip_fraction           | 0.279                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.86                                |\n",
      "|    explained_variance      | 0.984                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.61                                 |\n",
      "|    n_updates               | 1570                                 |\n",
      "|    policy_gradient_loss    | -0.0104                              |\n",
      "|    value_loss              | 3.53                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=10400000, episode_reward=59.32 +/- 5.19\n",
      "Episode length: 67.30 +/- 5.31\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 67.3                                 |\n",
      "|    mean_reward             | 59.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 222                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 10400000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0065961336                         |\n",
      "|    clip_fraction           | 0.276                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.81                                |\n",
      "|    explained_variance      | 0.984                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.43                                 |\n",
      "|    n_updates               | 1580                                 |\n",
      "|    policy_gradient_loss    | -0.01                                |\n",
      "|    value_loss              | 3.48                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 219                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 64                                   |\n",
      "|    ep_rew_mean             | 62.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 898                                  |\n",
      "|    iterations              | 159                                  |\n",
      "|    time_elapsed            | 11602                                |\n",
      "|    total_timesteps         | 10420224                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 218                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 64                                   |\n",
      "|    ep_rew_mean             | 62.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 898                                  |\n",
      "|    iterations              | 160                                  |\n",
      "|    time_elapsed            | 11666                                |\n",
      "|    total_timesteps         | 10485760                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0067675794                         |\n",
      "|    clip_fraction           | 0.276                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.76                                |\n",
      "|    explained_variance      | 0.986                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.47                                 |\n",
      "|    n_updates               | 1590                                 |\n",
      "|    policy_gradient_loss    | -0.01                                |\n",
      "|    value_loss              | 3.29                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 204                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 62.8                                 |\n",
      "|    ep_rew_mean             | 63.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 899                                  |\n",
      "|    iterations              | 161                                  |\n",
      "|    time_elapsed            | 11730                                |\n",
      "|    total_timesteps         | 10551296                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0067456984                         |\n",
      "|    clip_fraction           | 0.272                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.7                                 |\n",
      "|    explained_variance      | 0.987                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.44                                 |\n",
      "|    n_updates               | 1600                                 |\n",
      "|    policy_gradient_loss    | -0.0095                              |\n",
      "|    value_loss              | 3.34                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=10560000, episode_reward=65.68 +/- 4.15\n",
      "Episode length: 60.25 +/- 4.07\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 60.2                                 |\n",
      "|    mean_reward             | 65.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 204                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 10560000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0070995027                         |\n",
      "|    clip_fraction           | 0.274                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.66                                |\n",
      "|    explained_variance      | 0.987                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.65                                 |\n",
      "|    n_updates               | 1610                                 |\n",
      "|    policy_gradient_loss    | -0.00981                             |\n",
      "|    value_loss              | 3.38                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 204                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 63.4                                 |\n",
      "|    ep_rew_mean             | 63.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 899                                  |\n",
      "|    iterations              | 162                                  |\n",
      "|    time_elapsed            | 11799                                |\n",
      "|    total_timesteps         | 10616832                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 204                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 61.2                                 |\n",
      "|    ep_rew_mean             | 65.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 900                                  |\n",
      "|    iterations              | 163                                  |\n",
      "|    time_elapsed            | 11863                                |\n",
      "|    total_timesteps         | 10682368                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007014608                          |\n",
      "|    clip_fraction           | 0.262                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.6                                 |\n",
      "|    explained_variance      | 0.988                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.63                                 |\n",
      "|    n_updates               | 1620                                 |\n",
      "|    policy_gradient_loss    | -0.00909                             |\n",
      "|    value_loss              | 3.28                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=10720000, episode_reward=67.27 +/- 3.60\n",
      "Episode length: 58.85 +/- 4.09\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 58.9                                 |\n",
      "|    mean_reward             | 67.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 204                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 10720000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0070163887                         |\n",
      "|    clip_fraction           | 0.262                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.54                                |\n",
      "|    explained_variance      | 0.989                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.38                                 |\n",
      "|    n_updates               | 1630                                 |\n",
      "|    policy_gradient_loss    | -0.0087                              |\n",
      "|    value_loss              | 2.9                                  |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 204                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 60.3                                 |\n",
      "|    ep_rew_mean             | 66.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 900                                  |\n",
      "|    iterations              | 164                                  |\n",
      "|    time_elapsed            | 11934                                |\n",
      "|    total_timesteps         | 10747904                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 202                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 58.4                                 |\n",
      "|    ep_rew_mean             | 67.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 901                                  |\n",
      "|    iterations              | 165                                  |\n",
      "|    time_elapsed            | 11999                                |\n",
      "|    total_timesteps         | 10813440                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0076201083                         |\n",
      "|    clip_fraction           | 0.252                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.48                                |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.35                                 |\n",
      "|    n_updates               | 1640                                 |\n",
      "|    policy_gradient_loss    | -0.00863                             |\n",
      "|    value_loss              | 2.82                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 195                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 57.9                                 |\n",
      "|    ep_rew_mean             | 68.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 901                                  |\n",
      "|    iterations              | 166                                  |\n",
      "|    time_elapsed            | 12063                                |\n",
      "|    total_timesteps         | 10878976                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0068025715                         |\n",
      "|    clip_fraction           | 0.251                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.42                                |\n",
      "|    explained_variance      | 0.991                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.3                                  |\n",
      "|    n_updates               | 1650                                 |\n",
      "|    policy_gradient_loss    | -0.00813                             |\n",
      "|    value_loss              | 2.71                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=10880000, episode_reward=69.05 +/- 5.65\n",
      "Episode length: 57.05 +/- 6.21\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 57                                   |\n",
      "|    mean_reward             | 69                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 195                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 10880000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0066188253                         |\n",
      "|    clip_fraction           | 0.248                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.35                                |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.13                                 |\n",
      "|    n_updates               | 1660                                 |\n",
      "|    policy_gradient_loss    | -0.00777                             |\n",
      "|    value_loss              | 2.59                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 195                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 57                                   |\n",
      "|    ep_rew_mean             | 69.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 902                                  |\n",
      "|    iterations              | 167                                  |\n",
      "|    time_elapsed            | 12131                                |\n",
      "|    total_timesteps         | 10944512                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 192                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 55.8                                 |\n",
      "|    ep_rew_mean             | 70.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 902                                  |\n",
      "|    iterations              | 168                                  |\n",
      "|    time_elapsed            | 12194                                |\n",
      "|    total_timesteps         | 11010048                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006752451                          |\n",
      "|    clip_fraction           | 0.246                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.29                                |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.13                                 |\n",
      "|    n_updates               | 1670                                 |\n",
      "|    policy_gradient_loss    | -0.00773                             |\n",
      "|    value_loss              | 2.43                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=11040000, episode_reward=70.76 +/- 4.55\n",
      "Episode length: 55.55 +/- 5.01\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 55.5                                 |\n",
      "|    mean_reward             | 70.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 192                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 11040000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063932366                         |\n",
      "|    clip_fraction           | 0.237                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.24                                |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.1                                  |\n",
      "|    n_updates               | 1680                                 |\n",
      "|    policy_gradient_loss    | -0.00758                             |\n",
      "|    value_loss              | 2.36                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 192                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 54.8                                 |\n",
      "|    ep_rew_mean             | 71.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 903                                  |\n",
      "|    iterations              | 169                                  |\n",
      "|    time_elapsed            | 12262                                |\n",
      "|    total_timesteps         | 11075584                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 192                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 53.6                                 |\n",
      "|    ep_rew_mean             | 72.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 903                                  |\n",
      "|    iterations              | 170                                  |\n",
      "|    time_elapsed            | 12326                                |\n",
      "|    total_timesteps         | 11141120                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006632667                          |\n",
      "|    clip_fraction           | 0.237                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.16                                |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.883                                |\n",
      "|    n_updates               | 1690                                 |\n",
      "|    policy_gradient_loss    | -0.00719                             |\n",
      "|    value_loss              | 2.14                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=11200000, episode_reward=73.44 +/- 2.94\n",
      "Episode length: 52.80 +/- 3.34\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 52.8                                 |\n",
      "|    mean_reward             | 73.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 192                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 11200000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063556153                         |\n",
      "|    clip_fraction           | 0.23                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.08                                |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.886                                |\n",
      "|    n_updates               | 1700                                 |\n",
      "|    policy_gradient_loss    | -0.00681                             |\n",
      "|    value_loss              | 1.92                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 192                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 52.8                                 |\n",
      "|    ep_rew_mean             | 73.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 904                                  |\n",
      "|    iterations              | 171                                  |\n",
      "|    time_elapsed            | 12393                                |\n",
      "|    total_timesteps         | 11206656                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 192                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 51.3                                 |\n",
      "|    ep_rew_mean             | 74.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 904                                  |\n",
      "|    iterations              | 172                                  |\n",
      "|    time_elapsed            | 12456                                |\n",
      "|    total_timesteps         | 11272192                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0087615205                         |\n",
      "|    clip_fraction           | 0.224                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.01                                |\n",
      "|    explained_variance      | 0.995                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.04                                 |\n",
      "|    n_updates               | 1710                                 |\n",
      "|    policy_gradient_loss    | -0.00695                             |\n",
      "|    value_loss              | 1.85                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 189                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 51                                   |\n",
      "|    ep_rew_mean             | 74.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 905                                  |\n",
      "|    iterations              | 173                                  |\n",
      "|    time_elapsed            | 12521                                |\n",
      "|    total_timesteps         | 11337728                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006398608                          |\n",
      "|    clip_fraction           | 0.212                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.934                               |\n",
      "|    explained_variance      | 0.995                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.758                                |\n",
      "|    n_updates               | 1720                                 |\n",
      "|    policy_gradient_loss    | -0.00608                             |\n",
      "|    value_loss              | 1.82                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=11360000, episode_reward=75.10 +/- 2.75\n",
      "Episode length: 51.10 +/- 2.93\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 51.1                                 |\n",
      "|    mean_reward             | 75.1                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 189                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 11360000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006646702                          |\n",
      "|    clip_fraction           | 0.21                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.849                               |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.72                                 |\n",
      "|    n_updates               | 1730                                 |\n",
      "|    policy_gradient_loss    | -0.00566                             |\n",
      "|    value_loss              | 1.49                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 189                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 50.1                                 |\n",
      "|    ep_rew_mean             | 76                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 905                                  |\n",
      "|    iterations              | 174                                  |\n",
      "|    time_elapsed            | 12588                                |\n",
      "|    total_timesteps         | 11403264                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 189                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 49.5                                 |\n",
      "|    ep_rew_mean             | 76.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 906                                  |\n",
      "|    iterations              | 175                                  |\n",
      "|    time_elapsed            | 12651                                |\n",
      "|    total_timesteps         | 11468800                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007133807                          |\n",
      "|    clip_fraction           | 0.204                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.785                               |\n",
      "|    explained_variance      | 0.997                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.648                                |\n",
      "|    n_updates               | 1740                                 |\n",
      "|    policy_gradient_loss    | -0.00572                             |\n",
      "|    value_loss              | 1.36                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=11520000, episode_reward=78.03 +/- 1.87\n",
      "Episode length: 48.05 +/- 2.58\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 48                                   |\n",
      "|    mean_reward             | 78                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 189                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 11520000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007298862                          |\n",
      "|    clip_fraction           | 0.194                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.719                               |\n",
      "|    explained_variance      | 0.997                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.727                                |\n",
      "|    n_updates               | 1750                                 |\n",
      "|    policy_gradient_loss    | -0.00512                             |\n",
      "|    value_loss              | 1.27                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 189                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 48.9                                 |\n",
      "|    ep_rew_mean             | 77.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 906                                  |\n",
      "|    iterations              | 176                                  |\n",
      "|    time_elapsed            | 12718                                |\n",
      "|    total_timesteps         | 11534336                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 188                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 47.8                                 |\n",
      "|    ep_rew_mean             | 78.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 907                                  |\n",
      "|    iterations              | 177                                  |\n",
      "|    time_elapsed            | 12783                                |\n",
      "|    total_timesteps         | 11599872                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0063802204                         |\n",
      "|    clip_fraction           | 0.18                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.645                               |\n",
      "|    explained_variance      | 0.997                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.452                                |\n",
      "|    n_updates               | 1760                                 |\n",
      "|    policy_gradient_loss    | -0.0046                              |\n",
      "|    value_loss              | 1.19                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 188                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 47.4                                 |\n",
      "|    ep_rew_mean             | 78.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 907                                  |\n",
      "|    iterations              | 178                                  |\n",
      "|    time_elapsed            | 12847                                |\n",
      "|    total_timesteps         | 11665408                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0061058877                         |\n",
      "|    clip_fraction           | 0.165                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.557                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.282                                |\n",
      "|    n_updates               | 1770                                 |\n",
      "|    policy_gradient_loss    | -0.00294                             |\n",
      "|    value_loss              | 0.848                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=11680000, episode_reward=79.32 +/- 1.84\n",
      "Episode length: 47.15 +/- 1.74\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 47.1                                 |\n",
      "|    mean_reward             | 79.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 11680000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064708213                         |\n",
      "|    clip_fraction           | 0.158                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.495                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.328                                |\n",
      "|    n_updates               | 1780                                 |\n",
      "|    policy_gradient_loss    | -0.00322                             |\n",
      "|    value_loss              | 0.677                                |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 47.1                                 |\n",
      "|    ep_rew_mean             | 79.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 908                                  |\n",
      "|    iterations              | 179                                  |\n",
      "|    time_elapsed            | 12914                                |\n",
      "|    total_timesteps         | 11730944                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.6                                 |\n",
      "|    ep_rew_mean             | 79.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 909                                  |\n",
      "|    iterations              | 180                                  |\n",
      "|    time_elapsed            | 12976                                |\n",
      "|    total_timesteps         | 11796480                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005874334                          |\n",
      "|    clip_fraction           | 0.145                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.45                                |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.313                                |\n",
      "|    n_updates               | 1790                                 |\n",
      "|    policy_gradient_loss    | -0.00346                             |\n",
      "|    value_loss              | 0.839                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=11840000, episode_reward=79.67 +/- 2.14\n",
      "Episode length: 46.85 +/- 2.06\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 46.9                                 |\n",
      "|    mean_reward             | 79.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 11840000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006063776                          |\n",
      "|    clip_fraction           | 0.139                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.396                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.181                                |\n",
      "|    n_updates               | 1800                                 |\n",
      "|    policy_gradient_loss    | -0.00216                             |\n",
      "|    value_loss              | 0.662                                |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.2                                 |\n",
      "|    ep_rew_mean             | 79.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 909                                  |\n",
      "|    iterations              | 181                                  |\n",
      "|    time_elapsed            | 13042                                |\n",
      "|    total_timesteps         | 11862016                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.1                                 |\n",
      "|    ep_rew_mean             | 79.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 910                                  |\n",
      "|    iterations              | 182                                  |\n",
      "|    time_elapsed            | 13105                                |\n",
      "|    total_timesteps         | 11927552                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0061852                            |\n",
      "|    clip_fraction           | 0.128                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.339                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.119                                |\n",
      "|    n_updates               | 1810                                 |\n",
      "|    policy_gradient_loss    | -0.0018                              |\n",
      "|    value_loss              | 0.486                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45.8                                 |\n",
      "|    ep_rew_mean             | 80.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 910                                  |\n",
      "|    iterations              | 183                                  |\n",
      "|    time_elapsed            | 13168                                |\n",
      "|    total_timesteps         | 11993088                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00585098                           |\n",
      "|    clip_fraction           | 0.115                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.304                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0857                               |\n",
      "|    n_updates               | 1820                                 |\n",
      "|    policy_gradient_loss    | -0.00134                             |\n",
      "|    value_loss              | 0.403                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=12000000, episode_reward=77.95 +/- 11.24\n",
      "Episode length: 48.05 +/- 11.94\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 48                                   |\n",
      "|    mean_reward             | 77.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 12000000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006117845                          |\n",
      "|    clip_fraction           | 0.117                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.274                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.127                                |\n",
      "|    n_updates               | 1830                                 |\n",
      "|    policy_gradient_loss    | -0.000284                            |\n",
      "|    value_loss              | 0.296                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45.5                                 |\n",
      "|    ep_rew_mean             | 80.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 911                                  |\n",
      "|    iterations              | 184                                  |\n",
      "|    time_elapsed            | 13233                                |\n",
      "|    total_timesteps         | 12058624                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45                                   |\n",
      "|    ep_rew_mean             | 80.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 911                                  |\n",
      "|    iterations              | 185                                  |\n",
      "|    time_elapsed            | 13296                                |\n",
      "|    total_timesteps         | 12124160                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009130943                          |\n",
      "|    clip_fraction           | 0.122                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.262                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.405                                |\n",
      "|    n_updates               | 1840                                 |\n",
      "|    policy_gradient_loss    | -0.00131                             |\n",
      "|    value_loss              | 0.359                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=12160000, episode_reward=80.65 +/- 1.51\n",
      "Episode length: 45.00 +/- 1.45\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 45                                   |\n",
      "|    mean_reward             | 80.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 12160000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0068818396                         |\n",
      "|    clip_fraction           | 0.12                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.26                                |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0316                               |\n",
      "|    n_updates               | 1850                                 |\n",
      "|    policy_gradient_loss    | -0.00197                             |\n",
      "|    value_loss              | 0.298                                |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.8                                 |\n",
      "|    ep_rew_mean             | 80.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 912                                  |\n",
      "|    iterations              | 186                                  |\n",
      "|    time_elapsed            | 13363                                |\n",
      "|    total_timesteps         | 12189696                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.9                                 |\n",
      "|    ep_rew_mean             | 80.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 912                                  |\n",
      "|    iterations              | 187                                  |\n",
      "|    time_elapsed            | 13426                                |\n",
      "|    total_timesteps         | 12255232                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005777682                          |\n",
      "|    clip_fraction           | 0.118                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.252                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.316                                |\n",
      "|    n_updates               | 1860                                 |\n",
      "|    policy_gradient_loss    | -0.00115                             |\n",
      "|    value_loss              | 0.473                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=12320000, episode_reward=81.33 +/- 0.53\n",
      "Episode length: 44.30 +/- 1.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 44.3                                 |\n",
      "|    mean_reward             | 81.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 12320000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007616359                          |\n",
      "|    clip_fraction           | 0.122                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.245                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.35                                 |\n",
      "|    n_updates               | 1870                                 |\n",
      "|    policy_gradient_loss    | -0.00275                             |\n",
      "|    value_loss              | 0.506                                |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.6                                 |\n",
      "|    ep_rew_mean             | 81                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 913                                  |\n",
      "|    iterations              | 188                                  |\n",
      "|    time_elapsed            | 13492                                |\n",
      "|    total_timesteps         | 12320768                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.2                                 |\n",
      "|    ep_rew_mean             | 81.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 913                                  |\n",
      "|    iterations              | 189                                  |\n",
      "|    time_elapsed            | 13554                                |\n",
      "|    total_timesteps         | 12386304                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009027492                          |\n",
      "|    clip_fraction           | 0.127                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.226                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.285                                |\n",
      "|    n_updates               | 1880                                 |\n",
      "|    policy_gradient_loss    | -0.00185                             |\n",
      "|    value_loss              | 0.483                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44                                   |\n",
      "|    ep_rew_mean             | 81.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 914                                  |\n",
      "|    iterations              | 190                                  |\n",
      "|    time_elapsed            | 13617                                |\n",
      "|    total_timesteps         | 12451840                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006628435                          |\n",
      "|    clip_fraction           | 0.115                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.212                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0454                               |\n",
      "|    n_updates               | 1890                                 |\n",
      "|    policy_gradient_loss    | -0.00306                             |\n",
      "|    value_loss              | 0.537                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=12480000, episode_reward=81.66 +/- 0.35\n",
      "Episode length: 43.70 +/- 0.90\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 43.7                                 |\n",
      "|    mean_reward             | 81.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 12480000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00717393                           |\n",
      "|    clip_fraction           | 0.112                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.19                                |\n",
      "|    explained_variance      | 1                                    |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0699                               |\n",
      "|    n_updates               | 1900                                 |\n",
      "|    policy_gradient_loss    | -0.00288                             |\n",
      "|    value_loss              | 0.207                                |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.5                                 |\n",
      "|    ep_rew_mean             | 80.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 914                                  |\n",
      "|    iterations              | 191                                  |\n",
      "|    time_elapsed            | 13683                                |\n",
      "|    total_timesteps         | 12517376                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.6                                 |\n",
      "|    ep_rew_mean             | 81.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 915                                  |\n",
      "|    iterations              | 192                                  |\n",
      "|    time_elapsed            | 13746                                |\n",
      "|    total_timesteps         | 12582912                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005966896                          |\n",
      "|    clip_fraction           | 0.108                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.19                                |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0621                               |\n",
      "|    n_updates               | 1910                                 |\n",
      "|    policy_gradient_loss    | -0.00199                             |\n",
      "|    value_loss              | 0.543                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=12640000, episode_reward=81.92 +/- 0.33\n",
      "Episode length: 43.25 +/- 0.99\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 43.2                                 |\n",
      "|    mean_reward             | 81.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 12640000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007893937                          |\n",
      "|    clip_fraction           | 0.114                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.188                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0522                               |\n",
      "|    n_updates               | 1920                                 |\n",
      "|    policy_gradient_loss    | -0.00409                             |\n",
      "|    value_loss              | 0.727                                |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.7                                 |\n",
      "|    ep_rew_mean             | 81.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 915                                  |\n",
      "|    iterations              | 193                                  |\n",
      "|    time_elapsed            | 13811                                |\n",
      "|    total_timesteps         | 12648448                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.3                                 |\n",
      "|    ep_rew_mean             | 82                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 916                                  |\n",
      "|    iterations              | 194                                  |\n",
      "|    time_elapsed            | 13873                                |\n",
      "|    total_timesteps         | 12713984                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007141241                          |\n",
      "|    clip_fraction           | 0.121                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.176                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0766                               |\n",
      "|    n_updates               | 1930                                 |\n",
      "|    policy_gradient_loss    | -0.00384                             |\n",
      "|    value_loss              | 0.438                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.1                                 |\n",
      "|    ep_rew_mean             | 82                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 916                                  |\n",
      "|    iterations              | 195                                  |\n",
      "|    time_elapsed            | 13936                                |\n",
      "|    total_timesteps         | 12779520                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008218037                          |\n",
      "|    clip_fraction           | 0.109                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.161                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.079                                |\n",
      "|    n_updates               | 1940                                 |\n",
      "|    policy_gradient_loss    | -0.00186                             |\n",
      "|    value_loss              | 0.282                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=12800000, episode_reward=81.65 +/- 2.33\n",
      "Episode length: 43.60 +/- 2.08\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 43.6                                 |\n",
      "|    mean_reward             | 81.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 12800000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.010978697                          |\n",
      "|    clip_fraction           | 0.116                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.145                               |\n",
      "|    explained_variance      | 1                                    |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0383                               |\n",
      "|    n_updates               | 1950                                 |\n",
      "|    policy_gradient_loss    | -0.0036                              |\n",
      "|    value_loss              | 0.128                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.3                                 |\n",
      "|    ep_rew_mean             | 81.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 917                                  |\n",
      "|    iterations              | 196                                  |\n",
      "|    time_elapsed            | 14002                                |\n",
      "|    total_timesteps         | 12845056                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.6                                 |\n",
      "|    ep_rew_mean             | 81.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 917                                  |\n",
      "|    iterations              | 197                                  |\n",
      "|    time_elapsed            | 14065                                |\n",
      "|    total_timesteps         | 12910592                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.012246754                          |\n",
      "|    clip_fraction           | 0.0897                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.138                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0157                               |\n",
      "|    n_updates               | 1960                                 |\n",
      "|    policy_gradient_loss    | -6.66e-05                            |\n",
      "|    value_loss              | 0.232                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=12960000, episode_reward=80.77 +/- 5.57\n",
      "Episode length: 43.90 +/- 5.34\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 43.9                                 |\n",
      "|    mean_reward             | 80.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 12960000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.06543994                           |\n",
      "|    clip_fraction           | 0.123                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.156                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.186                                |\n",
      "|    n_updates               | 1970                                 |\n",
      "|    policy_gradient_loss    | -0.00445                             |\n",
      "|    value_loss              | 0.48                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43                                   |\n",
      "|    ep_rew_mean             | 81.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 918                                  |\n",
      "|    iterations              | 198                                  |\n",
      "|    time_elapsed            | 14130                                |\n",
      "|    total_timesteps         | 12976128                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 63.3                                 |\n",
      "|    ep_rew_mean             | 60.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 918                                  |\n",
      "|    iterations              | 199                                  |\n",
      "|    time_elapsed            | 14195                                |\n",
      "|    total_timesteps         | 13041664                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.020395853                          |\n",
      "|    clip_fraction           | 0.118                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.18                                |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0209                               |\n",
      "|    n_updates               | 1980                                 |\n",
      "|    policy_gradient_loss    | -0.00191                             |\n",
      "|    value_loss              | 0.275                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 56.3                                 |\n",
      "|    ep_rew_mean             | 67.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 919                                  |\n",
      "|    iterations              | 200                                  |\n",
      "|    time_elapsed            | 14258                                |\n",
      "|    total_timesteps         | 13107200                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0077650826                         |\n",
      "|    clip_fraction           | 0.179                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.09                                |\n",
      "|    explained_variance      | 0.904                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 12.3                                 |\n",
      "|    n_updates               | 1990                                 |\n",
      "|    policy_gradient_loss    | -0.00835                             |\n",
      "|    value_loss              | 23.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=13120000, episode_reward=69.69 +/- 31.22\n",
      "Episode length: 54.30 +/- 27.75\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 54.3                                 |\n",
      "|    mean_reward             | 69.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 13120000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008884666                          |\n",
      "|    clip_fraction           | 0.183                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.811                               |\n",
      "|    explained_variance      | 0.939                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 10.4                                 |\n",
      "|    n_updates               | 2000                                 |\n",
      "|    policy_gradient_loss    | -0.00678                             |\n",
      "|    value_loss              | 28.2                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 47.8                                 |\n",
      "|    ep_rew_mean             | 77                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 919                                  |\n",
      "|    iterations              | 201                                  |\n",
      "|    time_elapsed            | 14326                                |\n",
      "|    total_timesteps         | 13172736                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45                                   |\n",
      "|    ep_rew_mean             | 80                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 919                                  |\n",
      "|    iterations              | 202                                  |\n",
      "|    time_elapsed            | 14389                                |\n",
      "|    total_timesteps         | 13238272                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0099575315                         |\n",
      "|    clip_fraction           | 0.137                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.439                               |\n",
      "|    explained_variance      | 0.967                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.49                                 |\n",
      "|    n_updates               | 2010                                 |\n",
      "|    policy_gradient_loss    | -0.00547                             |\n",
      "|    value_loss              | 14.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=13280000, episode_reward=81.96 +/- 0.77\n",
      "Episode length: 42.70 +/- 1.05\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 42.7                                 |\n",
      "|    mean_reward             | 82                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 13280000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008895096                          |\n",
      "|    clip_fraction           | 0.118                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.233                               |\n",
      "|    explained_variance      | 0.987                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.603                                |\n",
      "|    n_updates               | 2020                                 |\n",
      "|    policy_gradient_loss    | -0.00288                             |\n",
      "|    value_loss              | 4.71                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.9                                 |\n",
      "|    ep_rew_mean             | 80.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 920                                  |\n",
      "|    iterations              | 203                                  |\n",
      "|    time_elapsed            | 14455                                |\n",
      "|    total_timesteps         | 13303808                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.5                                 |\n",
      "|    ep_rew_mean             | 82.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 920                                  |\n",
      "|    iterations              | 204                                  |\n",
      "|    time_elapsed            | 14518                                |\n",
      "|    total_timesteps         | 13369344                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.011242425                          |\n",
      "|    clip_fraction           | 0.097                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.163                               |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.112                                |\n",
      "|    n_updates               | 2030                                 |\n",
      "|    policy_gradient_loss    | -0.0013                              |\n",
      "|    value_loss              | 2.06                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.5                                 |\n",
      "|    ep_rew_mean             | 80                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 921                                  |\n",
      "|    iterations              | 205                                  |\n",
      "|    time_elapsed            | 14581                                |\n",
      "|    total_timesteps         | 13434880                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0093810465                         |\n",
      "|    clip_fraction           | 0.0781                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.126                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0302                               |\n",
      "|    n_updates               | 2040                                 |\n",
      "|    policy_gradient_loss    | -0.000806                            |\n",
      "|    value_loss              | 0.564                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=13440000, episode_reward=69.91 +/- 39.67\n",
      "Episode length: 51.60 +/- 24.60\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 51.6                                 |\n",
      "|    mean_reward             | 69.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 13440000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008854918                          |\n",
      "|    clip_fraction           | 0.0825                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.126                               |\n",
      "|    explained_variance      | 0.997                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0196                               |\n",
      "|    n_updates               | 2050                                 |\n",
      "|    policy_gradient_loss    | -0.00196                             |\n",
      "|    value_loss              | 0.405                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 54.4                                 |\n",
      "|    ep_rew_mean             | 70.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 921                                  |\n",
      "|    iterations              | 206                                  |\n",
      "|    time_elapsed            | 14648                                |\n",
      "|    total_timesteps         | 13500416                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45.7                                 |\n",
      "|    ep_rew_mean             | 79                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 922                                  |\n",
      "|    iterations              | 207                                  |\n",
      "|    time_elapsed            | 14711                                |\n",
      "|    total_timesteps         | 13565952                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.012193797                          |\n",
      "|    clip_fraction           | 0.176                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.647                               |\n",
      "|    explained_variance      | 0.967                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 7.25                                 |\n",
      "|    n_updates               | 2060                                 |\n",
      "|    policy_gradient_loss    | -0.00643                             |\n",
      "|    value_loss              | 12.3                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=13600000, episode_reward=79.40 +/- 7.66\n",
      "Episode length: 45.35 +/- 8.31\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 45.4                                 |\n",
      "|    mean_reward             | 79.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 13600000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007533277                          |\n",
      "|    clip_fraction           | 0.123                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.385                               |\n",
      "|    explained_variance      | 0.982                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.47                                 |\n",
      "|    n_updates               | 2070                                 |\n",
      "|    policy_gradient_loss    | -0.00518                             |\n",
      "|    value_loss              | 8.24                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.4                                 |\n",
      "|    ep_rew_mean             | 81.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 922                                  |\n",
      "|    iterations              | 208                                  |\n",
      "|    time_elapsed            | 14777                                |\n",
      "|    total_timesteps         | 13631488                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 185                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.2                                 |\n",
      "|    ep_rew_mean             | 82.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 922                                  |\n",
      "|    iterations              | 209                                  |\n",
      "|    time_elapsed            | 14840                                |\n",
      "|    total_timesteps         | 13697024                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007871969                          |\n",
      "|    clip_fraction           | 0.0819                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.193                               |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.1                                  |\n",
      "|    n_updates               | 2080                                 |\n",
      "|    policy_gradient_loss    | -0.00429                             |\n",
      "|    value_loss              | 3.5                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=13760000, episode_reward=61.15 +/- 25.57\n",
      "Episode length: 63.90 +/- 25.35\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 63.9                                 |\n",
      "|    mean_reward             | 61.1                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 13760000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.022611491                          |\n",
      "|    clip_fraction           | 0.248                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.254                               |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | -0.0111                              |\n",
      "|    n_updates               | 2090                                 |\n",
      "|    policy_gradient_loss    | -0.0104                              |\n",
      "|    value_loss              | 0.257                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 61.1                                 |\n",
      "|    ep_rew_mean             | 64                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 923                                  |\n",
      "|    iterations              | 210                                  |\n",
      "|    time_elapsed            | 14908                                |\n",
      "|    total_timesteps         | 13762560                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 54.9                                 |\n",
      "|    ep_rew_mean             | 70.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 923                                  |\n",
      "|    iterations              | 211                                  |\n",
      "|    time_elapsed            | 14972                                |\n",
      "|    total_timesteps         | 13828096                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0076458147                         |\n",
      "|    clip_fraction           | 0.204                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.953                               |\n",
      "|    explained_variance      | 0.952                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 7.71                                 |\n",
      "|    n_updates               | 2100                                 |\n",
      "|    policy_gradient_loss    | -0.00666                             |\n",
      "|    value_loss              | 15.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 51                                   |\n",
      "|    ep_rew_mean             | 73.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 923                                  |\n",
      "|    iterations              | 212                                  |\n",
      "|    time_elapsed            | 15037                                |\n",
      "|    total_timesteps         | 13893632                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.010336599                          |\n",
      "|    clip_fraction           | 0.234                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.862                               |\n",
      "|    explained_variance      | 0.963                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 8.37                                 |\n",
      "|    n_updates               | 2110                                 |\n",
      "|    policy_gradient_loss    | -0.00743                             |\n",
      "|    value_loss              | 14                                   |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=13920000, episode_reward=79.37 +/- 3.51\n",
      "Episode length: 45.40 +/- 3.32\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 45.4                                 |\n",
      "|    mean_reward             | 79.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 13920000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.017645413                          |\n",
      "|    clip_fraction           | 0.206                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.592                               |\n",
      "|    explained_variance      | 0.977                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.63                                 |\n",
      "|    n_updates               | 2120                                 |\n",
      "|    policy_gradient_loss    | -0.00841                             |\n",
      "|    value_loss              | 8.71                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.8                                 |\n",
      "|    ep_rew_mean             | 80.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 924                                  |\n",
      "|    iterations              | 213                                  |\n",
      "|    time_elapsed            | 15105                                |\n",
      "|    total_timesteps         | 13959168                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.6                                 |\n",
      "|    ep_rew_mean             | 81.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 924                                  |\n",
      "|    iterations              | 214                                  |\n",
      "|    time_elapsed            | 15167                                |\n",
      "|    total_timesteps         | 14024704                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009639777                          |\n",
      "|    clip_fraction           | 0.15                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.342                               |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.31                                 |\n",
      "|    n_updates               | 2130                                 |\n",
      "|    policy_gradient_loss    | -0.00482                             |\n",
      "|    value_loss              | 3.35                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=14080000, episode_reward=82.29 +/- 0.33\n",
      "Episode length: 42.30 +/- 0.64\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 42.3                                 |\n",
      "|    mean_reward             | 82.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 14080000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.016487045                          |\n",
      "|    clip_fraction           | 0.1                                  |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.202                               |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.33                                 |\n",
      "|    n_updates               | 2140                                 |\n",
      "|    policy_gradient_loss    | -0.00235                             |\n",
      "|    value_loss              | 1.11                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.4                                 |\n",
      "|    ep_rew_mean             | 82.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 924                                  |\n",
      "|    iterations              | 215                                  |\n",
      "|    time_elapsed            | 15233                                |\n",
      "|    total_timesteps         | 14090240                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 147                                  |\n",
      "|    ep_rew_mean             | -32.7                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 925                                  |\n",
      "|    iterations              | 216                                  |\n",
      "|    time_elapsed            | 15298                                |\n",
      "|    total_timesteps         | 14155776                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.8528422                            |\n",
      "|    clip_fraction           | 0.225                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.222                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0558                               |\n",
      "|    n_updates               | 2150                                 |\n",
      "|    policy_gradient_loss    | -0.000673                            |\n",
      "|    value_loss              | 0.239                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 150                                  |\n",
      "|    ep_rew_mean             | -31.1                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 925                                  |\n",
      "|    iterations              | 217                                  |\n",
      "|    time_elapsed            | 15363                                |\n",
      "|    total_timesteps         | 14221312                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.040454518                          |\n",
      "|    clip_fraction           | 0.272                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.423                               |\n",
      "|    explained_variance      | 0.931                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.22                                 |\n",
      "|    n_updates               | 2160                                 |\n",
      "|    policy_gradient_loss    | -0.0123                              |\n",
      "|    value_loss              | 11.2                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=14240000, episode_reward=-27.44 +/- 22.60\n",
      "Episode length: 147.25 +/- 21.08\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 147                                  |\n",
      "|    mean_reward             | -27.4                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 14240000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.019716103                          |\n",
      "|    clip_fraction           | 0.176                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.398                               |\n",
      "|    explained_variance      | 0.971                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.82                                 |\n",
      "|    n_updates               | 2170                                 |\n",
      "|    policy_gradient_loss    | -0.00453                             |\n",
      "|    value_loss              | 10.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 148                                  |\n",
      "|    ep_rew_mean             | -27.5                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 925                                  |\n",
      "|    iterations              | 218                                  |\n",
      "|    time_elapsed            | 15439                                |\n",
      "|    total_timesteps         | 14286848                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 142                                  |\n",
      "|    ep_rew_mean             | -20.4                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 925                                  |\n",
      "|    iterations              | 219                                  |\n",
      "|    time_elapsed            | 15503                                |\n",
      "|    total_timesteps         | 14352384                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.021979744                          |\n",
      "|    clip_fraction           | 0.165                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.386                               |\n",
      "|    explained_variance      | 0.975                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.33                                 |\n",
      "|    n_updates               | 2180                                 |\n",
      "|    policy_gradient_loss    | -0.00281                             |\n",
      "|    value_loss              | 10.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=14400000, episode_reward=9.64 +/- 36.48\n",
      "Episode length: 113.75 +/- 35.70\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 114                                  |\n",
      "|    mean_reward             | 9.64                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 14400000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007632074                          |\n",
      "|    clip_fraction           | 0.119                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.329                               |\n",
      "|    explained_variance      | 0.962                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.18                                 |\n",
      "|    n_updates               | 2190                                 |\n",
      "|    policy_gradient_loss    | -0.00129                             |\n",
      "|    value_loss              | 16.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 128                                  |\n",
      "|    ep_rew_mean             | -4.88                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 925                                  |\n",
      "|    iterations              | 220                                  |\n",
      "|    time_elapsed            | 15577                                |\n",
      "|    total_timesteps         | 14417920                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 117                                  |\n",
      "|    ep_rew_mean             | 6.51                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 925                                  |\n",
      "|    iterations              | 221                                  |\n",
      "|    time_elapsed            | 15641                                |\n",
      "|    total_timesteps         | 14483456                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.016423922                          |\n",
      "|    clip_fraction           | 0.133                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.354                               |\n",
      "|    explained_variance      | 0.939                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 12.5                                 |\n",
      "|    n_updates               | 2200                                 |\n",
      "|    policy_gradient_loss    | -0.0018                              |\n",
      "|    value_loss              | 28.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 81                                   |\n",
      "|    ep_rew_mean             | 43.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 926                                  |\n",
      "|    iterations              | 222                                  |\n",
      "|    time_elapsed            | 15707                                |\n",
      "|    total_timesteps         | 14548992                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.030041616                          |\n",
      "|    clip_fraction           | 0.146                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.386                               |\n",
      "|    explained_variance      | 0.923                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 32.8                                 |\n",
      "|    n_updates               | 2210                                 |\n",
      "|    policy_gradient_loss    | -0.00426                             |\n",
      "|    value_loss              | 44.1                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=14560000, episode_reward=42.60 +/- 32.85\n",
      "Episode length: 81.50 +/- 32.74\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 81.5                                 |\n",
      "|    mean_reward             | 42.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 14560000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0046299454                         |\n",
      "|    clip_fraction           | 0.122                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.422                               |\n",
      "|    explained_variance      | 0.871                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 23.1                                 |\n",
      "|    n_updates               | 2220                                 |\n",
      "|    policy_gradient_loss    | -0.00168                             |\n",
      "|    value_loss              | 62.3                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 77.8                                 |\n",
      "|    ep_rew_mean             | 46.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 926                                  |\n",
      "|    iterations              | 223                                  |\n",
      "|    time_elapsed            | 15778                                |\n",
      "|    total_timesteps         | 14614528                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 68.8                                 |\n",
      "|    ep_rew_mean             | 55.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 926                                  |\n",
      "|    iterations              | 224                                  |\n",
      "|    time_elapsed            | 15842                                |\n",
      "|    total_timesteps         | 14680064                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0057633594                         |\n",
      "|    clip_fraction           | 0.146                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.43                                |\n",
      "|    explained_variance      | 0.896                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 31.3                                 |\n",
      "|    n_updates               | 2230                                 |\n",
      "|    policy_gradient_loss    | -0.00412                             |\n",
      "|    value_loss              | 49.8                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=14720000, episode_reward=60.72 +/- 14.84\n",
      "Episode length: 63.30 +/- 14.97\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 63.3                                 |\n",
      "|    mean_reward             | 60.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 14720000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0053440337                         |\n",
      "|    clip_fraction           | 0.156                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.416                               |\n",
      "|    explained_variance      | 0.918                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 19.4                                 |\n",
      "|    n_updates               | 2240                                 |\n",
      "|    policy_gradient_loss    | -0.00478                             |\n",
      "|    value_loss              | 39                                   |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 60.1                                 |\n",
      "|    ep_rew_mean             | 64                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 926                                  |\n",
      "|    iterations              | 225                                  |\n",
      "|    time_elapsed            | 15910                                |\n",
      "|    total_timesteps         | 14745600                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 54.1                                 |\n",
      "|    ep_rew_mean             | 69.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 927                                  |\n",
      "|    iterations              | 226                                  |\n",
      "|    time_elapsed            | 15974                                |\n",
      "|    total_timesteps         | 14811136                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00975947                           |\n",
      "|    clip_fraction           | 0.224                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.411                               |\n",
      "|    explained_variance      | 0.935                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 19.7                                 |\n",
      "|    n_updates               | 2250                                 |\n",
      "|    policy_gradient_loss    | -0.00748                             |\n",
      "|    value_loss              | 30                                   |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 51.7                                 |\n",
      "|    ep_rew_mean             | 72.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 927                                  |\n",
      "|    iterations              | 227                                  |\n",
      "|    time_elapsed            | 16038                                |\n",
      "|    total_timesteps         | 14876672                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0071250554                         |\n",
      "|    clip_fraction           | 0.244                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.384                               |\n",
      "|    explained_variance      | 0.951                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 11.7                                 |\n",
      "|    n_updates               | 2260                                 |\n",
      "|    policy_gradient_loss    | -0.00841                             |\n",
      "|    value_loss              | 17.3                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=14880000, episode_reward=75.96 +/- 3.33\n",
      "Episode length: 47.95 +/- 3.56\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 48                                   |\n",
      "|    mean_reward             | 76                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 14880000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006002374                          |\n",
      "|    clip_fraction           | 0.239                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.365                               |\n",
      "|    explained_variance      | 0.96                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.56                                 |\n",
      "|    n_updates               | 2270                                 |\n",
      "|    policy_gradient_loss    | -0.00558                             |\n",
      "|    value_loss              | 14.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 48.3                                 |\n",
      "|    ep_rew_mean             | 75.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 927                                  |\n",
      "|    iterations              | 228                                  |\n",
      "|    time_elapsed            | 16104                                |\n",
      "|    total_timesteps         | 14942208                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.8                                 |\n",
      "|    ep_rew_mean             | 77.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 928                                  |\n",
      "|    iterations              | 229                                  |\n",
      "|    time_elapsed            | 16167                                |\n",
      "|    total_timesteps         | 15007744                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006218938                          |\n",
      "|    clip_fraction           | 0.226                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.338                               |\n",
      "|    explained_variance      | 0.971                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.36                                 |\n",
      "|    n_updates               | 2280                                 |\n",
      "|    policy_gradient_loss    | -0.00638                             |\n",
      "|    value_loss              | 11.1                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=15040000, episode_reward=77.00 +/- 4.90\n",
      "Episode length: 47.20 +/- 4.85\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 47.2                                 |\n",
      "|    mean_reward             | 77                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 15040000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0041254335                         |\n",
      "|    clip_fraction           | 0.163                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.284                               |\n",
      "|    explained_variance      | 0.98                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.87                                 |\n",
      "|    n_updates               | 2290                                 |\n",
      "|    policy_gradient_loss    | -0.00408                             |\n",
      "|    value_loss              | 6.25                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.9                                 |\n",
      "|    ep_rew_mean             | 76.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 928                                  |\n",
      "|    iterations              | 230                                  |\n",
      "|    time_elapsed            | 16233                                |\n",
      "|    total_timesteps         | 15073280                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.3                                 |\n",
      "|    ep_rew_mean             | 79.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 929                                  |\n",
      "|    iterations              | 231                                  |\n",
      "|    time_elapsed            | 16295                                |\n",
      "|    total_timesteps         | 15138816                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0045577874                         |\n",
      "|    clip_fraction           | 0.178                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.259                               |\n",
      "|    explained_variance      | 0.991                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.53                                 |\n",
      "|    n_updates               | 2300                                 |\n",
      "|    policy_gradient_loss    | -0.00629                             |\n",
      "|    value_loss              | 3.06                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=15200000, episode_reward=80.40 +/- 2.32\n",
      "Episode length: 43.60 +/- 2.50\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 43.6                                 |\n",
      "|    mean_reward             | 80.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 15200000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005299554                          |\n",
      "|    clip_fraction           | 0.164                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.238                               |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.99                                 |\n",
      "|    n_updates               | 2310                                 |\n",
      "|    policy_gradient_loss    | -0.00775                             |\n",
      "|    value_loss              | 2.61                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.9                                 |\n",
      "|    ep_rew_mean             | 79.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 929                                  |\n",
      "|    iterations              | 232                                  |\n",
      "|    time_elapsed            | 16361                                |\n",
      "|    total_timesteps         | 15204352                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.5                                 |\n",
      "|    ep_rew_mean             | 81.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 929                                  |\n",
      "|    iterations              | 233                                  |\n",
      "|    time_elapsed            | 16424                                |\n",
      "|    total_timesteps         | 15269888                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008539718                          |\n",
      "|    clip_fraction           | 0.17                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.207                               |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.617                                |\n",
      "|    n_updates               | 2320                                 |\n",
      "|    policy_gradient_loss    | -0.00771                             |\n",
      "|    value_loss              | 2.05                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.7                                 |\n",
      "|    ep_rew_mean             | 82.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 930                                  |\n",
      "|    iterations              | 234                                  |\n",
      "|    time_elapsed            | 16486                                |\n",
      "|    total_timesteps         | 15335424                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.014622308                          |\n",
      "|    clip_fraction           | 0.148                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.172                               |\n",
      "|    explained_variance      | 0.991                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.16                                 |\n",
      "|    n_updates               | 2330                                 |\n",
      "|    policy_gradient_loss    | -0.00555                             |\n",
      "|    value_loss              | 2.41                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=15360000, episode_reward=82.71 +/- 1.03\n",
      "Episode length: 41.05 +/- 0.92\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41                                   |\n",
      "|    mean_reward             | 82.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 15360000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0113823265                         |\n",
      "|    clip_fraction           | 0.104                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.127                               |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.706                                |\n",
      "|    n_updates               | 2340                                 |\n",
      "|    policy_gradient_loss    | -0.00388                             |\n",
      "|    value_loss              | 0.993                                |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.9                                 |\n",
      "|    ep_rew_mean             | 82.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 930                                  |\n",
      "|    iterations              | 235                                  |\n",
      "|    time_elapsed            | 16552                                |\n",
      "|    total_timesteps         | 15400960                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.5                                 |\n",
      "|    ep_rew_mean             | 83.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 930                                  |\n",
      "|    iterations              | 236                                  |\n",
      "|    time_elapsed            | 16615                                |\n",
      "|    total_timesteps         | 15466496                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.015675567                          |\n",
      "|    clip_fraction           | 0.0888                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.139                               |\n",
      "|    explained_variance      | 0.988                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.475                                |\n",
      "|    n_updates               | 2350                                 |\n",
      "|    policy_gradient_loss    | -0.00184                             |\n",
      "|    value_loss              | 3.39                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=15520000, episode_reward=83.30 +/- 0.30\n",
      "Episode length: 40.20 +/- 0.40\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.2                                 |\n",
      "|    mean_reward             | 83.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 15520000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.012451988                          |\n",
      "|    clip_fraction           | 0.0681                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.099                               |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.325                                |\n",
      "|    n_updates               | 2360                                 |\n",
      "|    policy_gradient_loss    | 0.00326                              |\n",
      "|    value_loss              | 1.67                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.4                                 |\n",
      "|    ep_rew_mean             | 83.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 931                                  |\n",
      "|    iterations              | 237                                  |\n",
      "|    time_elapsed            | 16680                                |\n",
      "|    total_timesteps         | 15532032                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.5                                 |\n",
      "|    ep_rew_mean             | 83.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 931                                  |\n",
      "|    iterations              | 238                                  |\n",
      "|    time_elapsed            | 16743                                |\n",
      "|    total_timesteps         | 15597568                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0059165773                         |\n",
      "|    clip_fraction           | 0.0448                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0924                              |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.226                                |\n",
      "|    n_updates               | 2370                                 |\n",
      "|    policy_gradient_loss    | 0.00159                              |\n",
      "|    value_loss              | 1.68                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.2                                 |\n",
      "|    ep_rew_mean             | 83.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 932                                  |\n",
      "|    iterations              | 239                                  |\n",
      "|    time_elapsed            | 16805                                |\n",
      "|    total_timesteps         | 15663104                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.012963185                          |\n",
      "|    clip_fraction           | 0.0365                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0684                              |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.086                                |\n",
      "|    n_updates               | 2380                                 |\n",
      "|    policy_gradient_loss    | 0.00109                              |\n",
      "|    value_loss              | 0.779                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=15680000, episode_reward=83.40 +/- 0.00\n",
      "Episode length: 40.05 +/- 0.22\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 15680000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0077574914                         |\n",
      "|    clip_fraction           | 0.0254                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0696                              |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.858                                |\n",
      "|    n_updates               | 2390                                 |\n",
      "|    policy_gradient_loss    | 0.00137                              |\n",
      "|    value_loss              | 1.68                                 |\n",
      "---------------------------------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 183                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.1                                 |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 932                                  |\n",
      "|    iterations              | 240                                  |\n",
      "|    time_elapsed            | 16871                                |\n",
      "|    total_timesteps         | 15728640                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 110                                  |\n",
      "|    ep_rew_mean             | 6.05                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 932                                  |\n",
      "|    iterations              | 241                                  |\n",
      "|    time_elapsed            | 16936                                |\n",
      "|    total_timesteps         | 15794176                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.024929214                          |\n",
      "|    clip_fraction           | 0.0469                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0678                              |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.297                                |\n",
      "|    n_updates               | 2400                                 |\n",
      "|    policy_gradient_loss    | -0.000524                            |\n",
      "|    value_loss              | 0.905                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=15840000, episode_reward=30.90 +/- 57.25\n",
      "Episode length: 91.80 +/- 56.28\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 91.8                                 |\n",
      "|    mean_reward             | 30.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 15840000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.013299977                          |\n",
      "|    clip_fraction           | 0.225                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.39                                |\n",
      "|    explained_variance      | 0.893                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 11.9                                 |\n",
      "|    n_updates               | 2410                                 |\n",
      "|    policy_gradient_loss    | -0.00883                             |\n",
      "|    value_loss              | 46.3                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 99.7                                 |\n",
      "|    ep_rew_mean             | 22                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 932                                  |\n",
      "|    iterations              | 242                                  |\n",
      "|    time_elapsed            | 17010                                |\n",
      "|    total_timesteps         | 15859712                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 76.5                                 |\n",
      "|    ep_rew_mean             | 46.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 932                                  |\n",
      "|    iterations              | 243                                  |\n",
      "|    time_elapsed            | 17078                                |\n",
      "|    total_timesteps         | 15925248                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0075037023                         |\n",
      "|    clip_fraction           | 0.239                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.44                                |\n",
      "|    explained_variance      | 0.939                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 31                                   |\n",
      "|    n_updates               | 2420                                 |\n",
      "|    policy_gradient_loss    | -0.0073                              |\n",
      "|    value_loss              | 46.6                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 50.7                                 |\n",
      "|    ep_rew_mean             | 72.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 932                                  |\n",
      "|    iterations              | 244                                  |\n",
      "|    time_elapsed            | 17143                                |\n",
      "|    total_timesteps         | 15990784                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007687558                          |\n",
      "|    clip_fraction           | 0.201                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.03                                |\n",
      "|    explained_variance      | 0.961                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 34.5                                 |\n",
      "|    n_updates               | 2430                                 |\n",
      "|    policy_gradient_loss    | -0.00675                             |\n",
      "|    value_loss              | 41.1                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=16000000, episode_reward=83.35 +/- 0.22\n",
      "Episode length: 40.05 +/- 0.22\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 16000000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0053736875                         |\n",
      "|    clip_fraction           | 0.119                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.517                               |\n",
      "|    explained_variance      | 0.974                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 16.1                                 |\n",
      "|    n_updates               | 2440                                 |\n",
      "|    policy_gradient_loss    | -0.00324                             |\n",
      "|    value_loss              | 24                                   |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.4                                 |\n",
      "|    ep_rew_mean             | 81                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 932                                  |\n",
      "|    iterations              | 245                                  |\n",
      "|    time_elapsed            | 17209                                |\n",
      "|    total_timesteps         | 16056320                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40                                   |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 933                                  |\n",
      "|    iterations              | 246                                  |\n",
      "|    time_elapsed            | 17275                                |\n",
      "|    total_timesteps         | 16121856                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006857913                          |\n",
      "|    clip_fraction           | 0.0593                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.178                               |\n",
      "|    explained_variance      | 0.985                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.99                                 |\n",
      "|    n_updates               | 2450                                 |\n",
      "|    policy_gradient_loss    | 0.00194                              |\n",
      "|    value_loss              | 7.73                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=16160000, episode_reward=83.40 +/- 0.00\n",
      "Episode length: 40.00 +/- 0.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 16160000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0037194507                         |\n",
      "|    clip_fraction           | 0.0242                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.076                               |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.145                                |\n",
      "|    n_updates               | 2460                                 |\n",
      "|    policy_gradient_loss    | 0.0026                               |\n",
      "|    value_loss              | 4.05                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.8                                 |\n",
      "|    ep_rew_mean             | 82.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 933                                  |\n",
      "|    iterations              | 247                                  |\n",
      "|    time_elapsed            | 17342                                |\n",
      "|    total_timesteps         | 16187392                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.3                                 |\n",
      "|    ep_rew_mean             | 83.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 933                                  |\n",
      "|    iterations              | 248                                  |\n",
      "|    time_elapsed            | 17406                                |\n",
      "|    total_timesteps         | 16252928                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.012594013                          |\n",
      "|    clip_fraction           | 0.0366                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0571                              |\n",
      "|    explained_variance      | 0.997                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0351                               |\n",
      "|    n_updates               | 2470                                 |\n",
      "|    policy_gradient_loss    | 0.00244                              |\n",
      "|    value_loss              | 0.983                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.2                                 |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 249                                  |\n",
      "|    time_elapsed            | 17468                                |\n",
      "|    total_timesteps         | 16318464                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.010535555                          |\n",
      "|    clip_fraction           | 0.0525                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0725                              |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.01                                 |\n",
      "|    n_updates               | 2480                                 |\n",
      "|    policy_gradient_loss    | 0.00476                              |\n",
      "|    value_loss              | 1.11                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=16320000, episode_reward=80.24 +/- 13.55\n",
      "Episode length: 43.35 +/- 13.92\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 43.4                                 |\n",
      "|    mean_reward             | 80.2                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 16320000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.015116636                          |\n",
      "|    clip_fraction           | 0.0334                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.058                               |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.947                                |\n",
      "|    n_updates               | 2490                                 |\n",
      "|    policy_gradient_loss    | 0.00117                              |\n",
      "|    value_loss              | 0.773                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.1                                 |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 250                                  |\n",
      "|    time_elapsed            | 17534                                |\n",
      "|    total_timesteps         | 16384000                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.1                                 |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 251                                  |\n",
      "|    time_elapsed            | 17596                                |\n",
      "|    total_timesteps         | 16449536                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007117926                          |\n",
      "|    clip_fraction           | 0.0185                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0446                              |\n",
      "|    explained_variance      | 0.995                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.31                                 |\n",
      "|    n_updates               | 2500                                 |\n",
      "|    policy_gradient_loss    | 0.000597                             |\n",
      "|    value_loss              | 1.42                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=16480000, episode_reward=-25.65 +/- 53.25\n",
      "Episode length: 136.15 +/- 37.40\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 136                                  |\n",
      "|    mean_reward             | -25.6                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 16480000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.14437649                           |\n",
      "|    clip_fraction           | 0.0803                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0873                              |\n",
      "|    explained_variance      | 0.997                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.826                                |\n",
      "|    n_updates               | 2510                                 |\n",
      "|    policy_gradient_loss    | -0.00271                             |\n",
      "|    value_loss              | 0.437                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 144                                  |\n",
      "|    ep_rew_mean             | -32.6                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 252                                  |\n",
      "|    time_elapsed            | 17673                                |\n",
      "|    total_timesteps         | 16515072                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 124                                  |\n",
      "|    ep_rew_mean             | -9.66                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 253                                  |\n",
      "|    time_elapsed            | 17739                                |\n",
      "|    total_timesteps         | 16580608                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0054257177                         |\n",
      "|    clip_fraction           | 0.207                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.75                                |\n",
      "|    explained_variance      | 0.833                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 18.5                                 |\n",
      "|    n_updates               | 2520                                 |\n",
      "|    policy_gradient_loss    | -0.00533                             |\n",
      "|    value_loss              | 29.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=16640000, episode_reward=9.24 +/- 49.32\n",
      "Episode length: 114.00 +/- 48.67\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 114                                  |\n",
      "|    mean_reward             | 9.24                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 16640000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007463517                          |\n",
      "|    clip_fraction           | 0.239                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.65                                |\n",
      "|    explained_variance      | 0.898                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 19.7                                 |\n",
      "|    n_updates               | 2530                                 |\n",
      "|    policy_gradient_loss    | -0.00618                             |\n",
      "|    value_loss              | 40.6                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 103                                  |\n",
      "|    ep_rew_mean             | 16.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 254                                  |\n",
      "|    time_elapsed            | 17814                                |\n",
      "|    total_timesteps         | 16646144                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 83                                   |\n",
      "|    ep_rew_mean             | 37.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 255                                  |\n",
      "|    time_elapsed            | 17880                                |\n",
      "|    total_timesteps         | 16711680                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.011361156                          |\n",
      "|    clip_fraction           | 0.249                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.48                                |\n",
      "|    explained_variance      | 0.909                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 34.8                                 |\n",
      "|    n_updates               | 2540                                 |\n",
      "|    policy_gradient_loss    | -0.00748                             |\n",
      "|    value_loss              | 58.9                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 67.5                                 |\n",
      "|    ep_rew_mean             | 56.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 256                                  |\n",
      "|    time_elapsed            | 17945                                |\n",
      "|    total_timesteps         | 16777216                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0062319255                         |\n",
      "|    clip_fraction           | 0.221                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.3                                 |\n",
      "|    explained_variance      | 0.929                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 18.2                                 |\n",
      "|    n_updates               | 2550                                 |\n",
      "|    policy_gradient_loss    | -0.00578                             |\n",
      "|    value_loss              | 62.1                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=16800000, episode_reward=64.50 +/- 40.65\n",
      "Episode length: 58.75 +/- 40.03\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 58.8                                 |\n",
      "|    mean_reward             | 64.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 16800000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006277694                          |\n",
      "|    clip_fraction           | 0.184                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.931                               |\n",
      "|    explained_variance      | 0.943                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 24.2                                 |\n",
      "|    n_updates               | 2560                                 |\n",
      "|    policy_gradient_loss    | -0.00589                             |\n",
      "|    value_loss              | 59                                   |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.1                                 |\n",
      "|    ep_rew_mean             | 77.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 934                                  |\n",
      "|    iterations              | 257                                  |\n",
      "|    time_elapsed            | 18013                                |\n",
      "|    total_timesteps         | 16842752                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 47                                   |\n",
      "|    ep_rew_mean             | 76.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 935                                  |\n",
      "|    iterations              | 258                                  |\n",
      "|    time_elapsed            | 18076                                |\n",
      "|    total_timesteps         | 16908288                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0056843534                         |\n",
      "|    clip_fraction           | 0.144                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.607                               |\n",
      "|    explained_variance      | 0.958                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 10.3                                 |\n",
      "|    n_updates               | 2570                                 |\n",
      "|    policy_gradient_loss    | -0.00503                             |\n",
      "|    value_loss              | 40.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=16960000, episode_reward=82.02 +/- 1.48\n",
      "Episode length: 41.45 +/- 1.77\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41.5                                 |\n",
      "|    mean_reward             | 82                                   |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 16960000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0056647668                         |\n",
      "|    clip_fraction           | 0.0828                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.252                               |\n",
      "|    explained_variance      | 0.97                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 9.3                                  |\n",
      "|    n_updates               | 2580                                 |\n",
      "|    policy_gradient_loss    | -0.00242                             |\n",
      "|    value_loss              | 18.2                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.4                                 |\n",
      "|    ep_rew_mean             | 81.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 935                                  |\n",
      "|    iterations              | 259                                  |\n",
      "|    time_elapsed            | 18142                                |\n",
      "|    total_timesteps         | 16973824                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.1                                 |\n",
      "|    ep_rew_mean             | 82.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 935                                  |\n",
      "|    iterations              | 260                                  |\n",
      "|    time_elapsed            | 18206                                |\n",
      "|    total_timesteps         | 17039360                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0058508078                         |\n",
      "|    clip_fraction           | 0.041                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.126                               |\n",
      "|    explained_variance      | 0.985                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.953                                |\n",
      "|    n_updates               | 2590                                 |\n",
      "|    policy_gradient_loss    | 0.00306                              |\n",
      "|    value_loss              | 6.8                                  |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41                                   |\n",
      "|    ep_rew_mean             | 82.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 936                                  |\n",
      "|    iterations              | 261                                  |\n",
      "|    time_elapsed            | 18269                                |\n",
      "|    total_timesteps         | 17104896                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0044224085                         |\n",
      "|    clip_fraction           | 0.0182                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.053                               |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.117                                |\n",
      "|    n_updates               | 2600                                 |\n",
      "|    policy_gradient_loss    | 0.000895                             |\n",
      "|    value_loss              | 2.22                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=17120000, episode_reward=53.92 +/- 35.57\n",
      "Episode length: 70.10 +/- 35.62\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 70.1                                 |\n",
      "|    mean_reward             | 53.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 17120000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.021309568                          |\n",
      "|    clip_fraction           | 0.139                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.103                               |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.358                                |\n",
      "|    n_updates               | 2610                                 |\n",
      "|    policy_gradient_loss    | -0.0119                              |\n",
      "|    value_loss              | 0.407                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 74                                   |\n",
      "|    ep_rew_mean             | 49.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 936                                  |\n",
      "|    iterations              | 262                                  |\n",
      "|    time_elapsed            | 18338                                |\n",
      "|    total_timesteps         | 17170432                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 50.1                                 |\n",
      "|    ep_rew_mean             | 73.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 936                                  |\n",
      "|    iterations              | 263                                  |\n",
      "|    time_elapsed            | 18403                                |\n",
      "|    total_timesteps         | 17235968                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.012038883                          |\n",
      "|    clip_fraction           | 0.179                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.558                               |\n",
      "|    explained_variance      | 0.948                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.94                                 |\n",
      "|    n_updates               | 2620                                 |\n",
      "|    policy_gradient_loss    | -0.00293                             |\n",
      "|    value_loss              | 13.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=17280000, episode_reward=75.69 +/- 8.74\n",
      "Episode length: 48.25 +/- 9.02\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 48.2                                 |\n",
      "|    mean_reward             | 75.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 17280000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009537944                          |\n",
      "|    clip_fraction           | 0.13                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.384                               |\n",
      "|    explained_variance      | 0.967                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 8.85                                 |\n",
      "|    n_updates               | 2630                                 |\n",
      "|    policy_gradient_loss    | -0.00269                             |\n",
      "|    value_loss              | 17                                   |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45.6                                 |\n",
      "|    ep_rew_mean             | 78.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 936                                  |\n",
      "|    iterations              | 264                                  |\n",
      "|    time_elapsed            | 18471                                |\n",
      "|    total_timesteps         | 17301504                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.9                                 |\n",
      "|    ep_rew_mean             | 79.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 936                                  |\n",
      "|    iterations              | 265                                  |\n",
      "|    time_elapsed            | 18536                                |\n",
      "|    total_timesteps         | 17367040                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.016466133                          |\n",
      "|    clip_fraction           | 0.148                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.225                               |\n",
      "|    explained_variance      | 0.978                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.4                                  |\n",
      "|    n_updates               | 2640                                 |\n",
      "|    policy_gradient_loss    | -0.00355                             |\n",
      "|    value_loss              | 10.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 82.7                                 |\n",
      "|    ep_rew_mean             | 37.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 937                                  |\n",
      "|    iterations              | 266                                  |\n",
      "|    time_elapsed            | 18602                                |\n",
      "|    total_timesteps         | 17432576                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.010747207                          |\n",
      "|    clip_fraction           | 0.128                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.154                               |\n",
      "|    explained_variance      | 0.987                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.23                                 |\n",
      "|    n_updates               | 2650                                 |\n",
      "|    policy_gradient_loss    | -0.00531                             |\n",
      "|    value_loss              | 4.52                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=17440000, episode_reward=52.09 +/- 46.76\n",
      "Episode length: 71.25 +/- 45.80\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 71.2                                 |\n",
      "|    mean_reward             | 52.1                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 17440000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0062642014                         |\n",
      "|    clip_fraction           | 0.197                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.21                                |\n",
      "|    explained_variance      | 0.941                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 15.6                                 |\n",
      "|    n_updates               | 2660                                 |\n",
      "|    policy_gradient_loss    | -0.00506                             |\n",
      "|    value_loss              | 32.8                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 70.3                                 |\n",
      "|    ep_rew_mean             | 49.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 937                                  |\n",
      "|    iterations              | 267                                  |\n",
      "|    time_elapsed            | 18672                                |\n",
      "|    total_timesteps         | 17498112                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 48                                   |\n",
      "|    ep_rew_mean             | 75.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 937                                  |\n",
      "|    iterations              | 268                                  |\n",
      "|    time_elapsed            | 18735                                |\n",
      "|    total_timesteps         | 17563648                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005833892                          |\n",
      "|    clip_fraction           | 0.174                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.856                               |\n",
      "|    explained_variance      | 0.963                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 17.1                                 |\n",
      "|    n_updates               | 2670                                 |\n",
      "|    policy_gradient_loss    | -0.00542                             |\n",
      "|    value_loss              | 28.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=17600000, episode_reward=82.10 +/- 1.78\n",
      "Episode length: 41.60 +/- 1.93\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41.6                                 |\n",
      "|    mean_reward             | 82.1                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 17600000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008457756                          |\n",
      "|    clip_fraction           | 0.165                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.567                               |\n",
      "|    explained_variance      | 0.977                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.18                                 |\n",
      "|    n_updates               | 2680                                 |\n",
      "|    policy_gradient_loss    | -0.00642                             |\n",
      "|    value_loss              | 19.2                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45.6                                 |\n",
      "|    ep_rew_mean             | 78                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 937                                  |\n",
      "|    iterations              | 269                                  |\n",
      "|    time_elapsed            | 18800                                |\n",
      "|    total_timesteps         | 17629184                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.5                                 |\n",
      "|    ep_rew_mean             | 82                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 938                                  |\n",
      "|    iterations              | 270                                  |\n",
      "|    time_elapsed            | 18862                                |\n",
      "|    total_timesteps         | 17694720                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006837341                          |\n",
      "|    clip_fraction           | 0.0909                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.254                               |\n",
      "|    explained_variance      | 0.983                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.03                                 |\n",
      "|    n_updates               | 2690                                 |\n",
      "|    policy_gradient_loss    | -0.00136                             |\n",
      "|    value_loss              | 8.97                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=17760000, episode_reward=82.65 +/- 0.54\n",
      "Episode length: 40.85 +/- 0.48\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.9                                 |\n",
      "|    mean_reward             | 82.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 17760000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0059119645                         |\n",
      "|    clip_fraction           | 0.0553                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0901                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0767                               |\n",
      "|    n_updates               | 2700                                 |\n",
      "|    policy_gradient_loss    | 0.002                                |\n",
      "|    value_loss              | 2.21                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.9                                 |\n",
      "|    ep_rew_mean             | 82.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 938                                  |\n",
      "|    iterations              | 271                                  |\n",
      "|    time_elapsed            | 18927                                |\n",
      "|    total_timesteps         | 17760256                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.6                                 |\n",
      "|    ep_rew_mean             | 80                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 938                                  |\n",
      "|    iterations              | 272                                  |\n",
      "|    time_elapsed            | 18988                                |\n",
      "|    total_timesteps         | 17825792                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.011018491                          |\n",
      "|    clip_fraction           | 0.0544                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0707                              |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.143                                |\n",
      "|    n_updates               | 2710                                 |\n",
      "|    policy_gradient_loss    | 0.000591                             |\n",
      "|    value_loss              | 0.833                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.9                                 |\n",
      "|    ep_rew_mean             | 82.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 939                                  |\n",
      "|    iterations              | 273                                  |\n",
      "|    time_elapsed            | 19050                                |\n",
      "|    total_timesteps         | 17891328                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.040606692                          |\n",
      "|    clip_fraction           | 0.0888                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.147                               |\n",
      "|    explained_variance      | 0.986                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.399                                |\n",
      "|    n_updates               | 2720                                 |\n",
      "|    policy_gradient_loss    | 0.00175                              |\n",
      "|    value_loss              | 3.87                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=17920000, episode_reward=82.75 +/- 0.57\n",
      "Episode length: 40.65 +/- 0.57\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.6                                 |\n",
      "|    mean_reward             | 82.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 17920000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.010317819                          |\n",
      "|    clip_fraction           | 0.0514                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0858                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.43                                 |\n",
      "|    n_updates               | 2730                                 |\n",
      "|    policy_gradient_loss    | 0.00205                              |\n",
      "|    value_loss              | 2.56                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.6                                 |\n",
      "|    ep_rew_mean             | 82.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 939                                  |\n",
      "|    iterations              | 274                                  |\n",
      "|    time_elapsed            | 19114                                |\n",
      "|    total_timesteps         | 17956864                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.8                                 |\n",
      "|    ep_rew_mean             | 81.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 939                                  |\n",
      "|    iterations              | 275                                  |\n",
      "|    time_elapsed            | 19176                                |\n",
      "|    total_timesteps         | 18022400                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.01410716                           |\n",
      "|    clip_fraction           | 0.0407                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0565                              |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0972                               |\n",
      "|    n_updates               | 2740                                 |\n",
      "|    policy_gradient_loss    | 0.00482                              |\n",
      "|    value_loss              | 0.836                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=18080000, episode_reward=83.26 +/- 0.44\n",
      "Episode length: 40.30 +/- 0.56\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.3                                 |\n",
      "|    mean_reward             | 83.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 18080000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.017733527                          |\n",
      "|    clip_fraction           | 0.0689                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.114                               |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.61                                 |\n",
      "|    n_updates               | 2750                                 |\n",
      "|    policy_gradient_loss    | 0.00506                              |\n",
      "|    value_loss              | 2.38                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.8                                 |\n",
      "|    ep_rew_mean             | 81.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 940                                  |\n",
      "|    iterations              | 276                                  |\n",
      "|    time_elapsed            | 19240                                |\n",
      "|    total_timesteps         | 18087936                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.1                                 |\n",
      "|    ep_rew_mean             | 83.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 940                                  |\n",
      "|    iterations              | 277                                  |\n",
      "|    time_elapsed            | 19301                                |\n",
      "|    total_timesteps         | 18153472                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.03741941                           |\n",
      "|    clip_fraction           | 0.0643                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0699                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.448                                |\n",
      "|    n_updates               | 2760                                 |\n",
      "|    policy_gradient_loss    | 0.000954                             |\n",
      "|    value_loss              | 1.73                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.5                                 |\n",
      "|    ep_rew_mean             | 82.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 940                                  |\n",
      "|    iterations              | 278                                  |\n",
      "|    time_elapsed            | 19363                                |\n",
      "|    total_timesteps         | 18219008                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.018219622                          |\n",
      "|    clip_fraction           | 0.0315                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0646                              |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.183                                |\n",
      "|    n_updates               | 2770                                 |\n",
      "|    policy_gradient_loss    | 0.0058                               |\n",
      "|    value_loss              | 2.01                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=18240000, episode_reward=77.35 +/- 24.77\n",
      "Episode length: 46.30 +/- 24.72\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 46.3                                 |\n",
      "|    mean_reward             | 77.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 18240000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.015341867                          |\n",
      "|    clip_fraction           | 0.0281                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0583                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.9                                  |\n",
      "|    n_updates               | 2780                                 |\n",
      "|    policy_gradient_loss    | 0.000809                             |\n",
      "|    value_loss              | 1.69                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.8                                 |\n",
      "|    ep_rew_mean             | 79.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 941                                  |\n",
      "|    iterations              | 279                                  |\n",
      "|    time_elapsed            | 19428                                |\n",
      "|    total_timesteps         | 18284544                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42                                   |\n",
      "|    ep_rew_mean             | 81.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 941                                  |\n",
      "|    iterations              | 280                                  |\n",
      "|    time_elapsed            | 19492                                |\n",
      "|    total_timesteps         | 18350080                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.015957654                          |\n",
      "|    clip_fraction           | 0.087                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.2                                 |\n",
      "|    explained_variance      | 0.975                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 12                                   |\n",
      "|    n_updates               | 2790                                 |\n",
      "|    policy_gradient_loss    | -0.00154                             |\n",
      "|    value_loss              | 17.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=18400000, episode_reward=83.35 +/- 0.22\n",
      "Episode length: 40.20 +/- 0.51\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.2                                 |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 18400000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.010718066                          |\n",
      "|    clip_fraction           | 0.0477                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0802                              |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.27                                 |\n",
      "|    n_updates               | 2800                                 |\n",
      "|    policy_gradient_loss    | 0.00176                              |\n",
      "|    value_loss              | 3                                    |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.5                                 |\n",
      "|    ep_rew_mean             | 82.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 941                                  |\n",
      "|    iterations              | 281                                  |\n",
      "|    time_elapsed            | 19558                                |\n",
      "|    total_timesteps         | 18415616                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.3                                 |\n",
      "|    ep_rew_mean             | 82.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 941                                  |\n",
      "|    iterations              | 282                                  |\n",
      "|    time_elapsed            | 19622                                |\n",
      "|    total_timesteps         | 18481152                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008161532                          |\n",
      "|    clip_fraction           | 0.0431                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0672                              |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.26                                 |\n",
      "|    n_updates               | 2810                                 |\n",
      "|    policy_gradient_loss    | 0.00137                              |\n",
      "|    value_loss              | 1.65                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.5                                 |\n",
      "|    ep_rew_mean             | 81.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 942                                  |\n",
      "|    iterations              | 283                                  |\n",
      "|    time_elapsed            | 19686                                |\n",
      "|    total_timesteps         | 18546688                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.02061729                           |\n",
      "|    clip_fraction           | 0.0314                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.073                               |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.119                                |\n",
      "|    n_updates               | 2820                                 |\n",
      "|    policy_gradient_loss    | 0.00105                              |\n",
      "|    value_loss              | 2.18                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=18560000, episode_reward=77.51 +/- 25.45\n",
      "Episode length: 45.75 +/- 24.84\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 45.8                                 |\n",
      "|    mean_reward             | 77.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 18560000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005132888                          |\n",
      "|    clip_fraction           | 0.0234                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0579                              |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.75                                 |\n",
      "|    n_updates               | 2830                                 |\n",
      "|    policy_gradient_loss    | 0.00318                              |\n",
      "|    value_loss              | 2.47                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40                                   |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 942                                  |\n",
      "|    iterations              | 284                                  |\n",
      "|    time_elapsed            | 19754                                |\n",
      "|    total_timesteps         | 18612224                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.1                                 |\n",
      "|    ep_rew_mean             | 82.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 942                                  |\n",
      "|    iterations              | 285                                  |\n",
      "|    time_elapsed            | 19817                                |\n",
      "|    total_timesteps         | 18677760                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0052009895                         |\n",
      "|    clip_fraction           | 0.0193                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0561                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.08                                 |\n",
      "|    n_updates               | 2840                                 |\n",
      "|    policy_gradient_loss    | 0.00424                              |\n",
      "|    value_loss              | 1.7                                  |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=18720000, episode_reward=83.40 +/- 0.00\n",
      "Episode length: 40.00 +/- 0.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 18720000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.019445194                          |\n",
      "|    clip_fraction           | 0.0196                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0454                              |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.397                                |\n",
      "|    n_updates               | 2850                                 |\n",
      "|    policy_gradient_loss    | -0.00115                             |\n",
      "|    value_loss              | 1.4                                  |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40                                   |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 942                                  |\n",
      "|    iterations              | 286                                  |\n",
      "|    time_elapsed            | 19885                                |\n",
      "|    total_timesteps         | 18743296                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.3                                 |\n",
      "|    ep_rew_mean             | 82.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 942                                  |\n",
      "|    iterations              | 287                                  |\n",
      "|    time_elapsed            | 19950                                |\n",
      "|    total_timesteps         | 18808832                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007531163                          |\n",
      "|    clip_fraction           | 0.0157                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0369                              |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.87                                 |\n",
      "|    n_updates               | 2860                                 |\n",
      "|    policy_gradient_loss    | 0.00143                              |\n",
      "|    value_loss              | 1.35                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.3                                 |\n",
      "|    ep_rew_mean             | 80.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 943                                  |\n",
      "|    iterations              | 288                                  |\n",
      "|    time_elapsed            | 20014                                |\n",
      "|    total_timesteps         | 18874368                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.043170184                          |\n",
      "|    clip_fraction           | 0.0278                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0453                              |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.646                                |\n",
      "|    n_updates               | 2870                                 |\n",
      "|    policy_gradient_loss    | -0.00214                             |\n",
      "|    value_loss              | 2                                    |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=18880000, episode_reward=83.40 +/- 0.00\n",
      "Episode length: 40.00 +/- 0.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 18880000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.012131443                          |\n",
      "|    clip_fraction           | 0.0275                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.059                               |\n",
      "|    explained_variance      | 0.989                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.35                                 |\n",
      "|    n_updates               | 2880                                 |\n",
      "|    policy_gradient_loss    | 0.00267                              |\n",
      "|    value_loss              | 3.95                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.2                                 |\n",
      "|    ep_rew_mean             | 82.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 943                                  |\n",
      "|    iterations              | 289                                  |\n",
      "|    time_elapsed            | 20079                                |\n",
      "|    total_timesteps         | 18939904                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 48.3                                 |\n",
      "|    ep_rew_mean             | 75                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 943                                  |\n",
      "|    iterations              | 290                                  |\n",
      "|    time_elapsed            | 20142                                |\n",
      "|    total_timesteps         | 19005440                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.015055794                          |\n",
      "|    clip_fraction           | 0.0472                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0664                              |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.944                                |\n",
      "|    n_updates               | 2890                                 |\n",
      "|    policy_gradient_loss    | 0.00168                              |\n",
      "|    value_loss              | 2.46                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=19040000, episode_reward=81.28 +/- 8.57\n",
      "Episode length: 42.15 +/- 8.70\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 42.1                                 |\n",
      "|    mean_reward             | 81.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 19040000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.026684124                          |\n",
      "|    clip_fraction           | 0.13                                 |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.425                               |\n",
      "|    explained_variance      | 0.959                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 10.9                                 |\n",
      "|    n_updates               | 2900                                 |\n",
      "|    policy_gradient_loss    | -0.0048                              |\n",
      "|    value_loss              | 29.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.8                                 |\n",
      "|    ep_rew_mean             | 81.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 943                                  |\n",
      "|    iterations              | 291                                  |\n",
      "|    time_elapsed            | 20207                                |\n",
      "|    total_timesteps         | 19070976                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.6                                 |\n",
      "|    ep_rew_mean             | 82.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 943                                  |\n",
      "|    iterations              | 292                                  |\n",
      "|    time_elapsed            | 20272                                |\n",
      "|    total_timesteps         | 19136512                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0035579666                         |\n",
      "|    clip_fraction           | 0.0298                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0885                              |\n",
      "|    explained_variance      | 0.981                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.81                                 |\n",
      "|    n_updates               | 2910                                 |\n",
      "|    policy_gradient_loss    | 0.00284                              |\n",
      "|    value_loss              | 7.68                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=19200000, episode_reward=83.40 +/- 0.00\n",
      "Episode length: 40.00 +/- 0.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 19200000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.023107145                          |\n",
      "|    clip_fraction           | 0.0144                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0311                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.13                                 |\n",
      "|    n_updates               | 2920                                 |\n",
      "|    policy_gradient_loss    | 0.00142                              |\n",
      "|    value_loss              | 2.22                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.6                                 |\n",
      "|    ep_rew_mean             | 82.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 944                                  |\n",
      "|    iterations              | 293                                  |\n",
      "|    time_elapsed            | 20337                                |\n",
      "|    total_timesteps         | 19202048                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.8                                 |\n",
      "|    ep_rew_mean             | 81.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 944                                  |\n",
      "|    iterations              | 294                                  |\n",
      "|    time_elapsed            | 20400                                |\n",
      "|    total_timesteps         | 19267584                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004599046                          |\n",
      "|    clip_fraction           | 0.0222                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0446                              |\n",
      "|    explained_variance      | 0.988                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.56                                 |\n",
      "|    n_updates               | 2930                                 |\n",
      "|    policy_gradient_loss    | 0.000807                             |\n",
      "|    value_loss              | 4.06                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44                                   |\n",
      "|    ep_rew_mean             | 79.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 944                                  |\n",
      "|    iterations              | 295                                  |\n",
      "|    time_elapsed            | 20462                                |\n",
      "|    total_timesteps         | 19333120                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00778716                           |\n",
      "|    clip_fraction           | 0.0181                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0412                              |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 12.7                                 |\n",
      "|    n_updates               | 2940                                 |\n",
      "|    policy_gradient_loss    | 0.00393                              |\n",
      "|    value_loss              | 2.83                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=19360000, episode_reward=83.36 +/- 0.17\n",
      "Episode length: 40.05 +/- 0.22\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 19360000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005079699                          |\n",
      "|    clip_fraction           | 0.0509                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.134                               |\n",
      "|    explained_variance      | 0.967                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 3.97                                 |\n",
      "|    n_updates               | 2950                                 |\n",
      "|    policy_gradient_loss    | 0.00124                              |\n",
      "|    value_loss              | 9.63                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40                                   |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 945                                  |\n",
      "|    iterations              | 296                                  |\n",
      "|    time_elapsed            | 20527                                |\n",
      "|    total_timesteps         | 19398656                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45.2                                 |\n",
      "|    ep_rew_mean             | 78.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 945                                  |\n",
      "|    iterations              | 297                                  |\n",
      "|    time_elapsed            | 20590                                |\n",
      "|    total_timesteps         | 19464192                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005170889                          |\n",
      "|    clip_fraction           | 0.017                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0318                              |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0617                               |\n",
      "|    n_updates               | 2960                                 |\n",
      "|    policy_gradient_loss    | 0.00482                              |\n",
      "|    value_loss              | 1.18                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=19520000, episode_reward=75.88 +/- 25.26\n",
      "Episode length: 47.65 +/- 25.42\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 47.6                                 |\n",
      "|    mean_reward             | 75.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 19520000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005769669                          |\n",
      "|    clip_fraction           | 0.103                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.439                               |\n",
      "|    explained_variance      | 0.966                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.65                                 |\n",
      "|    n_updates               | 2970                                 |\n",
      "|    policy_gradient_loss    | -0.00116                             |\n",
      "|    value_loss              | 17.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43                                   |\n",
      "|    ep_rew_mean             | 80.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 945                                  |\n",
      "|    iterations              | 298                                  |\n",
      "|    time_elapsed            | 20657                                |\n",
      "|    total_timesteps         | 19529728                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.5                                 |\n",
      "|    ep_rew_mean             | 82.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 945                                  |\n",
      "|    iterations              | 299                                  |\n",
      "|    time_elapsed            | 20720                                |\n",
      "|    total_timesteps         | 19595264                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0047394508                         |\n",
      "|    clip_fraction           | 0.0834                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.285                               |\n",
      "|    explained_variance      | 0.979                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.55                                 |\n",
      "|    n_updates               | 2980                                 |\n",
      "|    policy_gradient_loss    | -0.00199                             |\n",
      "|    value_loss              | 12.3                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40                                   |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 300                                  |\n",
      "|    time_elapsed            | 20782                                |\n",
      "|    total_timesteps         | 19660800                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0064346166                         |\n",
      "|    clip_fraction           | 0.0241                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0774                              |\n",
      "|    explained_variance      | 0.991                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.12                                 |\n",
      "|    n_updates               | 2990                                 |\n",
      "|    policy_gradient_loss    | 0.00567                              |\n",
      "|    value_loss              | 3.56                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=19680000, episode_reward=35.61 +/- 60.78\n",
      "Episode length: 83.45 +/- 52.98\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 83.5                                 |\n",
      "|    mean_reward             | 35.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 19680000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008155396                          |\n",
      "|    clip_fraction           | 0.0554                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0442                              |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0415                               |\n",
      "|    n_updates               | 3000                                 |\n",
      "|    policy_gradient_loss    | -0.000394                            |\n",
      "|    value_loss              | 0.43                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 94.5                                 |\n",
      "|    ep_rew_mean             | 24.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 945                                  |\n",
      "|    iterations              | 301                                  |\n",
      "|    time_elapsed            | 20853                                |\n",
      "|    total_timesteps         | 19726336                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 79.4                                 |\n",
      "|    ep_rew_mean             | 42                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 302                                  |\n",
      "|    time_elapsed            | 20918                                |\n",
      "|    total_timesteps         | 19791872                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0137584135                         |\n",
      "|    clip_fraction           | 0.223                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.03                                |\n",
      "|    explained_variance      | 0.927                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 30.5                                 |\n",
      "|    n_updates               | 3010                                 |\n",
      "|    policy_gradient_loss    | -0.0104                              |\n",
      "|    value_loss              | 44.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=19840000, episode_reward=48.44 +/- 51.49\n",
      "Episode length: 75.15 +/- 51.66\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 75.2                                 |\n",
      "|    mean_reward             | 48.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 19840000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008121297                          |\n",
      "|    clip_fraction           | 0.183                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.02                                |\n",
      "|    explained_variance      | 0.944                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 25.4                                 |\n",
      "|    n_updates               | 3020                                 |\n",
      "|    policy_gradient_loss    | -0.00495                             |\n",
      "|    value_loss              | 52.6                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 59.5                                 |\n",
      "|    ep_rew_mean             | 63.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 945                                  |\n",
      "|    iterations              | 303                                  |\n",
      "|    time_elapsed            | 20992                                |\n",
      "|    total_timesteps         | 19857408                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.9                                 |\n",
      "|    ep_rew_mean             | 79.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 304                                  |\n",
      "|    time_elapsed            | 21057                                |\n",
      "|    total_timesteps         | 19922944                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009010163                          |\n",
      "|    clip_fraction           | 0.144                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.67                                |\n",
      "|    explained_variance      | 0.954                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 30.7                                 |\n",
      "|    n_updates               | 3030                                 |\n",
      "|    policy_gradient_loss    | -0.0043                              |\n",
      "|    value_loss              | 46.2                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.6                                 |\n",
      "|    ep_rew_mean             | 81.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 305                                  |\n",
      "|    time_elapsed            | 21122                                |\n",
      "|    total_timesteps         | 19988480                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0041739624                         |\n",
      "|    clip_fraction           | 0.0679                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.233                               |\n",
      "|    explained_variance      | 0.969                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.7                                  |\n",
      "|    n_updates               | 3040                                 |\n",
      "|    policy_gradient_loss    | -0.000638                            |\n",
      "|    value_loss              | 16.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=20000000, episode_reward=62.74 +/- 40.82\n",
      "Episode length: 60.60 +/- 40.57\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 60.6                                 |\n",
      "|    mean_reward             | 62.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 20000000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007665127                          |\n",
      "|    clip_fraction           | 0.0565                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.075                               |\n",
      "|    explained_variance      | 0.988                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.82                                 |\n",
      "|    n_updates               | 3050                                 |\n",
      "|    policy_gradient_loss    | 0.000332                             |\n",
      "|    value_loss              | 3.43                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 63.7                                 |\n",
      "|    ep_rew_mean             | 59.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 306                                  |\n",
      "|    time_elapsed            | 21192                                |\n",
      "|    total_timesteps         | 20054016                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 57.2                                 |\n",
      "|    ep_rew_mean             | 66.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 307                                  |\n",
      "|    time_elapsed            | 21256                                |\n",
      "|    total_timesteps         | 20119552                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004521222                          |\n",
      "|    clip_fraction           | 0.139                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.975                               |\n",
      "|    explained_variance      | 0.952                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 27.6                                 |\n",
      "|    n_updates               | 3060                                 |\n",
      "|    policy_gradient_loss    | -0.00308                             |\n",
      "|    value_loss              | 49.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=20160000, episode_reward=82.75 +/- 0.79\n",
      "Episode length: 40.70 +/- 0.78\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.7                                 |\n",
      "|    mean_reward             | 82.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 20160000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0081960615                         |\n",
      "|    clip_fraction           | 0.114                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.6                                 |\n",
      "|    explained_variance      | 0.957                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 19                                   |\n",
      "|    n_updates               | 3070                                 |\n",
      "|    policy_gradient_loss    | -0.00264                             |\n",
      "|    value_loss              | 40.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.4                                 |\n",
      "|    ep_rew_mean             | 82                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 308                                  |\n",
      "|    time_elapsed            | 21326                                |\n",
      "|    total_timesteps         | 20185088                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.1                                 |\n",
      "|    ep_rew_mean             | 83.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 309                                  |\n",
      "|    time_elapsed            | 21390                                |\n",
      "|    total_timesteps         | 20250624                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008888653                          |\n",
      "|    clip_fraction           | 0.047                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.123                               |\n",
      "|    explained_variance      | 0.976                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.02                                 |\n",
      "|    n_updates               | 3080                                 |\n",
      "|    policy_gradient_loss    | 0.00122                              |\n",
      "|    value_loss              | 8.54                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 140                                  |\n",
      "|    ep_rew_mean             | -19.8                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 310                                  |\n",
      "|    time_elapsed            | 21455                                |\n",
      "|    total_timesteps         | 20316160                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.12629017                           |\n",
      "|    clip_fraction           | 0.291                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.198                               |\n",
      "|    explained_variance      | 0.995                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | -0.00412                             |\n",
      "|    n_updates               | 3090                                 |\n",
      "|    policy_gradient_loss    | -0.0146                              |\n",
      "|    value_loss              | 0.759                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=20320000, episode_reward=-16.71 +/- 33.67\n",
      "Episode length: 138.25 +/- 31.38\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 138                                  |\n",
      "|    mean_reward             | -16.7                                |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 20320000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004545759                          |\n",
      "|    clip_fraction           | 0.169                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.33                                |\n",
      "|    explained_variance      | 0.921                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 11.6                                 |\n",
      "|    n_updates               | 3100                                 |\n",
      "|    policy_gradient_loss    | -0.000807                            |\n",
      "|    value_loss              | 30.8                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 132                                  |\n",
      "|    ep_rew_mean             | -10.8                                |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 311                                  |\n",
      "|    time_elapsed            | 21531                                |\n",
      "|    total_timesteps         | 20381696                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 116                                  |\n",
      "|    ep_rew_mean             | 7.11                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 312                                  |\n",
      "|    time_elapsed            | 21596                                |\n",
      "|    total_timesteps         | 20447232                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005727818                          |\n",
      "|    clip_fraction           | 0.214                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.45                                |\n",
      "|    explained_variance      | 0.943                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 31.8                                 |\n",
      "|    n_updates               | 3110                                 |\n",
      "|    policy_gradient_loss    | -0.00189                             |\n",
      "|    value_loss              | 30.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=20480000, episode_reward=32.50 +/- 41.89\n",
      "Episode length: 91.80 +/- 41.50\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 91.8                                 |\n",
      "|    mean_reward             | 32.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 20480000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.008076267                          |\n",
      "|    clip_fraction           | 0.213                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.54                                |\n",
      "|    explained_variance      | 0.924                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 21.5                                 |\n",
      "|    n_updates               | 3120                                 |\n",
      "|    policy_gradient_loss    | -0.00172                             |\n",
      "|    value_loss              | 41.1                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 103                                  |\n",
      "|    ep_rew_mean             | 21                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 313                                  |\n",
      "|    time_elapsed            | 21667                                |\n",
      "|    total_timesteps         | 20512768                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 91.5                                 |\n",
      "|    ep_rew_mean             | 33.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 314                                  |\n",
      "|    time_elapsed            | 21731                                |\n",
      "|    total_timesteps         | 20578304                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005287042                          |\n",
      "|    clip_fraction           | 0.195                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.52                                |\n",
      "|    explained_variance      | 0.91                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 27.4                                 |\n",
      "|    n_updates               | 3130                                 |\n",
      "|    policy_gradient_loss    | -0.00108                             |\n",
      "|    value_loss              | 55.6                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=20640000, episode_reward=36.61 +/- 45.66\n",
      "Episode length: 87.80 +/- 44.79\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 87.8                                 |\n",
      "|    mean_reward             | 36.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 20640000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004336249                          |\n",
      "|    clip_fraction           | 0.191                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.46                                |\n",
      "|    explained_variance      | 0.915                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 37.2                                 |\n",
      "|    n_updates               | 3140                                 |\n",
      "|    policy_gradient_loss    | -0.00129                             |\n",
      "|    value_loss              | 63.2                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 82.5                                 |\n",
      "|    ep_rew_mean             | 42.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 946                                  |\n",
      "|    iterations              | 315                                  |\n",
      "|    time_elapsed            | 21802                                |\n",
      "|    total_timesteps         | 20643840                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 72.7                                 |\n",
      "|    ep_rew_mean             | 52.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 947                                  |\n",
      "|    iterations              | 316                                  |\n",
      "|    time_elapsed            | 21866                                |\n",
      "|    total_timesteps         | 20709376                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0036989918                         |\n",
      "|    clip_fraction           | 0.178                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.36                                |\n",
      "|    explained_variance      | 0.926                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 24.2                                 |\n",
      "|    n_updates               | 3150                                 |\n",
      "|    policy_gradient_loss    | -0.00169                             |\n",
      "|    value_loss              | 70.9                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 60.2                                 |\n",
      "|    ep_rew_mean             | 64.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 947                                  |\n",
      "|    iterations              | 317                                  |\n",
      "|    time_elapsed            | 21929                                |\n",
      "|    total_timesteps         | 20774912                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0039174473                         |\n",
      "|    clip_fraction           | 0.175                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -1.2                                 |\n",
      "|    explained_variance      | 0.929                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 50.8                                 |\n",
      "|    n_updates               | 3160                                 |\n",
      "|    policy_gradient_loss    | -0.00214                             |\n",
      "|    value_loss              | 71.9                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=20800000, episode_reward=76.13 +/- 8.59\n",
      "Episode length: 48.60 +/- 8.78\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 48.6                                 |\n",
      "|    mean_reward             | 76.1                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 20800000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005264174                          |\n",
      "|    clip_fraction           | 0.173                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.941                               |\n",
      "|    explained_variance      | 0.926                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 40.7                                 |\n",
      "|    n_updates               | 3170                                 |\n",
      "|    policy_gradient_loss    | -0.0029                              |\n",
      "|    value_loss              | 67.3                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 56.8                                 |\n",
      "|    ep_rew_mean             | 68.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 947                                  |\n",
      "|    iterations              | 318                                  |\n",
      "|    time_elapsed            | 21995                                |\n",
      "|    total_timesteps         | 20840448                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 52.6                                 |\n",
      "|    ep_rew_mean             | 72.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 947                                  |\n",
      "|    iterations              | 319                                  |\n",
      "|    time_elapsed            | 22058                                |\n",
      "|    total_timesteps         | 20905984                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0051250844                         |\n",
      "|    clip_fraction           | 0.166                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.742                               |\n",
      "|    explained_variance      | 0.94                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 37.5                                 |\n",
      "|    n_updates               | 3180                                 |\n",
      "|    policy_gradient_loss    | -0.00255                             |\n",
      "|    value_loss              | 49.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=20960000, episode_reward=80.61 +/- 2.56\n",
      "Episode length: 44.30 +/- 2.85\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 44.3                                 |\n",
      "|    mean_reward             | 80.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 20960000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0055817957                         |\n",
      "|    clip_fraction           | 0.143                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.549                               |\n",
      "|    explained_variance      | 0.953                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 20.5                                 |\n",
      "|    n_updates               | 3190                                 |\n",
      "|    policy_gradient_loss    | -0.00119                             |\n",
      "|    value_loss              | 33.1                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 45.1                                 |\n",
      "|    ep_rew_mean             | 79.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 947                                  |\n",
      "|    iterations              | 320                                  |\n",
      "|    time_elapsed            | 22124                                |\n",
      "|    total_timesteps         | 20971520                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.1                                 |\n",
      "|    ep_rew_mean             | 80.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 948                                  |\n",
      "|    iterations              | 321                                  |\n",
      "|    time_elapsed            | 22187                                |\n",
      "|    total_timesteps         | 21037056                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0050851954                         |\n",
      "|    clip_fraction           | 0.115                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.348                               |\n",
      "|    explained_variance      | 0.965                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.82                                 |\n",
      "|    n_updates               | 3200                                 |\n",
      "|    policy_gradient_loss    | -0.000565                            |\n",
      "|    value_loss              | 19.1                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 43.4                                 |\n",
      "|    ep_rew_mean             | 81.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 948                                  |\n",
      "|    iterations              | 322                                  |\n",
      "|    time_elapsed            | 22249                                |\n",
      "|    total_timesteps         | 21102592                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0045138113                         |\n",
      "|    clip_fraction           | 0.0878                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.282                               |\n",
      "|    explained_variance      | 0.978                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.44                                 |\n",
      "|    n_updates               | 3210                                 |\n",
      "|    policy_gradient_loss    | 0.00282                              |\n",
      "|    value_loss              | 8.17                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=21120000, episode_reward=82.28 +/- 0.99\n",
      "Episode length: 42.30 +/- 1.27\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 42.3                                 |\n",
      "|    mean_reward             | 82.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 21120000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009400012                          |\n",
      "|    clip_fraction           | 0.1                                  |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.164                               |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.68                                 |\n",
      "|    n_updates               | 3220                                 |\n",
      "|    policy_gradient_loss    | -0.000996                            |\n",
      "|    value_loss              | 2.01                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.4                                 |\n",
      "|    ep_rew_mean             | 82.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 948                                  |\n",
      "|    iterations              | 323                                  |\n",
      "|    time_elapsed            | 22314                                |\n",
      "|    total_timesteps         | 21168128                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.8                                 |\n",
      "|    ep_rew_mean             | 82.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 948                                  |\n",
      "|    iterations              | 324                                  |\n",
      "|    time_elapsed            | 22377                                |\n",
      "|    total_timesteps         | 21233664                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006241753                          |\n",
      "|    clip_fraction           | 0.0694                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.128                               |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.442                                |\n",
      "|    n_updates               | 3230                                 |\n",
      "|    policy_gradient_loss    | 0.0015                               |\n",
      "|    value_loss              | 1.13                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=21280000, episode_reward=82.64 +/- 0.85\n",
      "Episode length: 41.90 +/- 1.22\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41.9                                 |\n",
      "|    mean_reward             | 82.6                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 21280000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004702332                          |\n",
      "|    clip_fraction           | 0.0546                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0937                              |\n",
      "|    explained_variance      | 0.997                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.13                                 |\n",
      "|    n_updates               | 3240                                 |\n",
      "|    policy_gradient_loss    | 0.00097                              |\n",
      "|    value_loss              | 0.921                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.6                                 |\n",
      "|    ep_rew_mean             | 82.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 949                                  |\n",
      "|    iterations              | 325                                  |\n",
      "|    time_elapsed            | 22442                                |\n",
      "|    total_timesteps         | 21299200                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.9                                 |\n",
      "|    ep_rew_mean             | 79.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 949                                  |\n",
      "|    iterations              | 326                                  |\n",
      "|    time_elapsed            | 22505                                |\n",
      "|    total_timesteps         | 21364736                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.018464228                          |\n",
      "|    clip_fraction           | 0.0758                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0907                              |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.00738                              |\n",
      "|    n_updates               | 3250                                 |\n",
      "|    policy_gradient_loss    | -0.000504                            |\n",
      "|    value_loss              | 0.305                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 44.9                                 |\n",
      "|    ep_rew_mean             | 79.5                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 949                                  |\n",
      "|    iterations              | 327                                  |\n",
      "|    time_elapsed            | 22567                                |\n",
      "|    total_timesteps         | 21430272                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009311881                          |\n",
      "|    clip_fraction           | 0.0955                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.344                               |\n",
      "|    explained_variance      | 0.975                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.55                                 |\n",
      "|    n_updates               | 3260                                 |\n",
      "|    policy_gradient_loss    | -0.00334                             |\n",
      "|    value_loss              | 8.65                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=21440000, episode_reward=82.24 +/- 2.89\n",
      "Episode length: 41.90 +/- 3.05\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41.9                                 |\n",
      "|    mean_reward             | 82.2                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 21440000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007072089                          |\n",
      "|    clip_fraction           | 0.0676                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.185                               |\n",
      "|    explained_variance      | 0.987                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.45                                 |\n",
      "|    n_updates               | 3270                                 |\n",
      "|    policy_gradient_loss    | 0.00304                              |\n",
      "|    value_loss              | 4.41                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.3                                 |\n",
      "|    ep_rew_mean             | 81.9                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 949                                  |\n",
      "|    iterations              | 328                                  |\n",
      "|    time_elapsed            | 22632                                |\n",
      "|    total_timesteps         | 21495808                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.6                                 |\n",
      "|    ep_rew_mean             | 80.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 950                                  |\n",
      "|    iterations              | 329                                  |\n",
      "|    time_elapsed            | 22694                                |\n",
      "|    total_timesteps         | 21561344                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007048676                          |\n",
      "|    clip_fraction           | 0.0387                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0903                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.154                                |\n",
      "|    n_updates               | 3280                                 |\n",
      "|    policy_gradient_loss    | 0.00268                              |\n",
      "|    value_loss              | 1.27                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=21600000, episode_reward=82.53 +/- 1.83\n",
      "Episode length: 41.55 +/- 2.18\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41.5                                 |\n",
      "|    mean_reward             | 82.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 21600000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004842787                          |\n",
      "|    clip_fraction           | 0.0463                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.101                               |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.96                                 |\n",
      "|    n_updates               | 3290                                 |\n",
      "|    policy_gradient_loss    | 0.00241                              |\n",
      "|    value_loss              | 1.76                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.2                                 |\n",
      "|    ep_rew_mean             | 82.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 950                                  |\n",
      "|    iterations              | 330                                  |\n",
      "|    time_elapsed            | 22760                                |\n",
      "|    total_timesteps         | 21626880                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 54.8                                 |\n",
      "|    ep_rew_mean             | 69.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 950                                  |\n",
      "|    iterations              | 331                                  |\n",
      "|    time_elapsed            | 22824                                |\n",
      "|    total_timesteps         | 21692416                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.04119239                           |\n",
      "|    clip_fraction           | 0.081                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.103                               |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0451                               |\n",
      "|    n_updates               | 3300                                 |\n",
      "|    policy_gradient_loss    | -0.000403                            |\n",
      "|    value_loss              | 1.23                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.1                                 |\n",
      "|    ep_rew_mean             | 78.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 950                                  |\n",
      "|    iterations              | 332                                  |\n",
      "|    time_elapsed            | 22889                                |\n",
      "|    total_timesteps         | 21757952                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.06150194                           |\n",
      "|    clip_fraction           | 0.243                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.807                               |\n",
      "|    explained_variance      | 0.951                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 5.6                                  |\n",
      "|    n_updates               | 3310                                 |\n",
      "|    policy_gradient_loss    | -0.0128                              |\n",
      "|    value_loss              | 14.4                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=21760000, episode_reward=82.27 +/- 2.05\n",
      "Episode length: 41.65 +/- 2.26\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41.6                                 |\n",
      "|    mean_reward             | 82.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 21760000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007236992                          |\n",
      "|    clip_fraction           | 0.118                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.303                               |\n",
      "|    explained_variance      | 0.978                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.96                                 |\n",
      "|    n_updates               | 3320                                 |\n",
      "|    policy_gradient_loss    | -0.00279                             |\n",
      "|    value_loss              | 10.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.7                                 |\n",
      "|    ep_rew_mean             | 82.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 950                                  |\n",
      "|    iterations              | 333                                  |\n",
      "|    time_elapsed            | 22956                                |\n",
      "|    total_timesteps         | 21823488                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.4                                 |\n",
      "|    ep_rew_mean             | 81.6                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 950                                  |\n",
      "|    iterations              | 334                                  |\n",
      "|    time_elapsed            | 23018                                |\n",
      "|    total_timesteps         | 21889024                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.010031153                          |\n",
      "|    clip_fraction           | 0.0577                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.159                               |\n",
      "|    explained_variance      | 0.984                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.51                                 |\n",
      "|    n_updates               | 3330                                 |\n",
      "|    policy_gradient_loss    | 0.00134                              |\n",
      "|    value_loss              | 4.92                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=21920000, episode_reward=82.75 +/- 1.02\n",
      "Episode length: 41.10 +/- 1.22\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 41.1                                 |\n",
      "|    mean_reward             | 82.8                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 21920000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.00935274                           |\n",
      "|    clip_fraction           | 0.0508                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0842                              |\n",
      "|    explained_variance      | 0.996                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.167                                |\n",
      "|    n_updates               | 3340                                 |\n",
      "|    policy_gradient_loss    | 0.0038                               |\n",
      "|    value_loss              | 1.22                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.1                                 |\n",
      "|    ep_rew_mean             | 82.8                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 951                                  |\n",
      "|    iterations              | 335                                  |\n",
      "|    time_elapsed            | 23084                                |\n",
      "|    total_timesteps         | 21954560                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.7                                 |\n",
      "|    ep_rew_mean             | 82                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 951                                  |\n",
      "|    iterations              | 336                                  |\n",
      "|    time_elapsed            | 23145                                |\n",
      "|    total_timesteps         | 22020096                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0059510283                         |\n",
      "|    clip_fraction           | 0.0506                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0827                              |\n",
      "|    explained_variance      | 0.998                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0943                               |\n",
      "|    n_updates               | 3350                                 |\n",
      "|    policy_gradient_loss    | 0.00109                              |\n",
      "|    value_loss              | 0.743                                |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=22080000, episode_reward=83.34 +/- 0.14\n",
      "Episode length: 40.30 +/- 0.46\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.3                                 |\n",
      "|    mean_reward             | 83.3                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 22080000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.013101846                          |\n",
      "|    clip_fraction           | 0.0616                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0836                              |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0144                               |\n",
      "|    n_updates               | 3360                                 |\n",
      "|    policy_gradient_loss    | -0.00174                             |\n",
      "|    value_loss              | 0.207                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.6                                 |\n",
      "|    ep_rew_mean             | 83.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 951                                  |\n",
      "|    iterations              | 337                                  |\n",
      "|    time_elapsed            | 23210                                |\n",
      "|    total_timesteps         | 22085632                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.5                                 |\n",
      "|    ep_rew_mean             | 77.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 951                                  |\n",
      "|    iterations              | 338                                  |\n",
      "|    time_elapsed            | 23272                                |\n",
      "|    total_timesteps         | 22151168                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006450583                          |\n",
      "|    clip_fraction           | 0.0676                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0914                              |\n",
      "|    explained_variance      | 0.999                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0146                               |\n",
      "|    n_updates               | 3370                                 |\n",
      "|    policy_gradient_loss    | -0.00053                             |\n",
      "|    value_loss              | 0.381                                |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.2                                 |\n",
      "|    ep_rew_mean             | 83.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 952                                  |\n",
      "|    iterations              | 339                                  |\n",
      "|    time_elapsed            | 23335                                |\n",
      "|    total_timesteps         | 22216704                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0068348106                         |\n",
      "|    clip_fraction           | 0.0694                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.317                               |\n",
      "|    explained_variance      | 0.967                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 15.5                                 |\n",
      "|    n_updates               | 3380                                 |\n",
      "|    policy_gradient_loss    | -0.0011                              |\n",
      "|    value_loss              | 17.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=22240000, episode_reward=82.71 +/- 0.89\n",
      "Episode length: 40.90 +/- 0.94\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.9                                 |\n",
      "|    mean_reward             | 82.7                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 22240000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.040176578                          |\n",
      "|    clip_fraction           | 0.0754                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.135                               |\n",
      "|    explained_variance      | 0.99                                 |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.311                                |\n",
      "|    n_updates               | 3390                                 |\n",
      "|    policy_gradient_loss    | 0.0116                               |\n",
      "|    value_loss              | 2.87                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42.5                                 |\n",
      "|    ep_rew_mean             | 81.2                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 952                                  |\n",
      "|    iterations              | 340                                  |\n",
      "|    time_elapsed            | 23400                                |\n",
      "|    total_timesteps         | 22282240                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 42                                   |\n",
      "|    ep_rew_mean             | 81.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 952                                  |\n",
      "|    iterations              | 341                                  |\n",
      "|    time_elapsed            | 23463                                |\n",
      "|    total_timesteps         | 22347776                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.025995374                          |\n",
      "|    clip_fraction           | 0.0948                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.146                               |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.284                                |\n",
      "|    n_updates               | 3400                                 |\n",
      "|    policy_gradient_loss    | -0.000517                            |\n",
      "|    value_loss              | 1.95                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=22400000, episode_reward=77.37 +/- 24.67\n",
      "Episode length: 46.10 +/- 24.79\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 46.1                                 |\n",
      "|    mean_reward             | 77.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 22400000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.10963961                           |\n",
      "|    clip_fraction           | 0.087                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0995                              |\n",
      "|    explained_variance      | 0.995                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.05                                 |\n",
      "|    n_updates               | 3410                                 |\n",
      "|    policy_gradient_loss    | -0.00323                             |\n",
      "|    value_loss              | 1.43                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.2                                 |\n",
      "|    ep_rew_mean             | 83.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 952                                  |\n",
      "|    iterations              | 342                                  |\n",
      "|    time_elapsed            | 23528                                |\n",
      "|    total_timesteps         | 22413312                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.7                                 |\n",
      "|    ep_rew_mean             | 82.7                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 952                                  |\n",
      "|    iterations              | 343                                  |\n",
      "|    time_elapsed            | 23590                                |\n",
      "|    total_timesteps         | 22478848                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.034006234                          |\n",
      "|    clip_fraction           | 0.0564                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0885                              |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.116                                |\n",
      "|    n_updates               | 3420                                 |\n",
      "|    policy_gradient_loss    | -0.00409                             |\n",
      "|    value_loss              | 1.25                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40                                   |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 953                                  |\n",
      "|    iterations              | 344                                  |\n",
      "|    time_elapsed            | 23652                                |\n",
      "|    total_timesteps         | 22544384                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.052089937                          |\n",
      "|    clip_fraction           | 0.088                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0903                              |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.73                                 |\n",
      "|    n_updates               | 3430                                 |\n",
      "|    policy_gradient_loss    | -0.005                               |\n",
      "|    value_loss              | 1.45                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=22560000, episode_reward=83.40 +/- 0.00\n",
      "Episode length: 40.00 +/- 0.00\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40                                   |\n",
      "|    mean_reward             | 83.4                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 22560000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.017968785                          |\n",
      "|    clip_fraction           | 0.0473                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0736                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.058                                |\n",
      "|    n_updates               | 3440                                 |\n",
      "|    policy_gradient_loss    | -0.00291                             |\n",
      "|    value_loss              | 1.51                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.1                                 |\n",
      "|    ep_rew_mean             | 82.3                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 953                                  |\n",
      "|    iterations              | 345                                  |\n",
      "|    time_elapsed            | 23718                                |\n",
      "|    total_timesteps         | 22609920                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.3                                 |\n",
      "|    ep_rew_mean             | 82.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 953                                  |\n",
      "|    iterations              | 346                                  |\n",
      "|    time_elapsed            | 23780                                |\n",
      "|    total_timesteps         | 22675456                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.009696422                          |\n",
      "|    clip_fraction           | 0.0496                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.095                               |\n",
      "|    explained_variance      | 0.991                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.193                                |\n",
      "|    n_updates               | 3450                                 |\n",
      "|    policy_gradient_loss    | 0.000727                             |\n",
      "|    value_loss              | 3.44                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=22720000, episode_reward=82.54 +/- 3.75\n",
      "Episode length: 40.90 +/- 3.92\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.9                                 |\n",
      "|    mean_reward             | 82.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 22720000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.014811039                          |\n",
      "|    clip_fraction           | 0.0449                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0877                              |\n",
      "|    explained_variance      | 0.994                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.0941                               |\n",
      "|    n_updates               | 3460                                 |\n",
      "|    policy_gradient_loss    | 0.00385                              |\n",
      "|    value_loss              | 2.46                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.3                                 |\n",
      "|    ep_rew_mean             | 83.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 953                                  |\n",
      "|    iterations              | 347                                  |\n",
      "|    time_elapsed            | 23845                                |\n",
      "|    total_timesteps         | 22740992                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.3                                 |\n",
      "|    ep_rew_mean             | 83.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 953                                  |\n",
      "|    iterations              | 348                                  |\n",
      "|    time_elapsed            | 23907                                |\n",
      "|    total_timesteps         | 22806528                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.020372842                          |\n",
      "|    clip_fraction           | 0.036                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0816                              |\n",
      "|    explained_variance      | 0.989                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 4.48                                 |\n",
      "|    n_updates               | 3470                                 |\n",
      "|    policy_gradient_loss    | 0.00217                              |\n",
      "|    value_loss              | 3.99                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 54.9                                 |\n",
      "|    ep_rew_mean             | 68.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 954                                  |\n",
      "|    iterations              | 349                                  |\n",
      "|    time_elapsed            | 23971                                |\n",
      "|    total_timesteps         | 22872064                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.014099134                          |\n",
      "|    clip_fraction           | 0.0441                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0853                              |\n",
      "|    explained_variance      | 0.993                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.844                                |\n",
      "|    n_updates               | 3480                                 |\n",
      "|    policy_gradient_loss    | -0.00161                             |\n",
      "|    value_loss              | 2.49                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=22880000, episode_reward=80.94 +/- 10.04\n",
      "Episode length: 42.55 +/- 10.21\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 42.5                                 |\n",
      "|    mean_reward             | 80.9                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 22880000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.005017334                          |\n",
      "|    clip_fraction           | 0.103                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.539                               |\n",
      "|    explained_variance      | 0.975                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 9.79                                 |\n",
      "|    n_updates               | 3490                                 |\n",
      "|    policy_gradient_loss    | -0.0019                              |\n",
      "|    value_loss              | 41.7                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 41.2                                 |\n",
      "|    ep_rew_mean             | 82.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 954                                  |\n",
      "|    iterations              | 350                                  |\n",
      "|    time_elapsed            | 24036                                |\n",
      "|    total_timesteps         | 22937600                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40                                   |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 954                                  |\n",
      "|    iterations              | 351                                  |\n",
      "|    time_elapsed            | 24098                                |\n",
      "|    total_timesteps         | 23003136                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.004272013                          |\n",
      "|    clip_fraction           | 0.0586                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.201                               |\n",
      "|    explained_variance      | 0.984                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.94                                 |\n",
      "|    n_updates               | 3500                                 |\n",
      "|    policy_gradient_loss    | 0.000527                             |\n",
      "|    value_loss              | 15                                   |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=23040000, episode_reward=48.52 +/- 53.30\n",
      "Episode length: 74.20 +/- 52.24\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 74.2                                 |\n",
      "|    mean_reward             | 48.5                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 23040000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.007682393                          |\n",
      "|    clip_fraction           | 0.0339                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0788                              |\n",
      "|    explained_variance      | 0.992                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 1.48                                 |\n",
      "|    n_updates               | 3510                                 |\n",
      "|    policy_gradient_loss    | 0.00558                              |\n",
      "|    value_loss              | 3.33                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 54.2                                 |\n",
      "|    ep_rew_mean             | 69                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 954                                  |\n",
      "|    iterations              | 352                                  |\n",
      "|    time_elapsed            | 24167                                |\n",
      "|    total_timesteps         | 23068672                             |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 46.3                                 |\n",
      "|    ep_rew_mean             | 77.1                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 954                                  |\n",
      "|    iterations              | 353                                  |\n",
      "|    time_elapsed            | 24229                                |\n",
      "|    total_timesteps         | 23134208                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.0038561404                         |\n",
      "|    clip_fraction           | 0.0944                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.629                               |\n",
      "|    explained_variance      | 0.964                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 44.1                                 |\n",
      "|    n_updates               | 3520                                 |\n",
      "|    policy_gradient_loss    | -0.00169                             |\n",
      "|    value_loss              | 69.3                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.1                                 |\n",
      "|    ep_rew_mean             | 83.4                                 |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 954                                  |\n",
      "|    iterations              | 354                                  |\n",
      "|    time_elapsed            | 24293                                |\n",
      "|    total_timesteps         | 23199744                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.006161866                          |\n",
      "|    clip_fraction           | 0.065                                |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.3                                 |\n",
      "|    explained_variance      | 0.976                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 2.26                                 |\n",
      "|    n_updates               | 3530                                 |\n",
      "|    policy_gradient_loss    | -0.00109                             |\n",
      "|    value_loss              | 31.5                                 |\n",
      "---------------------------------------------------------------------\n",
      "Eval num_timesteps=23200000, episode_reward=83.15 +/- 0.54\n",
      "Episode length: 40.55 +/- 0.86\n",
      "---------------------------------------------------------------------\n",
      "| eval/                      |                                      |\n",
      "|    mean_ep_length          | 40.5                                 |\n",
      "|    mean_reward             | 83.2                                 |\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| time/                      |                                      |\n",
      "|    total_timesteps         | 23200000                             |\n",
      "| train/                     |                                      |\n",
      "|    approx_kl               | 0.011777086                          |\n",
      "|    clip_fraction           | 0.0412                               |\n",
      "|    clip_range              | 0.1                                  |\n",
      "|    entropy_loss            | -0.0837                              |\n",
      "|    explained_variance      | 0.988                                |\n",
      "|    learning_rate           | 5e-05                                |\n",
      "|    loss                    | 0.142                                |\n",
      "|    n_updates               | 3540                                 |\n",
      "|    policy_gradient_loss    | 0.0012                               |\n",
      "|    value_loss              | 2.69                                 |\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "| permutation/               |                                      |\n",
      "|    best_permutation        | 2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4... |\n",
      "|    best_permutation_length | 179                                  |\n",
      "| rollout/                   |                                      |\n",
      "|    ep_len_mean             | 40.5                                 |\n",
      "|    ep_rew_mean             | 83                                   |\n",
      "| time/                      |                                      |\n",
      "|    fps                     | 955                                  |\n",
      "|    iterations              | 355                                  |\n",
      "|    time_elapsed            | 24361                                |\n",
      "|    total_timesteps         | 23265280                             |\n",
      "---------------------------------------------------------------------\n",
      " View run intrigued-goat-418 at: http://127.0.0.1:8080/#/experiments/0/runs/9b5450bf111f4653b28a4d7e53123f32\n",
      " View experiment at: http://127.0.0.1:8080/#/experiments/0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 45\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Set custom logger\u001B[39;00m\n\u001B[0;32m     44\u001B[0m model\u001B[38;5;241m.\u001B[39mset_logger(loggers)\n\u001B[1;32m---> 45\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhp_training_timesteps\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001B[0m, in \u001B[0;36mPPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    303\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfPPO,\n\u001B[0;32m    304\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    309\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    310\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfPPO:\n\u001B[1;32m--> 311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:336\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    333\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mep_info_buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    334\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dump_logs(iteration)\n\u001B[1;32m--> 336\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    338\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_end()\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:278\u001B[0m, in \u001B[0;36mPPO.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;66;03m# Clip grad norm\u001B[39;00m\n\u001B[0;32m    277\u001B[0m     th\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_grad_norm)\n\u001B[1;32m--> 278\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_updates \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m continue_training:\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    482\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    483\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    484\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    485\u001B[0m             )\n\u001B[1;32m--> 487\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    490\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    211\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    213\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    214\u001B[0m         group,\n\u001B[0;32m    215\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    220\u001B[0m         state_steps,\n\u001B[0;32m    221\u001B[0m     )\n\u001B[1;32m--> 223\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:784\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    782\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 784\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    786\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    803\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Dev\\PyCharm projects\\superpermutations\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:430\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    428\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    429\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 430\u001B[0m         denom \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbias_correction2_sqrt\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    432\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[0;32m    434\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T18:18:48.567914Z",
     "start_time": "2025-06-18T18:18:48.562808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(permutation_metrics_callback.best_permutation_length)\n",
    "print(permutation_metrics_callback.best_permutation)"
   ],
   "id": "fbbb9c7cc6876928",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "2 3 5 4 1 2 5 3 4 1 2 5 4 3 1 2 4 5 3 1 4 2 5 3 1 4 5 2 3 1 5 2 4 1 3 2 5 4 1 3 5 2 4 1 5 3 2 4 1 3 5 4 2 1 3 2 4 5 1 3 4 2 5 1 3 4 5 2 1 4 3 5 2 1 4 2 3 5 1 4 3 2 5 1 4 3 5 1 2 4 3 5 1 4 2 3 1 5 4 2 3 1 4 5 3 2 1 4 5 3 2 1 5 4 3 2 1 5 2 4 3 1 5 2 3 4 1 5 2 3 1 4 5 2 1 3 4 5 1 2 3 4 5 1 3 2 4 1 5 3 4 2 1 5 3 4 2 1 3 5 4 1 2 3 5 4 5 3 1 2 4 3 1 2 5 4 1 3 2\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "After ~6 hours of training the model appears to reach a sub-optimal solution (179 vs 153 characters).\n",
    "\n",
    "Interestingly, regardless of tested settings (for the clip range used in PPO and the learning rate) the model exhibits policy collapse-like behavior soon after reaching what appears to be the highest possible mean episodic reward for the particular training run. After that (judging from the training graphs) the model cyclically recovers and starts having issues again (characterized by a sharp drop in mean reward)"
   ],
   "id": "7fa2016a5cfb4c37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
